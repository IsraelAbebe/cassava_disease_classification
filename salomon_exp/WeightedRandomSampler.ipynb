{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "d3cVbqIs7PDi",
    "outputId": "19f10d20-d20f-4a31-d1d4-b97da869c7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n",
      "Torchvision Version:  0.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "#import pretrainedmodels\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aB5I0Rw47gBn"
   },
   "outputs": [],
   "source": [
    "# print('Train set:')\n",
    "# for cls in os.listdir(\"../input/ammi-2020-convnets/train/train\"):\n",
    "#     print('{}:{}'.format(cls, len(os.listdir(os.path.join(\"../input/ammi-2020-convnets/train/train\", cls)))))\n",
    "# im = Image.open('../input/ammi-2020-convnets/train/train/cgm/train-cgm-738.jpg')\n",
    "# print(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60SznP4x7qZb"
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/train/train\"\n",
    "test_path = \"./data/test/test\"\n",
    "extraimage_path = \"./data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cbsd:1443\n",
      "cgm:773\n",
      "cbb:466\n",
      "healthy:316\n",
      "cmd:2658\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cbsd': 1443, 'cgm': 773, 'cbb': 466, 'healthy': 316, 'cmd': 2658}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pq7aPxZO8Nyc"
   },
   "source": [
    "# Distribution of the classes in the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BKbVY308Ss2"
   },
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "\n",
    "# Transformations for both the training and testing data\n",
    "mean=[0.4543, 0.5137, 0.3240]\n",
    "std=[0.1949, 0.1977, 0.1661]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224), #448, 299, 224, 331\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "test_transforms = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9Za0HGZ8W4F"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        print(class_names)\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "# #         return im.view(3, 448, 448), classCategory\n",
    "        return im.view(3, 224, 224), classCategory\n",
    "# #         return im.view(3, 299, 299), classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0jldgqi8aqT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-cbsd': 1443, '1-cgm': 773, '2-cbb': 466, '3-healthy': 316, '4-cmd': 2658}\n",
      "{'0-0': 3774}\n",
      "{'0-0': 12595}\n"
     ]
    }
   ],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) #maybe need an other trasforms, I had to change the dataset structure :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size = 125 #16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=valid_sampler)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=batch_size) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1) # make batch = 1 here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = 0\n",
    "from collections import Counter\n",
    "\n",
    "Classes = Counter()\n",
    "\n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    total_train += i\n",
    "    Classes.update(label.tolist())# += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1130, 1: 618, 3: 258, 4: 2141, 2: 378})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHxCbEnY_NH7"
   },
   "source": [
    "# Over sample minority class and under sample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_2 = torch.utils.data.DataLoader(\n",
    "#     train_data, \n",
    "#     sampler=ImbalancedDatasetSampler(train_data),\n",
    "#     batch_size=args.batch_size, \n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTETomek # doctest: +NORMALIZE_WHITESPACE\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=4, class_sep=2,\n",
    "... weights=[0.2, 0.1, 0.3, 0.5], n_informative=3, n_redundant=1, flip_y=0,\n",
    "... n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({3: 400, 2: 300, 0: 200, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class Smote:\n",
    "    \"\"\"\n",
    "    SMOTE过采样算法.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: int\n",
    "        选取的近邻数目.\n",
    "    sampling_rate: int\n",
    "        采样倍数, attention sampling_rate < k.\n",
    "    newindex: int\n",
    "        生成的新样本(合成样本)的索引号.\n",
    "    \"\"\"\n",
    "    def __init__(self, sampling_rate=5, k=5):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.k = k\n",
    "        self.newindex = 0\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        if y is not None:\n",
    "            negative_X = X[y == 0]\n",
    "            X = X[y == 1]\n",
    " \n",
    "        n_samples, n_features = X.shape\n",
    "        # 初始化一个矩阵, 用来存储合成样本\n",
    "        self.synthetic = np.zeros((n_samples * self.sampling_rate, n_features))\n",
    " \n",
    "        # 找出正样本集(数据集X)中的每一个样本在数据集X中的k个近邻\n",
    "        knn = NearestNeighbors(n_neighbors=self.k).fit(X)\n",
    "        for i in range(len(X)):\n",
    "            k_neighbors = knn.kneighbors(X[i].reshape(1, -1),return_distance=False)[0]\n",
    "            # 对正样本集(minority class samples)中每个样本, 分别根据其k个近邻生成\n",
    "            # sampling_rate个新的样本\n",
    "            self.synthetic_samples(X, i, k_neighbors)\n",
    " \n",
    "        if y is not None:\n",
    "            return (np.concatenate((self.synthetic, X, negative_X), axis=0),\n",
    "                    np.concatenate(([1] * (len(self.synthetic) + len(X)), y[y == 0]), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smt = SMOTETomek(random_state=42)\n",
    "smt = Smote()\n",
    "# smt = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 400, 0: 400, 1: 400, 3: 400})\n"
     ]
    }
   ],
   "source": [
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Smote' object has no attribute 'synthetic_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-be5e42a53564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-65bbfe5fd50c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# 对正样本集(minority class samples)中每个样本, 分别根据其k个近邻生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# sampling_rate个新的样本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthetic_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Smote' object has no attribute 'synthetic_samples'"
     ]
    }
   ],
   "source": [
    "X_res, y_res = smt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLKDt9r38dGZ"
   },
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "# train_sampler = SubsetRandomSampler(train_indices)\n",
    "# valid_sampler = SubsetRandomSampler(val_indices)\n",
    "from torch.utils.data.sampler import SubsetRandomSampler,WeightedRandomSampler\n",
    "#-----------------------------------------------------------------------------z\n",
    "\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "ipdb.set_trace()\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "# get target\n",
    "\n",
    "targets=[]\n",
    "#data=[]\n",
    "\n",
    "for i in train_data.file_list:\n",
    "    targets.append(i[0])\n",
    "   # data.append(i[2])\n",
    "    \n",
    "target_train=targets[split:]\n",
    "train_set=data[split:]\n",
    "print(len(train_set))\n",
    "\n",
    "target_test=targets[:split]\n",
    "#test_set=data[:split]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# for i in test_data.file_list:\n",
    "#     test_targets.append(i[0])\n",
    "    \n",
    "# target = torch.cat((torch.zeros(int(len(train_data) * 0.99), dtype=torch.long),\n",
    "#                     torch.ones(int(len(train_data) * 0.01), dtype=torch.long)))\n",
    "\n",
    "\n",
    "#count classes\n",
    "class_count = np.unique(target_train ,return_counts=True)[1]\n",
    "#print(class_count)\n",
    "class_count_test= np.unique(target_test, return_counts=True)[1]\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# get weights train\n",
    "\n",
    "weight_train = 1. / class_count\n",
    "#print(targets)\n",
    "samples_weight_train = weight_train[target_train]\n",
    "#print(samples_weight_train )\n",
    "\n",
    "samples_weight_train = torch.from_numpy(samples_weight_train)\n",
    "#print(samples_weight_train)\n",
    "sampler_train = WeightedRandomSampler(samples_weight_train, len(samples_weight_train))\n",
    "\n",
    "#### valid\n",
    "\n",
    "\n",
    "\n",
    "weight_test = 1. / class_count_test\n",
    "#print(targets)\n",
    "samples_weight_test = weight_test[target_test]\n",
    "#print(samples_weight_train )\n",
    "\n",
    "samples_weight_test = torch.from_numpy(samples_weight_test)\n",
    "#print(samples_weight_train)\n",
    "sampler_valid = WeightedRandomSampler(samples_weight_test, len(samples_weight_test))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "                                             sampler=sampler_train)\n",
    "\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "                                             sampler=sampler_valid)\n",
    "# valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "#                                              sampler=valid_sampler)\n",
    "\n",
    "#test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XkQefu0a8sz2"
   },
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3qezIkE85cj"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self,input,n_class , dropout=0.2):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.conv=nn.Sequential(nn.Conv2d(input,32,5),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.MaxPool2d(3),\n",
    "                                nn.Conv2d(32,64,3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.MaxPool2d(3),\n",
    "                                nn.Conv2d(64,128,3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.MaxPool2d(3)\n",
    "                               )\n",
    "        \n",
    "        self.fc1=nn.Linear(7*7*128,512)\n",
    "        self.dropout =nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc2=nn.Linear(512,1024)\n",
    "        \n",
    "        self.fc3=nn.Linear(1024,256)\n",
    "        \n",
    "        self.fc4=nn.Linear(256,n_class)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)        \n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.dropout(F.relu(x))\n",
    "        x=self.fc2(x)\n",
    "        x=self.dropout(F.relu(x))\n",
    "        x=self.fc3(x)\n",
    "        x=self.dropout(F.relu(x))\n",
    "        x=self.fc4(x)        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZR2wwkh86yK"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz-VT3wy9NT5"
   },
   "source": [
    " # Model whith cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOocz4mU9OCw"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model(3,5)\n",
    "model=model.to(device)\n",
    "lr = 1e-4  # 0.001\n",
    "\n",
    "#--------------------------------------------------------------------------------------#\n",
    "train_loader.dataset.classes,\n",
    "class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
    "class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
    "\n",
    "class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
    "\n",
    "x = torch.Tensor(class_weights_normalized)\n",
    "x = x.to(device)\n",
    "x = x\n",
    "x,class_distrbution\n",
    "\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs=30\n",
    "total_loss_train, total_acc_train = [],[]\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    n=0\n",
    "    loss_list = []\n",
    "    acc_list = []   \n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "#         correct=0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Run the forward pass\n",
    "        images, labels = data\n",
    "        #print(images.size())\n",
    "\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)   \n",
    "        \n",
    "        outputs = model(images)\n",
    "        #print(outputs.size())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        #print(total)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "       \n",
    "        \n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/total)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"----------------------------------------------------------------\")\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "            print(\"----------------------------------------------------------------\")\n",
    "\n",
    "            \n",
    "#######################################################################################\n",
    "\n",
    "model.eval()\n",
    "val_loss = AverageMeter()\n",
    "val_acc = AverageMeter()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKBoSrKB9u6w"
   },
   "source": [
    "#  Model with focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr2q2fuQ9pS5"
   },
   "outputs": [],
   "source": [
    "def focalLoss(outputs, targets, w, alpha=1, gamma=4):\n",
    "    ce_loss = torch.nn.functional.cross_entropy(outputs, targets, reduction='none') # important to add reduction='none' to keep per-batch-item loss\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = (alpha * (1-pt)**gamma * ce_loss).mean() # mean over the batch\n",
    "    return focal_loss\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight=None, \n",
    "                 gamma=2., reduction='none'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob, \n",
    "            target_tensor, \n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thAAvd6q937a"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#--------------------------------------------------------------------------------------#\n",
    "train_loader.dataset.classes,\n",
    "class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
    "class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
    "\n",
    "class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
    "\n",
    "x = torch.Tensor(class_weights_normalized)\n",
    "x = x.to(device)\n",
    "x = x\n",
    "x,class_distrbution\n",
    "\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "model = Model(3,5)\n",
    "\n",
    "model=model.to(device)\n",
    "\n",
    "lr = 1e-4   # 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs=30\n",
    "total_loss_train, total_acc_train = [],[]\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   \n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    n=0\n",
    "    loss_list = []\n",
    "    acc_list = []  \n",
    "     \n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "#         correct=0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Run the forward pass\n",
    "        images, labels = data\n",
    "        #print(images.size())\n",
    "\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)   \n",
    "        \n",
    "        outputs = model(images)\n",
    "        #print(outputs.size())\n",
    "        loss =  focalLoss(outputs, labels,x)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        #print(total)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "       \n",
    "        \n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/total)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    " model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(focalLoss(outputs, labels,x).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WeightedRandomSampler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
