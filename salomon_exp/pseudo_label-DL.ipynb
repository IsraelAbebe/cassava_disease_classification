{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# UNLABELED_BS = 256\n",
    "# TRAIN_BS = 32\n",
    "# TEST_BS = 1024\n",
    "\n",
    "UNLABELED_BS = 32\n",
    "TRAIN_BS = 32\n",
    "TEST_BS = 32\n",
    "\n",
    "num_train_samples = 1000\n",
    "samples_per_class = int(num_train_samples/9)\n",
    "\n",
    "x = pd.read_csv('data/mnist_train.csv')\n",
    "y = x['label']\n",
    "x.drop(['label'], inplace = True, axis = 1)\n",
    "\n",
    "x_test = pd.read_csv('data/mnist_test.csv')\n",
    "y_test = x_test['label']\n",
    "x_test.drop(['label'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now, lets divide the dataset into train and unlabeled sets. For the train set we'll make sure that we have equal samples for all the 10 classes. (class-balancing)\n",
    "\n",
    "We wont use the labels for the unlabeled set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train, x_unlabeled = x[y.values == 0].values[:samples_per_class], \\\n",
    "                            x[y.values == 0].values[samples_per_class:]\n",
    "y_train = y[y.values == 0].values[:samples_per_class]\n",
    "\n",
    "for i in range(1,10):\n",
    "    x_train = np.concatenate([x_train, x[y.values == i].values[:samples_per_class]], axis = 0)\n",
    "    y_train = np.concatenate([y_train, y[y.values == i].values[:samples_per_class]], axis = 0)\n",
    "    \n",
    "    x_unlabeled = np.concatenate([x_unlabeled, x[y.values == i].values[samples_per_class:]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 111,\n",
       "         1: 111,\n",
       "         2: 111,\n",
       "         3: 111,\n",
       "         4: 111,\n",
       "         5: 111,\n",
       "         6: 111,\n",
       "         7: 111,\n",
       "         8: 111,\n",
       "         9: 111})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that awe have balance\n",
    "\n",
    "from collections import Counter\n",
    "count = Counter()\n",
    "count.update(y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58890, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, we'll normalize the data, convert it into tensors and create the dataloaders for train, unlabeled and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "x_train = normalizer.fit_transform(x_train)\n",
    "x_unlabeled = normalizer.transform(x_unlabeled)\n",
    "x_test = normalizer.transform(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor) \n",
    "\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test.values).type(torch.LongTensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = TRAIN_BS, shuffle = True, num_workers = 8)\n",
    "\n",
    "unlabeled_train = torch.from_numpy(x_unlabeled).type(torch.FloatTensor)\n",
    "\n",
    "unlabeled = torch.utils.data.TensorDataset(unlabeled_train)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(unlabeled, batch_size = UNLABELED_BS, shuffle = True, num_workers = 8)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = TEST_BS, shuffle = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Network Architecture\n",
    "\n",
    "We'll use a simple 2 layer Conv + 2 FC layer network with dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Architecture from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "            self.conv2 = nn.Conv2d(20, 40, kernel_size=5)\n",
    "            self.conv2_drop = nn.Dropout2d()\n",
    "            self.fc1 = nn.Linear(640, 150)\n",
    "            self.fc2 = nn.Linear(150, 10)\n",
    "            self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1,1,28,28)\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "            x = x.view(-1, 640)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.log_softmax(x)\n",
    "            return x\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now let's define a function to evaluate the network and get loss and accuracy values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0 \n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            predicted = torch.max(output,1)[1]\n",
    "            correct += (predicted == labels).sum()\n",
    "            loss += F.nll_loss(output, labels).item()\n",
    "\n",
    "    return (float(correct)/len(test)) *100, (loss/len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "First, let's train the model on the labeled set for 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm.notebook.tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_supervised(model, train_loader, test_loader):\n",
    "    optimizer = torch.optim.SGD( model.parameters(), lr = 0.1)\n",
    "    EPOCHS = 100\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        correct = 0\n",
    "        running_loss = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            output = model(X_batch)\n",
    "            labeled_loss = F.nll_loss(output, y_batch)\n",
    "                       \n",
    "            optimizer.zero_grad()\n",
    "            labeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += labeled_loss.item()\n",
    "        \n",
    "        if epoch %10 == 0:\n",
    "            test_acc, test_loss = evaluate(model, test_loader)\n",
    "            print('Epoch: {} : Train Loss : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, running_loss/(10 * len(train)), test_acc, test_loss))\n",
    "            model.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ee3fba6a044635a1bbce62e3f8b1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 : Train Loss : 0.00726 | Test Acc : 9.80000 | Test Loss : 2.303 \n",
      "Epoch: 10 : Train Loss : 0.00725 | Test Acc : 10.33000 | Test Loss : 2.297 \n",
      "Epoch: 20 : Train Loss : 0.00500 | Test Acc : 64.78000 | Test Loss : 1.277 \n",
      "Epoch: 30 : Train Loss : 0.00171 | Test Acc : 87.85000 | Test Loss : 0.378 \n",
      "Epoch: 40 : Train Loss : 0.00103 | Test Acc : 91.62000 | Test Loss : 0.253 \n",
      "Epoch: 50 : Train Loss : 0.00070 | Test Acc : 93.25000 | Test Loss : 0.209 \n",
      "Epoch: 60 : Train Loss : 0.00055 | Test Acc : 94.15000 | Test Loss : 0.190 \n",
      "Epoch: 70 : Train Loss : 0.00044 | Test Acc : 94.16000 | Test Loss : 0.191 \n",
      "Epoch: 80 : Train Loss : 0.00038 | Test Acc : 94.45000 | Test Loss : 0.183 \n",
      "Epoch: 90 : Train Loss : 0.00031 | Test Acc : 94.61000 | Test Loss : 0.189 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_supervised(net, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc : 94.56000 | Test Loss : 0.198 \n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = evaluate(net, test_loader)\n",
    "print('Test Acc : {:.5f} | Test Loss : {:.3f} '.format(test_acc, test_loss))\n",
    "torch.save(net.state_dict(), 'supervised_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('supervised_weights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lee in 2013](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf) [1]\n",
    "Lee proposes using the following equation for alpha (t) \n",
    "\n",
    "where alpha_f = 3, T1 = 100 and T2 = 600. All of these are hyperparameters that change based on the model and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "T1 = 100\n",
    "T2 = 700\n",
    "af = 3\n",
    "\n",
    "def alpha_weight(epoch):\n",
    "    if epoch < T1:\n",
    "        return 0.0\n",
    "    elif epoch > T2:\n",
    "        return af\n",
    "    else:\n",
    "         return ((epoch-T1) / (T2-T1))*af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Concept from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "acc_scores = []\n",
    "unlabel = []\n",
    "pseudo_label = []\n",
    "\n",
    "alpha_log = []\n",
    "test_acc_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "def semisup_train(model, train_loader, unlabeled_loader, test_loader):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "    EPOCHS = 30 # 150\n",
    "    \n",
    "    # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
    "    # This helps the model converge faster\n",
    "    step = 100 \n",
    "    \n",
    "    model.train()\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        for batch_idx, x_unlabeled in enumerate(unlabeled_loader):\n",
    "            \n",
    "            \n",
    "            # Forward Pass to get the pseudo labels\n",
    "            x_unlabeled = x_unlabeled[0].to(device)\n",
    "            model.eval()\n",
    "            output_unlabeled = model(x_unlabeled)\n",
    "            _, pseudo_labeled = torch.max(output_unlabeled, 1)\n",
    "            model.train()\n",
    "            \n",
    "            \n",
    "            \"\"\" ONLY FOR VISUALIZATION\"\"\"\n",
    "            if (batch_idx < 3) and (epoch % 10 == 0):\n",
    "                unlabel.append(x_unlabeled.cpu())\n",
    "                pseudo_label.append(pseudo_labeled.cpu())\n",
    "            \"\"\" ********************** \"\"\"\n",
    "            \n",
    "            # Now calculate the unlabeled loss using the pseudo label\n",
    "            output = model(x_unlabeled)\n",
    "            unlabeled_loss = alpha_weight(step) * F.nll_loss(output, pseudo_labeled)   \n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            unlabeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # For every 50 batches train one epoch on labeled data \n",
    "            if batch_idx % 50 == 0:\n",
    "                \n",
    "                # Normal training procedure\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    output = model(X_batch)\n",
    "                    labeled_loss = F.nll_loss(output, y_batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    labeled_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Now we increment step by 1\n",
    "                step += 1\n",
    "                \n",
    "\n",
    "        test_acc, test_loss =evaluate(model, test_loader)\n",
    "        print('Epoch: {} : Alpha Weight : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, alpha_weight(step), test_acc, test_loss))\n",
    "        \n",
    "        \"\"\" LOGGING VALUES \"\"\"\n",
    "        alpha_log.append(alpha_weight(step))\n",
    "        test_acc_log.append(test_acc/100)\n",
    "        test_loss_log.append(test_loss)\n",
    "        \"\"\" ************** \"\"\"\n",
    "        model.train()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81744af2f8714b1088132246b626b7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 : Alpha Weight : 0.18500 | Test Acc : 95.62000 | Test Loss : 0.162 \n",
      "Epoch: 1 : Alpha Weight : 0.37000 | Test Acc : 95.98000 | Test Loss : 0.164 \n",
      "Epoch: 2 : Alpha Weight : 0.55500 | Test Acc : 96.20000 | Test Loss : 0.147 \n",
      "Epoch: 3 : Alpha Weight : 0.74000 | Test Acc : 96.31000 | Test Loss : 0.136 \n",
      "Epoch: 4 : Alpha Weight : 0.92500 | Test Acc : 96.48000 | Test Loss : 0.137 \n",
      "Epoch: 5 : Alpha Weight : 1.11000 | Test Acc : 96.99000 | Test Loss : 0.123 \n",
      "Epoch: 6 : Alpha Weight : 1.29500 | Test Acc : 97.09000 | Test Loss : 0.104 \n",
      "Epoch: 7 : Alpha Weight : 1.48000 | Test Acc : 97.26000 | Test Loss : 0.113 \n",
      "Epoch: 8 : Alpha Weight : 1.66500 | Test Acc : 97.30000 | Test Loss : 0.111 \n",
      "Epoch: 9 : Alpha Weight : 1.85000 | Test Acc : 97.41000 | Test Loss : 0.106 \n",
      "Epoch: 10 : Alpha Weight : 2.03500 | Test Acc : 96.01000 | Test Loss : 0.150 \n",
      "Epoch: 11 : Alpha Weight : 2.22000 | Test Acc : 97.73000 | Test Loss : 0.089 \n",
      "Epoch: 12 : Alpha Weight : 2.40500 | Test Acc : 97.75000 | Test Loss : 0.096 \n",
      "Epoch: 13 : Alpha Weight : 2.59000 | Test Acc : 96.09000 | Test Loss : 0.159 \n",
      "Epoch: 14 : Alpha Weight : 2.77500 | Test Acc : 96.45000 | Test Loss : 0.137 \n",
      "Epoch: 15 : Alpha Weight : 2.96000 | Test Acc : 97.37000 | Test Loss : 0.110 \n",
      "Epoch: 16 : Alpha Weight : 3.00000 | Test Acc : 96.50000 | Test Loss : 0.176 \n",
      "Epoch: 17 : Alpha Weight : 3.00000 | Test Acc : 96.65000 | Test Loss : 0.139 \n",
      "Epoch: 18 : Alpha Weight : 3.00000 | Test Acc : 97.08000 | Test Loss : 0.139 \n",
      "Epoch: 19 : Alpha Weight : 3.00000 | Test Acc : 97.17000 | Test Loss : 0.117 \n",
      "Epoch: 20 : Alpha Weight : 3.00000 | Test Acc : 96.40000 | Test Loss : 0.152 \n",
      "Epoch: 21 : Alpha Weight : 3.00000 | Test Acc : 96.34000 | Test Loss : 0.145 \n",
      "Epoch: 22 : Alpha Weight : 3.00000 | Test Acc : 97.73000 | Test Loss : 0.109 \n",
      "Epoch: 23 : Alpha Weight : 3.00000 | Test Acc : 97.05000 | Test Loss : 0.113 \n",
      "Epoch: 24 : Alpha Weight : 3.00000 | Test Acc : 97.01000 | Test Loss : 0.113 \n",
      "Epoch: 25 : Alpha Weight : 3.00000 | Test Acc : 96.90000 | Test Loss : 0.129 \n",
      "Epoch: 26 : Alpha Weight : 3.00000 | Test Acc : 96.40000 | Test Loss : 0.174 \n",
      "Epoch: 27 : Alpha Weight : 3.00000 | Test Acc : 97.41000 | Test Loss : 0.125 \n",
      "Epoch: 28 : Alpha Weight : 3.00000 | Test Acc : 96.24000 | Test Loss : 0.160 \n",
      "Epoch: 29 : Alpha Weight : 3.00000 | Test Acc : 97.47000 | Test Loss : 0.132 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "semisup_train(net, train_loader, unlabeled_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc : 97.47000 | Test Loss : 0.132 \n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = evaluate(net, test_loader)\n",
    "print('Test Acc : {:.5f} | Test Loss : {:.3f} '.format(test_acc, test_loss))\n",
    "torch.save(net.state_dict(), 'semi_supervised_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "unlabel = np.concatenate([u.cpu().numpy() for u in unlabel])\n",
    "pseudo_label = np.concatenate([u.cpu().numpy() for u in pseudo_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = pd.read_csv('data/mnist_train.csv')\n",
    "y = x['label']\n",
    "x.drop(['label'], inplace = True, axis = 1)\n",
    "\n",
    "x = normalizer.transform(x.values)\n",
    "\n",
    "tsne_x = np.concatenate([x, x_train, unlabel])\n",
    "tsne_y = np.concatenate([y.values, y_train, pseudo_label])\n",
    "\n",
    "embeddings = TSNE(perplexity = 30, n_jobs=-1, verbose = 1, n_iter = 500).fit_transform(tsne_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: GTK3Agg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf931bf279b493388e547b56aae4b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%matplotlib\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "step_size = UNLABELED_BS * 3\n",
    "base_index = x.shape[0]\n",
    "epoch = 0\n",
    "for i in tqdm_notebook(range(0,unlabel.shape[0], step_size)):\n",
    "    plt.scatter(embeddings[:base_index, 0], embeddings[:base_index, 1], c=tsne_y[:base_index], cmap=plt.cm.get_cmap(\"jet\", 10), marker='s', alpha = 0.002, s = 14**2)\n",
    "    a = base_index\n",
    "    b = base_index + num_train_samples\n",
    "    plt.scatter(embeddings[a:b, 0], embeddings[a:b, 1], c=tsne_y[a:b], cmap=plt.cm.get_cmap(\"jet\", 10), marker='o', alpha = 0.3, s = 90**1)\n",
    "    a = base_index + num_train_samples + i\n",
    "    b = base_index + num_train_samples + i + step_size\n",
    "    plt.scatter(embeddings[a:b, 0], embeddings[a:b, 1], c=tsne_y[a:b], cmap=plt.cm.get_cmap(\"jet\", 10), marker='*', s = 150**1)\n",
    "    plt.colorbar(ticks=range(10))\n",
    "    plt.clim(-0.5, 9.5)\n",
    "    plt.title('Epoch : ' + str(epoch) +'  Test Acc : {:.2f}%'.format(test_acc_log[epoch]*100), fontsize = 20)\n",
    "    plt.savefig('imgs/tsne' + str(i) + '.png')\n",
    "    plt.draw()\n",
    "    plt.pause(5)\n",
    "    plt.clf()\n",
    "    epoch += 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
