{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretrainedmodels in /home/ubuntu/anaconda3/lib/python3.6/site-packages (0.7.4)\n",
      "Requirement already satisfied: munch in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from pretrainedmodels) (2.5.0)\n",
      "Requirement already satisfied: torch in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from pretrainedmodels) (1.5.0)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from pretrainedmodels) (0.6.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from pretrainedmodels) (4.45.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from munch->pretrainedmodels) (1.14.0)\n",
      "Requirement already satisfied: future in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from torch->pretrainedmodels) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from torch->pretrainedmodels) (1.16.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from torchvision->pretrainedmodels) (5.4.1)\n",
      "Collecting optuna\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/ee/2688cce5ced0597e12832d1ec4f4383a468f6bddff768eeaa3b5bf4f6500/optuna-1.3.0.tar.gz (163kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 6.5MB/s \n",
      "\u001b[?25hCollecting alembic\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 53.7MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cliff\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/17/57187872842bf9f65815b6969b515528ec7fd754137d2d3f49e3bc016175/cliff-3.1.0-py3-none-any.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 14.4MB/s \n",
      "\u001b[?25hCollecting cmaes\n",
      "  Downloading https://files.pythonhosted.org/packages/03/de/6ed34ebc0e5c34ed371d898540bca36edb4afe5bb2ca382483054e573c75/cmaes-0.5.0-py3-none-any.whl\n",
      "Collecting colorlog\n",
      "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from optuna) (0.14.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from optuna) (1.16.4)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from optuna) (1.2.11)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from optuna) (4.45.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from alembic->optuna) (2.7.3)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: Mako in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from alembic->optuna) (1.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from cliff->optuna) (2.2.0)\n",
      "Collecting PrettyTable<0.8,>=0.7.2\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
      "Collecting cmd2!=0.8.3,<0.9.0,>=0.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/40/a71caa2aaff10c73612a7106e2d35f693e85b8cf6e37ab0774274bca3cf9/cmd2-0.8.9-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 13.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from cliff->optuna) (1.14.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from cliff->optuna) (3.12)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 47.7MB/s \n",
      "\u001b[?25hCollecting stevedore>=1.20.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/49/a35dd566626892d577e426dbe5ea424dd7fbe10645f2c1070dcba474eca9/stevedore-1.32.0-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 11.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from Mako->alembic->optuna) (1.0)\n",
      "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /home/ubuntu/anaconda3/lib/python3.6/site-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna) (0.1.7)\n",
      "Collecting pyperclip\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
      "Building wheels for collected packages: alembic\n",
      "  Building wheel for alembic (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=9a37d2b71219a9bd99cac8c3af82fd310704436b68fc54d7f21542b88d273297\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
      "Successfully built alembic\n",
      "Building wheels for collected packages: optuna, PrettyTable, pyperclip\n",
      "  Building wheel for optuna (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optuna: filename=optuna-1.3.0-cp36-none-any.whl size=221121 sha256=c30319f3807f8a8355306b1961756cf3814c44988a85b2edeaad0f9b344e183c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/62/fd/dd/71cfd4cee14164152b952f477a16dac42ba413cfb1981585e4\n",
      "  Building wheel for PrettyTable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=413a8a8eea8e9614e776b8fade48fbcbcfcbb49bce7f1960c634f25ada596ae9\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=7ca8126ca63f4500a2e7b173f9fe3c52fd552eccf6bffdb66ad525352412ec1c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
      "Successfully built optuna PrettyTable pyperclip\n",
      "Installing collected packages: python-editor, alembic, PrettyTable, pyperclip, cmd2, pbr, stevedore, cliff, cmaes, colorlog, optuna\n",
      "Successfully installed PrettyTable-0.7.2 alembic-1.4.2 cliff-3.1.0 cmaes-0.5.0 cmd2-0.8.9 colorlog-4.1.0 optuna-1.3.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-1.32.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import pretrainedmodels\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train/train\"\n",
    "test_path = \"./data/test/test\"\n",
    "extraimage_path = \"./data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cmd:2658\n",
      "healthy:316\n",
      "cbsd:1443\n",
      "cbb:466\n",
      "cgm:773\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cmd': 2658, 'healthy': 316, 'cbsd': 1443, 'cbb': 466, 'cgm': 773}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.4543, 0.5137, 0.3240]\n",
    "std=[0.1949, 0.1977, 0.1661]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224), #448, 299, 224, 331\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "test_transforms = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "# normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "#         print(class_names)\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "# #         return im.view(3, 448, 448), classCategory\n",
    "        return im.view(3, 224, 224), classCategory\n",
    "# #         return im.view(3, 299, 299), classCategory\n",
    "#         return im.view(3, 331, 331), classCategory   # NASNetLarge 331x331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) #maybe need an other trasforms, I had to change the dataset structure :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size = 36 #16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=valid_sampler)\n",
    "\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=batch_size) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=1) # make batch = 1 here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(mean, std)],\n",
    "   std=[1/s for s in std]\n",
    ")\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = inv_normalize(img)# / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(unlabeled_loader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# print(labels)\n",
    "# img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# matplotlib_imshow(img_grid, one_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Additional(nn.Module):\n",
    "    def __init__(self, modelA,in_features,nb_classes=5,drop=0.1):\n",
    "        super(Additional, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        # Remove last linear layer\n",
    "        self.modelA.last_linear = nn.Identity()\n",
    "        \n",
    "        for p in self.modelA.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.fc_1 = nn.Linear(in_features,1024)\n",
    "        self.fc_2 = nn.Linear(1024,  512)\n",
    "        self.fc_out = nn.Linear( 512, nb_classes)\n",
    "        \n",
    "        #Dropout\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #model\n",
    "        x = self.modelA(x)  \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        #FC\n",
    "        x  = self.dropout(F.relu(self.fc_1(x)))\n",
    "        x = self.dropout(F.relu(self.fc_2(x)))\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Additional_(nn.Module):\n",
    "    def __init__(self, modelA,in_features,nb_classes=5, freeze = False):\n",
    "        super(Additional, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        # Remove last linear layer\n",
    "#         self.modelA.fc = nn.Identity() # for resnet\n",
    "        self.modelA.last_linear = nn.Identity() #for re_renext\n",
    "#         self.modelA.classifier = nn.Identity()    # densenet201\n",
    "        for p in self.modelA.parameters():\n",
    "            if freeze:\n",
    "                p.requires_grad = False\n",
    "            else :\n",
    "                p.requires_grad = True\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.fc_1 = nn.Linear(in_features,256)\n",
    "        self.fc_2 = nn.Linear(256,  512)\n",
    "        self.fc_out = nn.Linear( 512, nb_classes)\n",
    "        \n",
    "        #Dropout\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #model\n",
    "        x = self.modelA(x.clone())  \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        #FC\n",
    "        x  = self.dropout(self.fc_1(F.relu(x)))\n",
    "        x = self.dropout(self.fc_2(F.relu(x)))\n",
    "        x = self.fc_out(F.relu(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch,device):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "#         print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "            \n",
    "            \n",
    "        \n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch,device):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    _class_labels = np.array(['cbsd','cgm','cbb','healthy','cmd'])\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, _ = data\n",
    "            images = Variable(images).to(device)\n",
    "    \n",
    "            outputs = model(images)\n",
    "    \n",
    "            prediction = outputs.data.cpu().numpy().argmax()\n",
    "            \n",
    "            _predicted_class_labels = _class_labels[prediction]\n",
    "            \n",
    "            pred.append(_predicted_class_labels)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = pretrainedmodels.se_resnext50_32x4d(num_classes=1000, pretrained=\"imagenet\")\n",
    "   \n",
    "# # model.last_linear.in_features\n",
    "# # model.last_linear=nn.Identity()\n",
    "# # model = Additional(model,model.last_linear.in_features,drop=0.3)\n",
    "# # model = model.to(device)\n",
    "# model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     model = Additional(model,num_fits)\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
    "#     class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
    "\n",
    "#     class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
    "\n",
    "#     weights = torch.Tensor(class_weights_normalized)\n",
    "#     weights = weights.to(device)\n",
    "    \n",
    "    \n",
    "#     criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "#     optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "#     epoch_num = 15\n",
    "#     best_val_acc = 0.60\n",
    "#     total_loss_val, total_acc_val = [],[]\n",
    "#     for epoch in range(1, epoch_num+1):\n",
    "#         loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#         loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)\n",
    "#         total_loss_val.append(loss_val)\n",
    "#         total_acc_val.append(acc_val)\n",
    "#         if acc_val > best_val_acc:\n",
    "#             best_val_acc = acc_val\n",
    "#             torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "#             print('*****************************************************')\n",
    "#             print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "#             print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    drop  = trial.suggest_loguniform('drop', 0.1, 0.3)\n",
    "    \n",
    "#     model = model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet18', pretrained=True)\n",
    "\n",
    "    model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, \n",
    "                                                 pretrained=\"imagenet\")\n",
    "    model_name = 'se_resnext101_32x4d'\n",
    "\n",
    "    model = Additional(model, \n",
    "                       model.last_linear.in_features,\n",
    "                       drop=drop)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "#     class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
    "#     class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
    "\n",
    "#     class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
    "\n",
    "#     weights = torch.Tensor(class_weights_normalized)\n",
    "#     weights = weights.to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lr  = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    optim_ = trial.suggest_categorical('optim_',[optim.SGD, optim.RMSprop,optim.Adam])\n",
    "    momentum = trial.suggest_uniform('momentum', 0.4, 0.99)\n",
    "    optimizer = optim_(model.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch_num = 5\n",
    "    best_val_acc = 0.85\n",
    "    total_loss_val, total_acc_val = [],[]\n",
    "    for epoch in range(1, epoch_num+1):\n",
    "        loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch,device)\n",
    "        loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch,device)\n",
    "        total_loss_val.append(loss_val)\n",
    "        total_acc_val.append(acc_val)\n",
    "        if acc_val > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "            print('*****************************************************')\n",
    "            print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "            print('*****************************************************')\n",
    "            \n",
    "     # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "            \n",
    "    return acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/optuna/distributions.py:316: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "\n",
      "[W 2020-05-03 22:40:45,398] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/optuna/distributions.py:316: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "\n",
      "[W 2020-05-03 22:40:45,401] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/optuna/distributions.py:316: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "\n",
      "[W 2020-05-03 22:40:45,404] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.48681], [train acc 0.45861]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.32642], [val acc 0.48837]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.32316], [train acc 0.46444]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.24968], [val acc 0.48229]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.26208], [train acc 0.46944]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.20032], [val acc 0.48958]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.21453], [train acc 0.47833]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.14474], [val acc 0.56042]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 1.15130], [train acc 0.56194]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.08049], [val acc 0.61823]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 22:47:44,268] Finished trial#0 with value: 0.6182291666666668 with parameters: {'drop': 0.13614476646589874, 'lr': 0.0063059345324253165, 'optim_': <class 'torch.optim.sgd.SGD'>, 'momentum': 0.8970769054877679}. Best is trial#0 with value: 0.6182291666666668.\n",
      "[W 2020-05-03 22:47:45,421] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 22:47:45,424] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 22:47:45,426] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.32874], [train acc 0.59472]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.86087], [val acc 0.66285]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.90767], [train acc 0.67667]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.81340], [val acc 0.72188]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.86169], [train acc 0.70056]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.74391], [val acc 0.75104]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.86654], [train acc 0.69583]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.79284], [val acc 0.72465]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.83838], [train acc 0.71333]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.75600], [val acc 0.74497]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 22:54:46,189] Finished trial#1 with value: 0.7449652777777778 with parameters: {'drop': 0.11663145581970108, 'lr': 0.008769170914111571, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.5615441847309084}. Best is trial#1 with value: 0.7449652777777778.\n",
      "[W 2020-05-03 22:54:46,934] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 22:54:46,936] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 22:54:46,939] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 100.59461], [train acc 0.43889]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.32671], [val acc 0.48351]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.34382], [train acc 0.47056]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.32078], [val acc 0.48958]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.36821], [train acc 0.46500]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.32480], [val acc 0.48108]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.36095], [train acc 0.46750]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.31963], [val acc 0.48594]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 1.35324], [train acc 0.46611]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.32625], [val acc 0.48715]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:01:44,878] Finished trial#2 with value: 0.48715277777777766 with parameters: {'drop': 0.13783001366818087, 'lr': 0.08209134791956006, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.5503999488624555}. Best is trial#1 with value: 0.7449652777777778.\n",
      "[W 2020-05-03 23:01:45,626] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:01:45,628] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:01:45,630] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.16825], [train acc 0.59611]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.83036], [val acc 0.69965]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.87760], [train acc 0.69028]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.75176], [val acc 0.72535]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.81539], [train acc 0.71028]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.78721], [val acc 0.73854]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.83935], [train acc 0.70083]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.72670], [val acc 0.73715]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.77062], [train acc 0.72500]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.78760], [val acc 0.73611]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:08:44,225] Finished trial#3 with value: 0.7361111111111112 with parameters: {'drop': 0.17372115888756723, 'lr': 0.006772806790633048, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.4077944342848884}. Best is trial#1 with value: 0.7449652777777778.\n",
      "[W 2020-05-03 23:08:45,157] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:08:45,160] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:08:45,164] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.59515], [train acc 0.23694]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.57612], [val acc 0.45833]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.57152], [train acc 0.44056]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.55364], [val acc 0.49045]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.55075], [train acc 0.46361]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.53034], [val acc 0.48837]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.53024], [train acc 0.46417]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.50865], [val acc 0.48594]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 1.50898], [train acc 0.46750]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.48561], [val acc 0.48715]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:15:44,755] Finished trial#4 with value: 0.48715277777777777 with parameters: {'drop': 0.26114892515434124, 'lr': 0.00046353620554268656, 'optim_': <class 'torch.optim.sgd.SGD'>, 'momentum': 0.47121692585788566}. Best is trial#1 with value: 0.7449652777777778.\n",
      "[W 2020-05-03 23:15:45,457] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:15:45,459] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:15:45,461] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 0.94964], [train acc 0.64139]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.70842], [val acc 0.74063]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.73671], [train acc 0.73972]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.81461], [val acc 0.70139]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.69799], [train acc 0.74611]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.75100], [val acc 0.73628]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.69566], [train acc 0.75472]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.63994], [val acc 0.77187]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.64131], [train acc 0.76611]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.68467], [val acc 0.76076]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:22:46,018] Finished trial#5 with value: 0.7607638888888888 with parameters: {'drop': 0.2062737129841159, 'lr': 0.001337308717519322, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.9180869321753731}. Best is trial#5 with value: 0.7607638888888888.\n",
      "[W 2020-05-03 23:22:46,779] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:22:46,782] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:22:46,784] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 7264.60761], [train acc 0.38472]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 2.60638], [val acc 0.48420]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 41.21151], [train acc 0.45333]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.55383], [val acc 0.48594]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 2.60328], [train acc 0.46528]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.47053], [val acc 0.48559]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 27.20557], [train acc 0.45861]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.35404], [val acc 0.48681]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 8.67473], [train acc 0.46389]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.31580], [val acc 0.48594]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:29:45,683] Finished trial#6 with value: 0.48593749999999997 with parameters: {'drop': 0.12472493529895838, 'lr': 0.05267796495409559, 'optim_': <class 'torch.optim.rmsprop.RMSprop'>, 'momentum': 0.806191609428299}. Best is trial#5 with value: 0.7607638888888888.\n",
      "[W 2020-05-03 23:29:46,457] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:29:46,460] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:29:46,462] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.48379], [train acc 0.43694]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.29078], [val acc 0.48108]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.27673], [train acc 0.46917]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.17576], [val acc 0.52847]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.16979], [train acc 0.55750]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.06745], [val acc 0.62847]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.06721], [train acc 0.61361]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.97755], [val acc 0.64358]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.98929], [train acc 0.63639]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.93178], [val acc 0.67170]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:36:46,413] Finished trial#7 with value: 0.6717013888888888 with parameters: {'drop': 0.17840861844076344, 'lr': 1.0775357764688068e-05, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.7448557556808433}. Best is trial#5 with value: 0.7607638888888888.\n",
      "[W 2020-05-03 23:36:47,124] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:36:47,126] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:36:47,128] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 43.84907], [train acc 0.47278]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.01439], [val acc 0.62257]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.14239], [train acc 0.60389]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.88802], [val acc 0.66389]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.02329], [train acc 0.64417]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.83698], [val acc 0.69861]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.91309], [train acc 0.67333]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.81522], [val acc 0.71840]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.90465], [train acc 0.68750]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.86976], [val acc 0.67205]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:43:43,338] Finished trial#8 with value: 0.672048611111111 with parameters: {'drop': 0.15713872836780832, 'lr': 0.008289921690180493, 'optim_': <class 'torch.optim.rmsprop.RMSprop'>, 'momentum': 0.7342000076008594}. Best is trial#5 with value: 0.7607638888888888.\n",
      "[W 2020-05-03 23:43:44,112] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:43:44,114] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:43:44,117] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 7.96943], [train acc 0.52889]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.90342], [val acc 0.70469]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.90265], [train acc 0.68611]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.76614], [val acc 0.74028]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.81253], [train acc 0.70278]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.74851], [val acc 0.73646]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.75457], [train acc 0.73250]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.78383], [val acc 0.71493]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.75298], [train acc 0.73556]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.73516], [val acc 0.75069]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:50:46,801] Finished trial#9 with value: 0.7506944444444447 with parameters: {'drop': 0.2838551327293442, 'lr': 0.003976407724406057, 'optim_': <class 'torch.optim.rmsprop.RMSprop'>, 'momentum': 0.9671903123422626}. Best is trial#5 with value: 0.7607638888888888.\n",
      "[W 2020-05-03 23:50:47,784] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:50:47,787] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:50:47,790] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.10202], [train acc 0.57056]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.82044], [val acc 0.70625]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.77393], [train acc 0.71528]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.68565], [val acc 0.75556]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.68424], [train acc 0.75167]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.65933], [val acc 0.78594]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.64091], [train acc 0.76750]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.67499], [val acc 0.74809]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.62671], [train acc 0.76639]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.63243], [val acc 0.78125]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-03 23:57:46,328] Finished trial#10 with value: 0.7812499999999999 with parameters: {'drop': 0.22116263953849485, 'lr': 0.0001572527944133103, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.9697440252053012}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-03 23:57:47,148] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-03 23:57:47,151] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-03 23:57:47,154] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.12393], [train acc 0.55778]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.82693], [val acc 0.70868]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.79793], [train acc 0.71111]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.73314], [val acc 0.73333]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.70275], [train acc 0.75250]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.71533], [val acc 0.74549]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.67034], [train acc 0.75583]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.64583], [val acc 0.77587]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.63978], [train acc 0.77389]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.65865], [val acc 0.76250]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:04:48,166] Finished trial#11 with value: 0.7625000000000002 with parameters: {'drop': 0.2250659416059225, 'lr': 0.00012882277110717159, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.9894115514306111}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:04:48,866] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:04:48,870] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:04:48,872] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.24072], [train acc 0.52000]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.94670], [val acc 0.64306]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.88962], [train acc 0.66917]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.78236], [val acc 0.73264]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.76596], [train acc 0.72333]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.74232], [val acc 0.73976]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.69001], [train acc 0.74778]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.67460], [val acc 0.76892]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.67791], [train acc 0.75417]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.65943], [val acc 0.75747]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:11:47,366] Finished trial#12 with value: 0.7574652777777776 with parameters: {'drop': 0.2310658558060838, 'lr': 6.750615024116234e-05, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.9860226502332087}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:11:48,288] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:11:48,291] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:11:48,294] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.17865], [train acc 0.54194]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.85799], [val acc 0.69948]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.81336], [train acc 0.70667]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.73052], [val acc 0.72049]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.71412], [train acc 0.74000]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.68495], [val acc 0.76580]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.66297], [train acc 0.76222]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.69816], [val acc 0.75260]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.65845], [train acc 0.76722]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.63425], [val acc 0.77708]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:18:47,396] Finished trial#13 with value: 0.7770833333333335 with parameters: {'drop': 0.2145743141639617, 'lr': 9.422673086579123e-05, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.8578303053326606}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:18:48,142] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:18:48,144] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:18:48,147] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.47316], [train acc 0.44694]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.27388], [val acc 0.48715]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.26410], [train acc 0.47056]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.15967], [val acc 0.55503]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.15139], [train acc 0.56333]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.04157], [val acc 0.62344]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.03736], [train acc 0.62167]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.96154], [val acc 0.66302]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.96169], [train acc 0.64333]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.89326], [val acc 0.67188]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:25:47,639] Finished trial#14 with value: 0.671875 with parameters: {'drop': 0.19952138691485935, 'lr': 1.2195292630101856e-05, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.8510823211331353}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:25:48,739] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:25:48,742] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:25:48,745] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.60958], [train acc 0.19361]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.60869], [val acc 0.20017]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.60618], [train acc 0.23639]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.60456], [val acc 0.25156]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 1.60364], [train acc 0.26500]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.60085], [val acc 0.32049]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 1.60065], [train acc 0.30333]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.59818], [val acc 0.36944]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 1.59672], [train acc 0.34528]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.59440], [val acc 0.42170]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:32:47,707] Finished trial#15 with value: 0.42170138888888886 with parameters: {'drop': 0.2551956429037652, 'lr': 5.707312554122396e-05, 'optim_': <class 'torch.optim.sgd.SGD'>, 'momentum': 0.8110229863392482}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:32:48,456] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:32:48,459] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:32:48,464] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 0.99656], [train acc 0.62417]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.75537], [val acc 0.73247]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.75074], [train acc 0.72556]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.66788], [val acc 0.74774]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.66810], [train acc 0.76250]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.69202], [val acc 0.74774]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.63156], [train acc 0.77250]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.75217], [val acc 0.73750]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.65467], [train acc 0.76278]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.64569], [val acc 0.76910]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:39:48,649] Finished trial#16 with value: 0.7690972222222223 with parameters: {'drop': 0.2876311501561197, 'lr': 0.00039028917437102976, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.6462991489337667}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:39:49,680] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:39:49,683] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:39:49,685] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.34296], [train acc 0.46944]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.10172], [val acc 0.61701]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 1.04655], [train acc 0.60944]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.89119], [val acc 0.66372]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.89442], [train acc 0.66583]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.78254], [val acc 0.70781]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.81054], [train acc 0.70028]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.74786], [val acc 0.72517]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.73388], [train acc 0.73778]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.69302], [val acc 0.74722]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:46:48,775] Finished trial#17 with value: 0.7472222222222222 with parameters: {'drop': 0.20125769000000626, 'lr': 3.198443059165596e-05, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.9095946794035338}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:46:49,787] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:46:49,789] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:46:49,791] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.06269], [train acc 0.59472]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.78768], [val acc 0.72187]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.76415], [train acc 0.72056]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.69423], [val acc 0.77361]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.68248], [train acc 0.75361]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.64810], [val acc 0.77118]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.64801], [train acc 0.76778]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.66859], [val acc 0.75608]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.62722], [train acc 0.76833]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.63919], [val acc 0.77778]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 00:53:48,114] Finished trial#18 with value: 0.7777777777777778 with parameters: {'drop': 0.10200088121173835, 'lr': 0.0002046315603677309, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.838154173456564}. Best is trial#10 with value: 0.7812499999999999.\n",
      "[W 2020-05-04 00:53:48,875] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
      "[W 2020-05-04 00:53:48,878] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.rmsprop.RMSprop'> which is of type type.\n",
      "[W 2020-05-04 00:53:48,883] Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 126], [train loss 1.07039], [train acc 0.59750]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.86629], [val acc 0.68681]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 126], [train loss 0.73446], [train acc 0.74000]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.69949], [val acc 0.75365]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 126], [train loss 0.69212], [train acc 0.75361]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.65257], [val acc 0.76840]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 126], [train loss 0.65460], [train acc 0.76139]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.65217], [val acc 0.76771]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 126], [train loss 0.61660], [train acc 0.77722]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.66259], [val acc 0.74913]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-04 01:00:48,408] Finished trial#19 with value: 0.7491319444444443 with parameters: {'drop': 0.10682191307249966, 'lr': 0.0002212790581010009, 'optim_': <class 'torch.optim.adam.Adam'>, 'momentum': 0.6551700049432666}. Best is trial#10 with value: 0.7812499999999999.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0:'cbsd', 1: 'cgm', 2: 'cbb', 3: 'healthy', 4: 'cmd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_dir):\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # tensor.numpy().transpose(1, 2, 0)\n",
    "    image = Image.open(image_dir)\n",
    "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "    image = preprocess(image)\n",
    "    # Convert 2D image to 1D vector\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.from_numpy(image)\n",
    "    inputs = image.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the label\n",
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model(image)\n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"./data/test/test/0\"\n",
    "predictions, test_image_fileName = [], []\n",
    "try:\n",
    "    test_images = listdir(test_directory)\n",
    "    for images in test_images:\n",
    "        test_image_fileName.append(images)\n",
    "        image = process_image(f'{test_directory}/{images}')\n",
    "        top_prob, top_class = predict(image, model)\n",
    "        predictions.append(class_names[top_class])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Creating pandas dataframe\")\n",
    "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
    "submission_data_frame = pd.DataFrame(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_frame.to_csv('submission'+model_name+'_freeze_86_flip.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
