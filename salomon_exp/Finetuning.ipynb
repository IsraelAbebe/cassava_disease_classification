{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrainedmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.5.0+cu101)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.6.0+cu101)\n",
      "Collecting munch\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.38.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.18.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (7.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.12.0)\n",
      "Building wheels for collected packages: pretrainedmodels\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=7b6c4528fe545634fc2de98077ec6b8be780c0463b0332738f5831c1efe3f470\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
      "Successfully built pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels\n",
      "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0+cu101\n",
      "Torchvision Version:  0.6.0+cu101\n",
      "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.1.3)\n",
      "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import pretrainedmodels\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "!pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train/train\"\n",
    "test_path = \"./data/test/test\"\n",
    "extraimage_path = \"./data/extraimages/extraimages\"\n",
    "\n",
    "path_to_drive = \"../../../../content/gdrive/My\\ Drive/data/cassava_disease_classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cbb:466\n",
      "healthy:316\n",
      "cbsd:1443\n",
      "cmd:2658\n",
      "cgm:773\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cbb': 466, 'cbsd': 1443, 'cgm': 773, 'cmd': 2658, 'healthy': 316}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.4543, 0.5137, 0.3240]\n",
    "std=[0.1949, 0.1977, 0.1661]\n",
    "\n",
    "\n",
    "s=1\n",
    "color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        \n",
    "train_2_transforms  =  torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.RandomResizedCrop(448),\n",
    "                            torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                            torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                            torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                            torchvision.transforms.ToTensor()])\n",
    "        \n",
    "\n",
    "# data augumentaion: RandomCrop, VFlip, HFilp, RandomRotate\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(448),\n",
    "                                       transforms.RandomResizedCrop(448), #448, 299, 224, 331\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "test_transforms = transforms.Compose([ transforms.Resize(448),\n",
    "                                       transforms.CenterCrop(448),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "# normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "#         print(class_names)\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "        return im.view(3, 448, 448), classCategory\n",
    "#         return im.view(3, 224, 224), classCategory\n",
    "# #         return im.view(3, 299, 299), classCategory\n",
    "#         return im.view(3, 331, 331), classCategory   # NASNetLarge 331x331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) #maybe need an other trasforms, I had to change the dataset structure :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size = 16 #16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                             sampler=valid_sampler)\n",
    "\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=batch_size) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=1) # make batch = 1 here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating PT data samplers and loaders:\n",
    "# # train_sampler = SubsetRandomSampler(train_indices)\n",
    "# # valid_sampler = SubsetRandomSampler(val_indices)\n",
    "# from torch.utils.data.sampler import SubsetRandomSampler,WeightedRandomSampler\n",
    "# #-----------------------------------------------------------------------------z\n",
    "\n",
    "# validation_split = 0.2\n",
    "# shuffle_dataset = True\n",
    "# random_seed= 42\n",
    "\n",
    "# # ipdb.set_trace()\n",
    "# # Creating data indices for training and validation splits:\n",
    "# dataset_size = len(train_data)\n",
    "# indices = list(range(dataset_size))\n",
    "# split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "\n",
    "# train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "# # get target\n",
    "\n",
    "# targets=[]\n",
    "# #data=[]\n",
    "# file_list =train_data.file_list\n",
    "# np.random.shuffle(file_list)\n",
    "# for i in file_list:\n",
    "#     targets.append(i[0])\n",
    "#    # data.append(i[2])\n",
    "    \n",
    "# target_train=targets[split:]\n",
    "# # train_set=data[split:]\n",
    "# # print(len(train_set))\n",
    "\n",
    "# target_test=targets[:split]\n",
    "# #test_set=data[:split]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# # for i in test_data.file_list:\n",
    "# #     test_targets.append(i[0])\n",
    "    \n",
    "# # target = torch.cat((torch.zeros(int(len(train_data) * 0.99), dtype=torch.long),\n",
    "# #                     torch.ones(int(len(train_data) * 0.01), dtype=torch.long)))\n",
    "\n",
    "\n",
    "# #count classes\n",
    "# class_count = np.unique(target_train ,return_counts=True)[1]\n",
    "# #print(class_count)\n",
    "# class_count_test= np.unique(target_test, return_counts=True)[1]\n",
    "\n",
    "\n",
    "# #--------------------------------------------------------------------\n",
    "# # get weights train\n",
    "\n",
    "# weight_train = 1. / class_count\n",
    "# #print(targets)\n",
    "# samples_weight_train = weight_train[target_train]\n",
    "# #print(samples_weight_train )\n",
    "\n",
    "# samples_weight_train = torch.from_numpy(samples_weight_train)\n",
    "# #print(samples_weight_train)\n",
    "# sampler_train = WeightedRandomSampler(samples_weight_train, len(samples_weight_train))\n",
    "\n",
    "# #### valid\n",
    "\n",
    "\n",
    "\n",
    "# weight_test = 1. / class_count_test\n",
    "# #print(targets)\n",
    "# samples_weight_test = weight_test[target_test]\n",
    "# #print(samples_weight_train )\n",
    "\n",
    "# samples_weight_test = torch.from_numpy(samples_weight_test)\n",
    "# #print(samples_weight_train)\n",
    "# sampler_valid = WeightedRandomSampler(samples_weight_test, len(samples_weight_test))\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "#                                              sampler=sampler_train)\n",
    "\n",
    "\n",
    "# valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "#                                              sampler=sampler_valid)\n",
    "# # valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "# #                                              sampler=valid_sampler)\n",
    "\n",
    "# #test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data,label in valid_loader:\n",
    "#     print(label)\n",
    "#     break\n",
    "# #     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(mean, std)],\n",
    "   std=[1/s for s in std]\n",
    ")\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = inv_normalize(img)# / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(unlabeled_loader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# print(labels)\n",
    "# img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# matplotlib_imshow(img_grid, one_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Additional(nn.Module):\n",
    "    def __init__(self, modelA,in_features,nb_classes=5, freeze = False):\n",
    "        super(Additional, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        # Remove last linear layer\n",
    "#         self.modelA.fc = nn.Identity() # for resnet\n",
    "        self.modelA.last_linear = nn.Identity() #for re_renext\n",
    "#         self.modelA.classifier = nn.Identity()    # densenet201\n",
    "        for p in self.modelA.parameters():\n",
    "            if freeze:\n",
    "                p.requires_grad = False\n",
    "            else :\n",
    "                p.requires_grad = True\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.fc_1 = nn.Linear(in_features, 256)\n",
    "        self.fc_2 = nn.Linear(256, 512)\n",
    "        self.fc_out = nn.Linear( 512, nb_classes)\n",
    "        \n",
    "        #Dropout\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #model\n",
    "        x = self.modelA(x.clone())  \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        #FC\n",
    "        x  = self.dropout(self.fc_1(F.relu(x)))\n",
    "        x = self.dropout(self.fc_2(F.relu(x)))\n",
    "        x = self.fc_out(F.relu(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipdb\n",
    "# {'0-cbsd': 1443, '1-cgm': 773, '2-cbb': 466, '3-healthy': 316, '4-cmd': 2658}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    _class_labels = np.array(['cbsd','cgm','cbb','healthy','cmd'])\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, _ = data\n",
    "            images = Variable(images).to(device)\n",
    "    \n",
    "            outputs = model(images)\n",
    "    \n",
    "            prediction = outputs.data.cpu().numpy().argmax()\n",
    "            \n",
    "            _predicted_class_labels = _class_labels[prediction]\n",
    "            \n",
    "            pred.append(_predicted_class_labels)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'se_resnext101_32x4d' # se_resnext101_32x4d, resnext101_64x4d, nasnetlarge\n",
    "# resnet_model = torch.hub.load('pytorch/vision:v0.5.0', model_name, pretrained=True)\n",
    "resnet_model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")# todo : how to pretrained=False ?\n",
    "\n",
    "# # num_fits = resnet_model.fc.in_features\n",
    "num_fits = 131072# resnet_model.last_linear.in_features # se_resnext101_32x4d\n",
    "# # num_fits = resnet_model.classifier.in_features # densenet201\n",
    "# num_fits\n",
    "\n",
    "\n",
    "model = Additional(resnet_model, num_fits, freeze = False)\n",
    "model = model.to(device)\n",
    "# # model\n",
    "\n",
    "# #--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('se_resnext101_32x4dall_data_0.89.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# train_loader.dataset.classes,\n",
    "# class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
    "# class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
    "\n",
    "# class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
    "\n",
    "# x = torch.Tensor(class_weights_normalized)\n",
    "# x = x.to(device)\n",
    "# x = x\n",
    "# x,class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 76 - 74 (non weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 283], [train loss 0.31900], [train acc 0.88875]\n",
      "[epoch 1], [iter 200 / 283], [train loss 0.30732], [train acc 0.88750]\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 0.31581], [val acc 0.88621]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 283], [train loss 0.32153], [train acc 0.88625]\n",
      "[epoch 2], [iter 200 / 283], [train loss 0.32538], [train acc 0.88594]\n",
      "[epoch 3], [iter 100 / 283], [train loss 0.32519], [train acc 0.88187]\n",
      "[epoch 3], [iter 200 / 283], [train loss 0.31756], [train acc 0.88438]\n",
      "*****************************************************\n",
      "best record: [epoch 3], [val loss 0.31830], [val acc 0.88704]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 / 283], [train loss 0.28207], [train acc 0.90250]\n",
      "[epoch 4], [iter 200 / 283], [train loss 0.28793], [train acc 0.89625]\n",
      "*****************************************************\n",
      "best record: [epoch 4], [val loss 0.29507], [val acc 0.89411]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 100 / 283], [train loss 0.30160], [train acc 0.88875]\n",
      "[epoch 5], [iter 200 / 283], [train loss 0.30746], [train acc 0.89094]\n",
      "[epoch 6], [iter 100 / 283], [train loss 0.27715], [train acc 0.90250]\n",
      "[epoch 6], [iter 200 / 283], [train loss 0.29863], [train acc 0.89656]\n",
      "*****************************************************\n",
      "best record: [epoch 6], [val loss 0.29903], [val acc 0.89664]\n",
      "*****************************************************\n",
      "[epoch 7], [iter 100 / 283], [train loss 0.28561], [train acc 0.90187]\n",
      "[epoch 7], [iter 200 / 283], [train loss 0.29936], [train acc 0.89812]\n",
      "*****************************************************\n",
      "best record: [epoch 7], [val loss 0.29485], [val acc 0.89858]\n",
      "*****************************************************\n",
      "[epoch 8], [iter 100 / 283], [train loss 0.28495], [train acc 0.89563]\n",
      "[epoch 8], [iter 200 / 283], [train loss 0.28476], [train acc 0.89687]\n",
      "[epoch 9], [iter 100 / 283], [train loss 0.27888], [train acc 0.89875]\n",
      "[epoch 9], [iter 200 / 283], [train loss 0.27562], [train acc 0.90281]\n",
      "*****************************************************\n",
      "best record: [epoch 9], [val loss 0.27981], [val acc 0.89946]\n",
      "*****************************************************\n",
      "[epoch 10], [iter 100 / 283], [train loss 0.26408], [train acc 0.92063]\n",
      "[epoch 10], [iter 200 / 283], [train loss 0.25694], [train acc 0.91687]\n",
      "*****************************************************\n",
      "best record: [epoch 10], [val loss 0.26247], [val acc 0.91316]\n",
      "*****************************************************\n",
      "[epoch 11], [iter 100 / 283], [train loss 0.26654], [train acc 0.91063]\n",
      "[epoch 11], [iter 200 / 283], [train loss 0.28372], [train acc 0.90563]\n",
      "[epoch 12], [iter 100 / 283], [train loss 0.27214], [train acc 0.89938]\n",
      "[epoch 12], [iter 200 / 283], [train loss 0.28056], [train acc 0.89438]\n",
      "[epoch 13], [iter 100 / 283], [train loss 0.27222], [train acc 0.90250]\n",
      "[epoch 13], [iter 200 / 283], [train loss 0.27409], [train acc 0.90094]\n",
      "[epoch 14], [iter 100 / 283], [train loss 0.26578], [train acc 0.90250]\n",
      "[epoch 14], [iter 200 / 283], [train loss 0.29232], [train acc 0.89750]\n",
      "[epoch 15], [iter 100 / 283], [train loss 0.28290], [train acc 0.89687]\n",
      "[epoch 15], [iter 200 / 283], [train loss 0.26602], [train acc 0.90469]\n",
      "[epoch 16], [iter 100 / 283], [train loss 0.24576], [train acc 0.90875]\n",
      "[epoch 16], [iter 200 / 283], [train loss 0.26519], [train acc 0.90500]\n",
      "[epoch 17], [iter 100 / 283], [train loss 0.23629], [train acc 0.91250]\n",
      "[epoch 17], [iter 200 / 283], [train loss 0.26894], [train acc 0.90500]\n",
      "[epoch 18], [iter 100 / 283], [train loss 0.29259], [train acc 0.89625]\n",
      "[epoch 18], [iter 200 / 283], [train loss 0.28609], [train acc 0.90312]\n",
      "[epoch 19], [iter 100 / 283], [train loss 0.26518], [train acc 0.90875]\n",
      "[epoch 19], [iter 200 / 283], [train loss 0.26427], [train acc 0.91156]\n",
      "[epoch 20], [iter 100 / 283], [train loss 0.26306], [train acc 0.90938]\n",
      "[epoch 20], [iter 200 / 283], [train loss 0.25935], [train acc 0.90656]\n",
      "[epoch 21], [iter 100 / 283], [train loss 0.27161], [train acc 0.91125]\n",
      "[epoch 21], [iter 200 / 283], [train loss 0.25263], [train acc 0.91531]\n",
      "[epoch 22], [iter 100 / 283], [train loss 0.26112], [train acc 0.91063]\n",
      "[epoch 22], [iter 200 / 283], [train loss 0.26430], [train acc 0.90594]\n",
      "[epoch 23], [iter 100 / 283], [train loss 0.24923], [train acc 0.91438]\n",
      "[epoch 23], [iter 200 / 283], [train loss 0.25179], [train acc 0.91344]\n",
      "*****************************************************\n",
      "best record: [epoch 23], [val loss 0.24391], [val acc 0.91620]\n",
      "*****************************************************\n",
      "[epoch 24], [iter 100 / 283], [train loss 0.25068], [train acc 0.90312]\n",
      "[epoch 24], [iter 200 / 283], [train loss 0.25931], [train acc 0.90344]\n",
      "[epoch 25], [iter 100 / 283], [train loss 0.19859], [train acc 0.92437]\n",
      "[epoch 25], [iter 200 / 283], [train loss 0.22146], [train acc 0.91750]\n",
      "[epoch 26], [iter 100 / 283], [train loss 0.23499], [train acc 0.91563]\n",
      "[epoch 26], [iter 200 / 283], [train loss 0.24971], [train acc 0.91500]\n",
      "[epoch 27], [iter 100 / 283], [train loss 0.27532], [train acc 0.90125]\n",
      "[epoch 27], [iter 200 / 283], [train loss 0.25565], [train acc 0.90469]\n",
      "[epoch 28], [iter 100 / 283], [train loss 0.23017], [train acc 0.92375]\n",
      "[epoch 28], [iter 200 / 283], [train loss 0.23639], [train acc 0.92188]\n",
      "*****************************************************\n",
      "best record: [epoch 28], [val loss 0.24192], [val acc 0.91801]\n",
      "*****************************************************\n",
      "[epoch 29], [iter 100 / 283], [train loss 0.22437], [train acc 0.92000]\n",
      "[epoch 29], [iter 200 / 283], [train loss 0.23837], [train acc 0.91375]\n",
      "[epoch 30], [iter 100 / 283], [train loss 0.23519], [train acc 0.91438]\n",
      "[epoch 30], [iter 200 / 283], [train loss 0.23224], [train acc 0.91438]\n",
      "[epoch 31], [iter 100 / 283], [train loss 0.25165], [train acc 0.90500]\n",
      "[epoch 31], [iter 200 / 283], [train loss 0.24189], [train acc 0.91031]\n",
      "[epoch 32], [iter 100 / 283], [train loss 0.24217], [train acc 0.90812]\n",
      "[epoch 32], [iter 200 / 283], [train loss 0.24623], [train acc 0.91219]\n",
      "[epoch 33], [iter 100 / 283], [train loss 0.22957], [train acc 0.92312]\n",
      "[epoch 33], [iter 200 / 283], [train loss 0.24616], [train acc 0.91719]\n",
      "[epoch 34], [iter 100 / 283], [train loss 0.20587], [train acc 0.92563]\n",
      "[epoch 34], [iter 200 / 283], [train loss 0.23621], [train acc 0.91563]\n",
      "[epoch 35], [iter 100 / 283], [train loss 0.19657], [train acc 0.92437]\n",
      "[epoch 35], [iter 200 / 283], [train loss 0.21735], [train acc 0.92063]\n",
      "[epoch 36], [iter 100 / 283], [train loss 0.20395], [train acc 0.92437]\n",
      "[epoch 36], [iter 200 / 283], [train loss 0.22466], [train acc 0.91906]\n",
      "*****************************************************\n",
      "best record: [epoch 36], [val loss 0.22391], [val acc 0.92078]\n",
      "*****************************************************\n",
      "[epoch 37], [iter 100 / 283], [train loss 0.22452], [train acc 0.92563]\n",
      "[epoch 37], [iter 200 / 283], [train loss 0.23173], [train acc 0.92312]\n",
      "*****************************************************\n",
      "best record: [epoch 37], [val loss 0.22534], [val acc 0.92557]\n",
      "*****************************************************\n",
      "[epoch 38], [iter 100 / 283], [train loss 0.24089], [train acc 0.91687]\n",
      "[epoch 38], [iter 200 / 283], [train loss 0.23684], [train acc 0.91656]\n",
      "[epoch 39], [iter 100 / 283], [train loss 0.24009], [train acc 0.91375]\n",
      "[epoch 39], [iter 200 / 283], [train loss 0.23015], [train acc 0.91687]\n",
      "[epoch 40], [iter 100 / 283], [train loss 0.26056], [train acc 0.90750]\n",
      "[epoch 40], [iter 200 / 283], [train loss 0.25817], [train acc 0.90469]\n",
      "[epoch 41], [iter 100 / 283], [train loss 0.21301], [train acc 0.92500]\n",
      "[epoch 41], [iter 200 / 283], [train loss 0.22210], [train acc 0.92000]\n",
      "[epoch 42], [iter 100 / 283], [train loss 0.21864], [train acc 0.92063]\n",
      "[epoch 42], [iter 200 / 283], [train loss 0.21366], [train acc 0.92375]\n",
      "[epoch 43], [iter 100 / 283], [train loss 0.20854], [train acc 0.92625]\n",
      "[epoch 43], [iter 200 / 283], [train loss 0.21910], [train acc 0.91938]\n",
      "[epoch 44], [iter 100 / 283], [train loss 0.20537], [train acc 0.92375]\n",
      "[epoch 44], [iter 200 / 283], [train loss 0.20620], [train acc 0.92625]\n",
      "[epoch 45], [iter 100 / 283], [train loss 0.17870], [train acc 0.93000]\n",
      "[epoch 45], [iter 200 / 283], [train loss 0.19022], [train acc 0.92625]\n",
      "[epoch 46], [iter 100 / 283], [train loss 0.22571], [train acc 0.92312]\n",
      "[epoch 46], [iter 200 / 283], [train loss 0.21640], [train acc 0.92188]\n",
      "[epoch 47], [iter 100 / 283], [train loss 0.18778], [train acc 0.92937]\n",
      "[epoch 47], [iter 200 / 283], [train loss 0.21859], [train acc 0.92188]\n",
      "[epoch 48], [iter 100 / 283], [train loss 0.19919], [train acc 0.92875]\n",
      "[epoch 48], [iter 200 / 283], [train loss 0.21182], [train acc 0.92469]\n",
      "*****************************************************\n",
      "best record: [epoch 48], [val loss 0.21285], [val acc 0.92624]\n",
      "*****************************************************\n",
      "[epoch 49], [iter 100 / 283], [train loss 0.18747], [train acc 0.93125]\n",
      "[epoch 49], [iter 200 / 283], [train loss 0.20156], [train acc 0.92812]\n",
      "*****************************************************\n",
      "best record: [epoch 49], [val loss 0.20326], [val acc 0.92685]\n",
      "*****************************************************\n",
      "[epoch 50], [iter 100 / 283], [train loss 0.18799], [train acc 0.93188]\n",
      "*****************************************************\n",
      "best record: [epoch 50], [val loss 0.20267], [val acc 0.92800]\n",
      "*****************************************************\n",
      "[epoch 51], [iter 100 / 283], [train loss 0.20439], [train acc 0.91563]\n",
      "[epoch 51], [iter 200 / 283], [train loss 0.21163], [train acc 0.91812]\n",
      "[epoch 52], [iter 100 / 283], [train loss 0.20847], [train acc 0.92500]\n",
      "[epoch 52], [iter 200 / 283], [train loss 0.21306], [train acc 0.92250]\n",
      "[epoch 53], [iter 100 / 283], [train loss 0.19745], [train acc 0.93563]\n",
      "[epoch 53], [iter 200 / 283], [train loss 0.18932], [train acc 0.93594]\n",
      "*****************************************************\n",
      "best record: [epoch 53], [val loss 0.19416], [val acc 0.93242]\n",
      "*****************************************************\n",
      "[epoch 54], [iter 100 / 283], [train loss 0.20585], [train acc 0.92312]\n",
      "[epoch 54], [iter 200 / 283], [train loss 0.20312], [train acc 0.92469]\n",
      "[epoch 55], [iter 100 / 283], [train loss 0.21252], [train acc 0.92937]\n",
      "[epoch 55], [iter 200 / 283], [train loss 0.20775], [train acc 0.93125]\n",
      "[epoch 56], [iter 100 / 283], [train loss 0.21704], [train acc 0.92500]\n",
      "[epoch 56], [iter 200 / 283], [train loss 0.19063], [train acc 0.93469]\n",
      "[epoch 57], [iter 100 / 283], [train loss 0.20969], [train acc 0.92625]\n",
      "[epoch 57], [iter 200 / 283], [train loss 0.21621], [train acc 0.92156]\n",
      "[epoch 58], [iter 100 / 283], [train loss 0.20111], [train acc 0.93625]\n",
      "[epoch 58], [iter 200 / 283], [train loss 0.20166], [train acc 0.93125]\n",
      "[epoch 59], [iter 100 / 283], [train loss 0.18162], [train acc 0.93937]\n",
      "[epoch 59], [iter 200 / 283], [train loss 0.19507], [train acc 0.93281]\n",
      "[epoch 60], [iter 100 / 283], [train loss 0.17971], [train acc 0.93125]\n",
      "[epoch 60], [iter 200 / 283], [train loss 0.19141], [train acc 0.92844]\n",
      "[epoch 61], [iter 100 / 283], [train loss 0.15052], [train acc 0.93812]\n",
      "[epoch 61], [iter 200 / 283], [train loss 0.17719], [train acc 0.93219]\n",
      "[epoch 62], [iter 100 / 283], [train loss 0.21338], [train acc 0.92375]\n",
      "[epoch 62], [iter 200 / 283], [train loss 0.20005], [train acc 0.93000]\n",
      "[epoch 63], [iter 100 / 283], [train loss 0.18808], [train acc 0.93375]\n",
      "[epoch 63], [iter 200 / 283], [train loss 0.18867], [train acc 0.93250]\n",
      "*****************************************************\n",
      "best record: [epoch 63], [val loss 0.18912], [val acc 0.93403]\n",
      "*****************************************************\n",
      "[epoch 64], [iter 100 / 283], [train loss 0.18188], [train acc 0.93812]\n",
      "[epoch 64], [iter 200 / 283], [train loss 0.19340], [train acc 0.93344]\n",
      "*****************************************************\n",
      "best record: [epoch 64], [val loss 0.19051], [val acc 0.93529]\n",
      "*****************************************************\n",
      "[epoch 65], [iter 100 / 283], [train loss 0.19485], [train acc 0.93125]\n",
      "[epoch 65], [iter 200 / 283], [train loss 0.19004], [train acc 0.93344]\n",
      "[epoch 66], [iter 100 / 283], [train loss 0.19109], [train acc 0.93375]\n",
      "[epoch 66], [iter 200 / 283], [train loss 0.19426], [train acc 0.93094]\n",
      "[epoch 67], [iter 100 / 283], [train loss 0.21794], [train acc 0.91938]\n",
      "[epoch 67], [iter 200 / 283], [train loss 0.19794], [train acc 0.92812]\n",
      "[epoch 68], [iter 100 / 283], [train loss 0.18164], [train acc 0.93563]\n",
      "[epoch 68], [iter 200 / 283], [train loss 0.18903], [train acc 0.93375]\n",
      "[epoch 69], [iter 100 / 283], [train loss 0.17716], [train acc 0.94250]\n",
      "[epoch 69], [iter 200 / 283], [train loss 0.17062], [train acc 0.94094]\n",
      "*****************************************************\n",
      "best record: [epoch 69], [val loss 0.17752], [val acc 0.93740]\n",
      "*****************************************************\n",
      "[epoch 70], [iter 100 / 283], [train loss 0.20946], [train acc 0.93250]\n",
      "[epoch 70], [iter 200 / 283], [train loss 0.18812], [train acc 0.93531]\n",
      "[epoch 71], [iter 100 / 283], [train loss 0.16963], [train acc 0.93750]\n",
      "[epoch 71], [iter 200 / 283], [train loss 0.18690], [train acc 0.93563]\n",
      "[epoch 72], [iter 100 / 283], [train loss 0.16453], [train acc 0.94250]\n",
      "[epoch 72], [iter 200 / 283], [train loss 0.17449], [train acc 0.94156]\n",
      "[epoch 73], [iter 100 / 283], [train loss 0.16071], [train acc 0.94000]\n",
      "[epoch 73], [iter 200 / 283], [train loss 0.17109], [train acc 0.93812]\n",
      "*****************************************************\n",
      "best record: [epoch 73], [val loss 0.17219], [val acc 0.93811]\n",
      "*****************************************************\n",
      "[epoch 74], [iter 100 / 283], [train loss 0.17233], [train acc 0.93688]\n",
      "[epoch 74], [iter 200 / 283], [train loss 0.19530], [train acc 0.92906]\n",
      "[epoch 75], [iter 100 / 283], [train loss 0.14741], [train acc 0.94437]\n",
      "[epoch 75], [iter 200 / 283], [train loss 0.16297], [train acc 0.94000]\n",
      "*****************************************************\n",
      "best record: [epoch 75], [val loss 0.17454], [val acc 0.93877]\n",
      "*****************************************************\n",
      "[epoch 76], [iter 100 / 283], [train loss 0.18712], [train acc 0.93125]\n",
      "[epoch 76], [iter 200 / 283], [train loss 0.16750], [train acc 0.94094]\n",
      "*****************************************************\n",
      "best record: [epoch 76], [val loss 0.16973], [val acc 0.94059]\n",
      "*****************************************************\n",
      "[epoch 77], [iter 100 / 283], [train loss 0.17819], [train acc 0.94000]\n",
      "[epoch 77], [iter 200 / 283], [train loss 0.16338], [train acc 0.94125]\n",
      "[epoch 78], [iter 100 / 283], [train loss 0.16863], [train acc 0.93250]\n",
      "[epoch 78], [iter 200 / 283], [train loss 0.17253], [train acc 0.93625]\n",
      "[epoch 79], [iter 100 / 283], [train loss 0.18169], [train acc 0.94188]\n",
      "[epoch 79], [iter 200 / 283], [train loss 0.18324], [train acc 0.93656]\n",
      "[epoch 80], [iter 100 / 283], [train loss 0.19595], [train acc 0.93563]\n",
      "[epoch 80], [iter 200 / 283], [train loss 0.19823], [train acc 0.93219]\n",
      "[epoch 81], [iter 100 / 283], [train loss 0.20522], [train acc 0.93188]\n",
      "[epoch 81], [iter 200 / 283], [train loss 0.19505], [train acc 0.93375]\n",
      "[epoch 82], [iter 100 / 283], [train loss 0.17366], [train acc 0.93312]\n",
      "[epoch 82], [iter 200 / 283], [train loss 0.17730], [train acc 0.93281]\n",
      "[epoch 83], [iter 100 / 283], [train loss 0.14866], [train acc 0.94812]\n",
      "[epoch 83], [iter 200 / 283], [train loss 0.16636], [train acc 0.93937]\n",
      "[epoch 84], [iter 100 / 283], [train loss 0.16855], [train acc 0.93750]\n",
      "[epoch 84], [iter 200 / 283], [train loss 0.18184], [train acc 0.93219]\n",
      "[epoch 85], [iter 100 / 283], [train loss 0.16767], [train acc 0.93812]\n",
      "[epoch 85], [iter 200 / 283], [train loss 0.16669], [train acc 0.94219]\n",
      "*****************************************************\n",
      "best record: [epoch 85], [val loss 0.16713], [val acc 0.94226]\n",
      "*****************************************************\n",
      "[epoch 86], [iter 100 / 283], [train loss 0.19768], [train acc 0.93125]\n",
      "[epoch 86], [iter 200 / 283], [train loss 0.18887], [train acc 0.93500]\n",
      "[epoch 87], [iter 100 / 283], [train loss 0.17401], [train acc 0.94000]\n",
      "[epoch 87], [iter 200 / 283], [train loss 0.17888], [train acc 0.93656]\n",
      "[epoch 88], [iter 100 / 283], [train loss 0.19008], [train acc 0.93312]\n",
      "[epoch 88], [iter 200 / 283], [train loss 0.19021], [train acc 0.93000]\n",
      "[epoch 89], [iter 100 / 283], [train loss 0.17158], [train acc 0.93625]\n",
      "[epoch 89], [iter 200 / 283], [train loss 0.17253], [train acc 0.93812]\n",
      "*****************************************************\n",
      "best record: [epoch 89], [val loss 0.16064], [val acc 0.94236]\n",
      "*****************************************************\n",
      "[epoch 90], [iter 100 / 283], [train loss 0.15511], [train acc 0.94750]\n",
      "[epoch 90], [iter 200 / 283], [train loss 0.17525], [train acc 0.94094]\n",
      "*****************************************************\n",
      "best record: [epoch 90], [val loss 0.16572], [val acc 0.94424]\n",
      "*****************************************************\n",
      "[epoch 91], [iter 100 / 283], [train loss 0.15894], [train acc 0.94563]\n",
      "[epoch 91], [iter 200 / 283], [train loss 0.15873], [train acc 0.94375]\n",
      "[epoch 92], [iter 100 / 283], [train loss 0.14859], [train acc 0.95125]\n",
      "[epoch 92], [iter 200 / 283], [train loss 0.16223], [train acc 0.94688]\n",
      "[epoch 93], [iter 100 / 283], [train loss 0.15726], [train acc 0.94688]\n",
      "[epoch 93], [iter 200 / 283], [train loss 0.15843], [train acc 0.94563]\n",
      "[epoch 94], [iter 100 / 283], [train loss 0.16089], [train acc 0.94125]\n",
      "[epoch 94], [iter 200 / 283], [train loss 0.15940], [train acc 0.94281]\n",
      "[epoch 95], [iter 100 / 283], [train loss 0.14370], [train acc 0.94250]\n",
      "[epoch 95], [iter 200 / 283], [train loss 0.16735], [train acc 0.94031]\n",
      "[epoch 96], [iter 100 / 283], [train loss 0.15894], [train acc 0.94125]\n",
      "[epoch 96], [iter 200 / 283], [train loss 0.15499], [train acc 0.94688]\n",
      "*****************************************************\n",
      "best record: [epoch 96], [val loss 0.15464], [val acc 0.94678]\n",
      "*****************************************************\n",
      "[epoch 97], [iter 100 / 283], [train loss 0.18139], [train acc 0.93563]\n",
      "[epoch 97], [iter 200 / 283], [train loss 0.17684], [train acc 0.93625]\n",
      "[epoch 98], [iter 100 / 283], [train loss 0.14397], [train acc 0.95063]\n",
      "[epoch 98], [iter 200 / 283], [train loss 0.15684], [train acc 0.94688]\n",
      "[epoch 99], [iter 100 / 283], [train loss 0.16384], [train acc 0.94188]\n",
      "[epoch 99], [iter 200 / 283], [train loss 0.16244], [train acc 0.94406]\n",
      "*****************************************************\n",
      "best record: [epoch 99], [val loss 0.15579], [val acc 0.94810]\n",
      "*****************************************************\n",
      "[epoch 100], [iter 100 / 283], [train loss 0.16121], [train acc 0.94250]\n",
      "[epoch 100], [iter 200 / 283], [train loss 0.15852], [train acc 0.93906]\n"
     ]
    }
   ],
   "source": [
    "lr = 2e-4 # 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "epoch_num = 100\n",
    "best_val_acc = 0.88\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_val, acc_val = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model.state_dict(), model_name+'all_data_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 100], [val loss 0.12220], [val acc 0.95551]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model_name = 'se_resnext101_32x4d' # se_resnext101_32x4d, resnext101_64x4d, nasnetlarge\n",
    "# # resnet_model = torch.hub.load('pytorch/vision:v0.5.0', model_name, pretrained=True)\n",
    "# resnet_model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")# todo : how to pretrained=False ?\n",
    "\n",
    "# resnet_model.last_linear = nn.Identity()\n",
    "\n",
    "\n",
    "# resnet_model.to(device)\n",
    "# summary(resnet_model, (3, 448, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 283], [train loss 1.11986], [train acc 0.59375]\n",
      "[epoch 1], [iter 200 / 283], [train loss 0.99001], [train acc 0.65063]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.70427], [val acc 0.74840]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [iter 100 / 283], [train loss 0.68194], [train acc 0.76500]\n",
      "[epoch 2], [iter 200 / 283], [train loss 0.67151], [train acc 0.76781]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.54760], [val acc 0.82706]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 283], [train loss 0.57196], [train acc 0.80937]\n",
      "[epoch 3], [iter 200 / 283], [train loss 0.58535], [train acc 0.80750]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.53240], [val acc 0.84075]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 283], [train loss 0.58169], [train acc 0.80375]\n",
      "[epoch 4], [iter 200 / 283], [train loss 0.55557], [train acc 0.81281]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.52764], [val acc 0.82498]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 283], [train loss 0.52630], [train acc 0.82500]\n",
      "[epoch 5], [iter 200 / 283], [train loss 0.50801], [train acc 0.82750]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.46446], [val acc 0.85972]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [iter 100 / 283], [train loss 0.48989], [train acc 0.83188]\n",
      "[epoch 6], [iter 200 / 283], [train loss 0.50288], [train acc 0.82906]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 0.43536], [val acc 0.84603]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [iter 100 / 283], [train loss 0.48422], [train acc 0.82688]\n",
      "[epoch 7], [iter 200 / 283], [train loss 0.48159], [train acc 0.82969]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 0.43254], [val acc 0.85131]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [iter 100 / 283], [train loss 0.46959], [train acc 0.83375]\n",
      "[epoch 8], [iter 200 / 283], [train loss 0.48729], [train acc 0.82906]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 0.40984], [val acc 0.85795]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [iter 100 / 283], [train loss 0.47560], [train acc 0.84125]\n",
      "[epoch 9], [iter 200 / 283], [train loss 0.46430], [train acc 0.83875]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 0.43876], [val acc 0.85611]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [iter 100 / 283], [train loss 0.43182], [train acc 0.84625]\n",
      "[epoch 10], [iter 200 / 283], [train loss 0.44796], [train acc 0.84406]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 0.40130], [val acc 0.85835]\n",
      "------------------------------------------------------------\n",
      "[epoch 11], [iter 100 / 283], [train loss 0.45823], [train acc 0.83250]\n",
      "[epoch 11], [iter 200 / 283], [train loss 0.44629], [train acc 0.84437]\n",
      "------------------------------------------------------------\n",
      "[epoch 11], [val loss 0.42561], [val acc 0.84291]\n",
      "------------------------------------------------------------\n",
      "[epoch 12], [iter 100 / 283], [train loss 0.45614], [train acc 0.83813]\n",
      "[epoch 12], [iter 200 / 283], [train loss 0.44586], [train acc 0.84469]\n",
      "------------------------------------------------------------\n",
      "[epoch 12], [val loss 0.37863], [val acc 0.86724]\n",
      "------------------------------------------------------------\n",
      "[epoch 13], [iter 100 / 283], [train loss 0.45874], [train acc 0.83750]\n",
      "[epoch 13], [iter 200 / 283], [train loss 0.46014], [train acc 0.83656]\n",
      "------------------------------------------------------------\n",
      "[epoch 13], [val loss 0.38738], [val acc 0.87372]\n",
      "------------------------------------------------------------\n",
      "[epoch 14], [iter 100 / 283], [train loss 0.39710], [train acc 0.85938]\n",
      "[epoch 14], [iter 200 / 283], [train loss 0.39700], [train acc 0.85750]\n",
      "------------------------------------------------------------\n",
      "[epoch 14], [val loss 0.43568], [val acc 0.86148]\n",
      "------------------------------------------------------------\n",
      "[epoch 15], [iter 100 / 283], [train loss 0.41805], [train acc 0.84500]\n",
      "[epoch 15], [iter 200 / 283], [train loss 0.43592], [train acc 0.84344]\n",
      "------------------------------------------------------------\n",
      "[epoch 15], [val loss 0.41402], [val acc 0.85131]\n",
      "------------------------------------------------------------\n",
      "[epoch 16], [iter 100 / 283], [train loss 0.42027], [train acc 0.85625]\n",
      "[epoch 16], [iter 200 / 283], [train loss 0.41580], [train acc 0.85250]\n",
      "------------------------------------------------------------\n",
      "[epoch 16], [val loss 0.41260], [val acc 0.86492]\n",
      "------------------------------------------------------------\n",
      "[epoch 17], [iter 100 / 283], [train loss 0.39200], [train acc 0.86562]\n",
      "[epoch 17], [iter 200 / 283], [train loss 0.39885], [train acc 0.86125]\n",
      "------------------------------------------------------------\n",
      "[epoch 17], [val loss 0.42512], [val acc 0.85651]\n",
      "------------------------------------------------------------\n",
      "[epoch 18], [iter 100 / 283], [train loss 0.37237], [train acc 0.86500]\n",
      "[epoch 18], [iter 200 / 283], [train loss 0.38192], [train acc 0.86281]\n",
      "------------------------------------------------------------\n",
      "[epoch 18], [val loss 0.38842], [val acc 0.87988]\n",
      "------------------------------------------------------------\n",
      "[epoch 19], [iter 100 / 283], [train loss 0.35416], [train acc 0.87313]\n",
      "[epoch 19], [iter 200 / 283], [train loss 0.35972], [train acc 0.86938]\n",
      "------------------------------------------------------------\n",
      "[epoch 19], [val loss 0.38627], [val acc 0.87244]\n",
      "------------------------------------------------------------\n",
      "[epoch 20], [iter 100 / 283], [train loss 0.37459], [train acc 0.86438]\n",
      "[epoch 20], [iter 200 / 283], [train loss 0.38839], [train acc 0.86187]\n",
      "------------------------------------------------------------\n",
      "[epoch 20], [val loss 0.37399], [val acc 0.87380]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'se_resnext101_32x4d' # se_resnext101_32x4d, resnext101_64x4d, nasnetlarge\n",
    "# resnet_model = torch.hub.load('pytorch/vision:v0.5.0', model_name, pretrained=True)\n",
    "resnet_model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")# todo : how to pretrained=False ?\n",
    "\n",
    "# resnet_model = torchvision.models.resnet50(pretrained=True)\n",
    "#---------------------------------------------\n",
    "\n",
    "# num_fits = resnet_model.fc.in_features\n",
    "num_fits = resnet_model.last_linear.in_features # se_resnext101_32x4d #131072\n",
    "# num_fits = resnet_model.classifier.in_features # densenet201\n",
    "num_fits\n",
    "\n",
    "\n",
    "model = Additional(resnet_model, num_fits, freeze = False)\n",
    "model = model.to(device)\n",
    "# model\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "lr = 2e-4 # 0.001\n",
    "# criterion = nn.CrossEntropyLoss(weight = x)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion2 = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "epoch_num = 20\n",
    "best_val_acc = 0.89\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model.state_dict(), model_name+'non_freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), model_name+str(best_val_acc)[:4]+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load better model\n",
    "# model.load_state_dict(torch.load('se_resnext101_32x4dnon_freeze_0.88.ckpt'))\n",
    "\n",
    "# loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, 1)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.41739], [val acc 0.87148]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time Augmentation TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/ttach\n",
      "  Cloning https://github.com/qubvel/ttach to /tmp/pip-req-build-sbeuzxxd\n",
      "  Running command git clone -q https://github.com/qubvel/ttach /tmp/pip-req-build-sbeuzxxd\n",
      "Building wheels for collected packages: ttach\n",
      "  Building wheel for ttach (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ttach: filename=ttach-0.0.2-cp37-none-any.whl size=9084 sha256=59c445b5709a5b782539247542df2cd29892b9201e848be5b7dffe53f33636b4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o1noqaun/wheels/b3/ed/f4/23b671cfba58ac389bbeb0ac6b178f34ee1840422635edd496\n",
      "Successfully built ttach\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/qubvel/ttach\n",
    "\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.36979], [val acc 0.87860]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.Rotate90(angles=[0, 180]),\n",
    "#         tta.Scale(scales=[1, 2, 4]),\n",
    "#         tta.Multiply(factors=[0.9, 1, 1.1]),        \n",
    "    ]\n",
    ")\n",
    "\n",
    "tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "\n",
    "loss_val, acc_val = validate(valid_loader, tta_model, criterion, optimizer, 5)\n",
    "\n",
    "# # #---------------------------------------------\n",
    "\n",
    "# lr = 2e-4 # 0.001\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# epoch_num = 5\n",
    "# best_val_acc = 0.88\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "#     loss_train, acc_train = train(train_loader, tta_model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(valid_loader, tta_model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "#         print('*****************************************************')\n",
    "#         print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "#         print('*****************************************************')\n",
    "        \n",
    "# # tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878601152368758"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val, acc_val = validate(train_loader, tta_model, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 100\n",
    "T2 = 700\n",
    "af = 3\n",
    "\n",
    "def alpha_weight(epoch):\n",
    "    if epoch < T1:\n",
    "        return 0.0\n",
    "    elif epoch > T2:\n",
    "        return af\n",
    "    else:\n",
    "         return ((epoch-T1) / (T2-T1))*af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def semi_superv_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(unlabeled_loader):\n",
    "            images, _ = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg\n",
    "\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(unlabeled_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "#         labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "acc_scores = []\n",
    "unlabel = []\n",
    "pseudo_label = []\n",
    "\n",
    "alpha_log = []\n",
    "test_acc_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "best_val_acc = 0.87\n",
    "\n",
    "def semisup_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "#     EPOCHS = 5\n",
    "    \n",
    "    # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
    "    # This helps the model converge faster\n",
    "    step = 100 \n",
    "    \n",
    "    model.train()\n",
    "    # for epoch in tqdm(range(EPOCHS)):\n",
    "    for epoch in range(epoch):\n",
    "\n",
    "#         for batch_idx, x_unlabeled in enumerate(unlabeled_loader):\n",
    "        for i, x_unlabeled in enumerate(unlabeled_loader):\n",
    "            \n",
    "            \n",
    "            # Forward Pass to get the pseudo labels\n",
    "            x_unlabeled = x_unlabeled[0].to(device)\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_unlabeled = model(x_unlabeled)\n",
    "                pseudo_labeled = output_unlabeled.max(1, keepdim=True)[1]\n",
    "                \n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            # Now calculate the unlabeled loss using the pseudo label\n",
    "            output = model(x_unlabeled)\n",
    "            \n",
    "            pseudo_labeled = Variable(pseudo_labeled).to(device)\n",
    "            output = Variable(output).to(device)\n",
    "            \n",
    "            unlabeled_loss = alpha_weight(step) * F.nll_loss(output, pseudo_labeled).tem()   \n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            unlabeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # For every 50 batches train one epoch on labeled data \n",
    "            if i % 50 == 0:\n",
    "                \n",
    "                # Normal training procedure\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                    \n",
    "                    X_batch = Variable(X_batch).to(device)\n",
    "                    y_batch = Variable(y_batch).to(device)\n",
    "                    \n",
    "                    output = model(X_batch)\n",
    "                    \n",
    "                    labeled_loss = F.nll_loss(output, y_batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    labeled_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Now we increment step by 1\n",
    "                step += 1\n",
    "                \n",
    "\n",
    "        loss_val, acc_va = validate(val_loader, model, criterion, optimizer, epoch) # evaluate(model, test_loader)\n",
    "        \n",
    "        print('Epoch: {} : Alpha Weight : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, alpha_weight(step), test_acc, test_loss))\n",
    "        \n",
    "        if acc_va > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "            print('*****************************************************')\n",
    "            print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "            print('*****************************************************')\n",
    "        \n",
    "#         \"\"\" LOGGING VALUES \"\"\"\n",
    "#         alpha_log.append(alpha_weight(step))\n",
    "#         test_acc_log.append(test_acc/100)\n",
    "#         test_loss_log.append(test_loss)\n",
    "#         \"\"\" ************** \"\"\"\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d667075e140c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemisup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-0efb00919e27>\u001b[0m in \u001b[0;36msemisup_train\u001b[0;34m(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0munlabeled_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpseudo_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Backpropogate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "semisup_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "acc_scores = []\n",
    "unlabel = []\n",
    "pseudo_label = []\n",
    "\n",
    "alpha_log = []\n",
    "test_acc_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "best_val_acc = 0.87\n",
    "\n",
    "def semisup_train(model, train_loader, unlabeled_loader, val_loader):\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "    EPOCHS = 5\n",
    "    \n",
    "    # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
    "    # This helps the model converge faster\n",
    "    step = 100 \n",
    "    \n",
    "    model.train()\n",
    "    # for epoch in tqdm(range(EPOCHS)):\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        for batch_idx, x_unlabeled in enumerate(unlabeled_loader):\n",
    "            \n",
    "            \n",
    "            # Forward Pass to get the pseudo labels\n",
    "            x_unlabeled = x_unlabeled[0].to(device)\n",
    "            model.eval()\n",
    "            output_unlabeled = model(x_unlabeled)\n",
    "            _, pseudo_labeled = torch.max(output_unlabeled, 1)\n",
    "            model.train()\n",
    "            \n",
    "            \n",
    "            \"\"\" ONLY FOR VISUALIZATION\"\"\"\n",
    "            if (batch_idx < 3) and (epoch % 10 == 0):\n",
    "                unlabel.append(x_unlabeled.cpu())\n",
    "                pseudo_label.append(pseudo_labeled.cpu())\n",
    "            \"\"\" ********************** \"\"\"\n",
    "            \n",
    "            # Now calculate the unlabeled loss using the pseudo label\n",
    "            output = model(x_unlabeled)\n",
    "            unlabeled_loss = alpha_weight(step) * criterion(output, pseudo_labeled)   \n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            unlabeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # For every 2 batches train one epoch on labeled data \n",
    "            if batch_idx % 2 == 0:\n",
    "                \n",
    "                # Normal training procedure\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    output = model(X_batch)\n",
    "                    labeled_loss = criterion(output, y_batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    labeled_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Now we increment step by 1\n",
    "                step += 1\n",
    "                \n",
    "\n",
    "        loss_val, acc_va = validate(val_loader, model, criterion, optimizer, epoch) # evaluate(model, test_loader)\n",
    "        \n",
    "        print('Epoch: {} : Alpha Weight : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, alpha_weight(step), test_acc, test_loss))\n",
    "        \n",
    "        if acc_va > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "            print('*****************************************************')\n",
    "            print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "            print('*****************************************************')\n",
    "        \n",
    "        \"\"\" LOGGING VALUES \"\"\"\n",
    "        alpha_log.append(alpha_weight(step))\n",
    "        test_acc_log.append(test_acc/100)\n",
    "        test_loss_log.append(test_loss)\n",
    "        \"\"\" ************** \"\"\"\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-01defd85d8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemisup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-a491da97dee4>\u001b[0m in \u001b[0;36msemisup_train\u001b[0;34m(model, train_loader, unlabeled_loader, val_loader)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# Normal training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-80f85865b2ef>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         return im.view(3, 448, 448), classCategory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, resample, expand, center, fill)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2297\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"missing method data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMESH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0;31m# list of quads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2505\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "semisup_train(model, train_loader, unlabeled_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,label in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmd', 'healthy', 'cbsd', 'cbb', 'cgm']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_loader.dataset.classes # {0:'cbsd', 1: 'cgm', 2: 'cbb', 3: 'healthy', 4: 'cmd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_dir):\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # tensor.numpy().transpose(1, 2, 0)\n",
    "    image = Image.open(image_dir)\n",
    "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "    image = preprocess(image)\n",
    "    # Convert 2D image to 1D vector\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.from_numpy(image)\n",
    "    inputs = image.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the label\n",
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model(image)\n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"./data/test/test/0\"\n",
    "predictions, test_image_fileName = [], []\n",
    "try:\n",
    "    test_images = listdir(test_directory)\n",
    "    for images in test_images:\n",
    "        test_image_fileName.append(images)\n",
    "        image = process_image(f'{test_directory}/{images}')\n",
    "        top_prob, top_class = predict(image, model)\n",
    "        predictions.append(class_names[top_class])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Creating pandas dataframe\")\n",
    "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
    "submission_data_frame = pd.DataFrame(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-1551.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-311.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-600.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-1092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>healthy</td>\n",
       "      <td>test-img-156.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                 Id\n",
       "0      cmd  test-img-1551.jpg\n",
       "1      cmd   test-img-311.jpg\n",
       "2     cbsd   test-img-600.jpg\n",
       "3      cmd  test-img-1092.jpg\n",
       "4  healthy   test-img-156.jpg"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-2547.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-1415.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-2683.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbb</td>\n",
       "      <td>test-img-683.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-3585.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                 Id\n",
       "0     cbsd  test-img-2547.jpg\n",
       "1     cbsd  test-img-1415.jpg\n",
       "2     cbsd  test-img-2683.jpg\n",
       "3      cbb   test-img-683.jpg\n",
       "4      cmd  test-img-3585.jpg"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_frame.to_csv('submission'+model_name+'_91_oversampling.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
