{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretrainedmodels in /opt/anaconda3/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.7/site-packages (from pretrainedmodels) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.7/site-packages (from pretrainedmodels) (0.5.0)\n",
      "Requirement already satisfied: munch in /opt/anaconda3/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from pretrainedmodels) (4.42.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (1.18.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/anaconda3/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (6.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n",
      "Torchvision Version:  0.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import pretrainedmodels\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cbsd:1443\n",
      "cgm:773\n",
      "cbb:466\n",
      "healthy:316\n",
      "cmd:2658\n",
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Train set:')\n",
    "for cls in os.listdir('./data/train/train'):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join('./data/train/train', cls)))))\n",
    "im = Image.open('./data/train/train/cgm/train-cgm-738.jpg')\n",
    "print(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train/train\"\n",
    "test_path = \"./data/test/test\"\n",
    "extraimage_path = \"./data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.4543, 0.5137, 0.3240]\n",
    "std=[0.1949, 0.1977, 0.1661]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224), #448, 299, 224\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "test_transforms = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "\n",
    "# normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        print(class_names)\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "# #         return im.view(3, 448, 448), classCategory\n",
    "        return im.view(3, 224, 224), classCategory\n",
    "# #         return im.view(3, 299, 299), classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-cbsd': 1443, '1-cgm': 773, '2-cbb': 466, '3-healthy': 316, '4-cmd': 2658}\n",
      "{'0-0': 3774}\n",
      "{'0-0': 12595, '1-.ipynb_checkpoints': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) #maybe need an other trasforms, I had to change the dataset structure :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = 0.1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=16,\n",
    "                                             sampler=valid_sampler)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=8) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1) # make batch = 1 here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4, 4, 0, 0, 2, 2, 2, 4, 1, 2, 4, 4, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "for data,label in valid_loader:\n",
    "    print(label)\n",
    "    break\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(unlabeled_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(labels)\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "matplotlib_imshow(img_grid, one_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Additional(nn.Module):\n",
    "    def __init__(self, modelA,in_features,nb_classes=5, freeze = False):\n",
    "        super(Additional, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        # Remove last linear layer\n",
    "#         self.modelA.fc = nn.Identity() # for resnet\n",
    "        self.modelA.last_linear = nn.Identity() #for re_renext\n",
    "#         self.modelA.classifier = nn.Identity()    # densenet201\n",
    "        for p in self.modelA.parameters():\n",
    "            if freeze:\n",
    "                p.requires_grad = False\n",
    "            else :\n",
    "                p.requires_grad = True\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.fc_1 = nn.Linear(in_features,256)\n",
    "        self.fc_2 = nn.Linear(256,  512)\n",
    "        self.fc_out = nn.Linear( 512, nb_classes)\n",
    "        \n",
    "        #Dropout\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #model\n",
    "        x = self.modelA(x.clone())  \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        #FC\n",
    "        x  = self.dropout(self.fc_1(F.relu(x)))\n",
    "        x = self.dropout(self.fc_2(F.relu(x)))\n",
    "        x = self.fc_out(F.relu(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipdb\n",
    "# {'0-cbsd': 1443, '1-cgm': 773, '2-cbb': 466, '3-healthy': 316, '4-cmd': 2658}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    _class_labels = np.array(['cbsd','cgm','cbb','healthy','cmd'])\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, _ = data\n",
    "            images = Variable(images).to(device)\n",
    "    \n",
    "            outputs = model(images)\n",
    "    \n",
    "            prediction = outputs.data.cpu().numpy().argmax()\n",
    "            \n",
    "            _predicted_class_labels = _class_labels[prediction]\n",
    "            \n",
    "            pred.append(_predicted_class_labels)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")\n",
    "# resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'se_resnext101_32x4d' # se_resnext101_32x4d, resnext101_64x4d\n",
    "# resnet_model = torch.hub.load('pytorch/vision:v0.5.0', model_name, pretrained=True)\n",
    "resnet_model = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")# todo : how to pretrained=False ?\n",
    "\n",
    "# resnet_model = torchvision.models.resnet50(pretrained=True)\n",
    "#---------------------------------------------\n",
    "\n",
    "# num_fits = resnet_model.fc.in_features\n",
    "num_fits = resnet_model.last_linear.in_features # se_resnext101_32x4d\n",
    "# num_fits = resnet_model.classifier.in_features # densenet201\n",
    "num_fits\n",
    "\n",
    "\n",
    "model = Additional(resnet_model, num_fits, freeze = False)\n",
    "model = model.to(device)\n",
    "model\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "lr = 2e-4 # 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# epoch_num = 5\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(train_loader, model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "#         print('*****************************************************')\n",
    "#         print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "#         print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Additional(\n",
       "  (modelA): SENet(\n",
       "    (layer0): Sequential(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (7): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (8): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (9): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (10): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (11): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (12): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (13): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (14): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (15): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (16): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (17): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (18): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (19): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (20): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (21): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (22): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (last_linear): Identity()\n",
       "  )\n",
       "  (fc_1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc_out): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load better model\n",
    "model.load_state_dict(torch.load('se_resnext101_32x4dfreeze_0.86.ckpt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 100\n",
    "T2 = 700\n",
    "af = 3\n",
    "\n",
    "def alpha_weight(epoch):\n",
    "    if epoch < T1:\n",
    "        return 0.0\n",
    "    elif epoch > T2:\n",
    "        return af\n",
    "    else:\n",
    "         return ((epoch-T1) / (T2-T1))*af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def semi_superv_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(unlabeled_loader):\n",
    "            images, _ = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg\n",
    "\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(unlabeled_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "#         labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "acc_scores = []\n",
    "unlabel = []\n",
    "pseudo_label = []\n",
    "\n",
    "alpha_log = []\n",
    "test_acc_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "best_val_acc = 0.87\n",
    "\n",
    "def semisup_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "#     EPOCHS = 5\n",
    "    \n",
    "    # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
    "    # This helps the model converge faster\n",
    "    step = 100 \n",
    "    \n",
    "    model.train()\n",
    "    # for epoch in tqdm(range(EPOCHS)):\n",
    "    for epoch in range(epoch):\n",
    "\n",
    "#         for batch_idx, x_unlabeled in enumerate(unlabeled_loader):\n",
    "        for i, x_unlabeled in enumerate(unlabeled_loader):\n",
    "            \n",
    "            \n",
    "            # Forward Pass to get the pseudo labels\n",
    "            x_unlabeled = x_unlabeled[0].to(device)\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_unlabeled = model(x_unlabeled)\n",
    "                pseudo_labeled = output_unlabeled.max(1, keepdim=True)[1]\n",
    "                \n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            # Now calculate the unlabeled loss using the pseudo label\n",
    "            output = model(x_unlabeled)\n",
    "            \n",
    "            pseudo_labeled = Variable(pseudo_labeled).to(device)\n",
    "            output = Variable(output).to(device)\n",
    "            \n",
    "            unlabeled_loss = alpha_weight(step) * F.nll_loss(output, pseudo_labeled).tem()   \n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            unlabeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # For every 50 batches train one epoch on labeled data \n",
    "            if i % 50 == 0:\n",
    "                \n",
    "                # Normal training procedure\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                    \n",
    "                    X_batch = Variable(X_batch).to(device)\n",
    "                    y_batch = Variable(y_batch).to(device)\n",
    "                    \n",
    "                    output = model(X_batch)\n",
    "                    \n",
    "                    labeled_loss = F.nll_loss(output, y_batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    labeled_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Now we increment step by 1\n",
    "                step += 1\n",
    "                \n",
    "\n",
    "        loss_val, acc_va = validate(val_loader, model, criterion, optimizer, epoch) # evaluate(model, test_loader)\n",
    "        \n",
    "        print('Epoch: {} : Alpha Weight : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, alpha_weight(step), test_acc, test_loss))\n",
    "        \n",
    "        if acc_va > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "            print('*****************************************************')\n",
    "            print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "            print('*****************************************************')\n",
    "        \n",
    "#         \"\"\" LOGGING VALUES \"\"\"\n",
    "#         alpha_log.append(alpha_weight(step))\n",
    "#         test_acc_log.append(test_acc/100)\n",
    "#         test_loss_log.append(test_loss)\n",
    "#         \"\"\" ************** \"\"\"\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d667075e140c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemisup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-0efb00919e27>\u001b[0m in \u001b[0;36msemisup_train\u001b[0;34m(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0munlabeled_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpseudo_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Backpropogate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "semisup_train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept from : https://github.com/peimengsui/semi_supervised_mnist\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "acc_scores = []\n",
    "unlabel = []\n",
    "pseudo_label = []\n",
    "\n",
    "alpha_log = []\n",
    "test_acc_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "best_val_acc = 0.87\n",
    "\n",
    "def semisup_train(model, train_loader, unlabeled_loader, val_loader):\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "    EPOCHS = 5\n",
    "    \n",
    "    # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
    "    # This helps the model converge faster\n",
    "    step = 100 \n",
    "    \n",
    "    model.train()\n",
    "    # for epoch in tqdm(range(EPOCHS)):\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        for batch_idx, x_unlabeled in enumerate(unlabeled_loader):\n",
    "            \n",
    "            \n",
    "            # Forward Pass to get the pseudo labels\n",
    "            x_unlabeled = x_unlabeled[0].to(device)\n",
    "            model.eval()\n",
    "            output_unlabeled = model(x_unlabeled)\n",
    "            _, pseudo_labeled = torch.max(output_unlabeled, 1)\n",
    "            model.train()\n",
    "            \n",
    "            \n",
    "            \"\"\" ONLY FOR VISUALIZATION\"\"\"\n",
    "            if (batch_idx < 3) and (epoch % 10 == 0):\n",
    "                unlabel.append(x_unlabeled.cpu())\n",
    "                pseudo_label.append(pseudo_labeled.cpu())\n",
    "            \"\"\" ********************** \"\"\"\n",
    "            \n",
    "            # Now calculate the unlabeled loss using the pseudo label\n",
    "            output = model(x_unlabeled)\n",
    "            unlabeled_loss = alpha_weight(step) * criterion(output, pseudo_labeled)   \n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            unlabeled_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # For every 2 batches train one epoch on labeled data \n",
    "            if batch_idx % 2 == 0:\n",
    "                \n",
    "                # Normal training procedure\n",
    "                for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    output = model(X_batch)\n",
    "                    labeled_loss = criterion(output, y_batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    labeled_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Now we increment step by 1\n",
    "                step += 1\n",
    "                \n",
    "\n",
    "        loss_val, acc_va = validate(val_loader, model, criterion, optimizer, epoch) # evaluate(model, test_loader)\n",
    "        \n",
    "        print('Epoch: {} : Alpha Weight : {:.5f} | Test Acc : {:.5f} | Test Loss : {:.3f} '.format(epoch, alpha_weight(step), test_acc, test_loss))\n",
    "        \n",
    "        if acc_va > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
    "            print('*****************************************************')\n",
    "            print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "            print('*****************************************************')\n",
    "        \n",
    "        \"\"\" LOGGING VALUES \"\"\"\n",
    "        alpha_log.append(alpha_weight(step))\n",
    "        test_acc_log.append(test_acc/100)\n",
    "        test_loss_log.append(test_loss)\n",
    "        \"\"\" ************** \"\"\"\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-01defd85d8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemisup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-a491da97dee4>\u001b[0m in \u001b[0;36msemisup_train\u001b[0;34m(model, train_loader, unlabeled_loader, val_loader)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# Normal training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-80f85865b2ef>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         return im.view(3, 448, 448), classCategory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, resample, expand, center, fill)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2297\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"missing method data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMESH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0;31m# list of quads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2505\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "semisup_train(model, train_loader, unlabeled_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, unlabeled_loader, valid_loader, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,label in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0:'cbsd', 1: 'cgm', 2: 'cbb', 3: 'healthy', 4: 'cmd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_dir):\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # tensor.numpy().transpose(1, 2, 0)\n",
    "    image = Image.open(image_dir)\n",
    "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "    image = preprocess(image)\n",
    "    # Convert 2D image to 1D vector\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.from_numpy(image)\n",
    "    inputs = image.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the label\n",
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model(image)\n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"./data/test/test/0\"\n",
    "predictions, test_image_fileName = [], []\n",
    "try:\n",
    "    test_images = listdir(test_directory)\n",
    "    for images in test_images:\n",
    "        test_image_fileName.append(images)\n",
    "        image = process_image(f'{test_directory}/{images}')\n",
    "        top_prob, top_class = predict(image, model)\n",
    "        predictions.append(class_names[top_class])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Creating pandas dataframe\")\n",
    "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
    "submission_data_frame = pd.DataFrame(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-2547.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-1415.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbsd</td>\n",
       "      <td>test-img-2683.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbb</td>\n",
       "      <td>test-img-683.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-3585.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                 Id\n",
       "0     cbsd  test-img-2547.jpg\n",
       "1     cbsd  test-img-1415.jpg\n",
       "2     cbsd  test-img-2683.jpg\n",
       "3      cbb   test-img-683.jpg\n",
       "4      cmd  test-img-3585.jpg"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_frame.to_csv('submission'+model_name+'_freeze_86_flip.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
