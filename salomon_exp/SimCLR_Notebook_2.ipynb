{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF8ZoVrwt0n0"
   },
   "source": [
    "# SimCLR\n",
    "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
    "\n",
    "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt6WMxjCvN3o"
   },
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels\n",
    "\n",
    "# !git clone https://github.com/spijkervet/SimCLR.git\n",
    "# %cd SimCLR\n",
    "# !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "53JMIYtat8tT",
    "outputId": "82df4c10-ad67-4917-8963-43ee477f666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/cassava_disease_classification/salomon_exp/SimCLR-1\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/Kabongosalomon/SimCLR-1.git\n",
    "%cd SimCLR-1\n",
    "# !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "\n",
    "# from experiment import ex\n",
    "from model import load_model\n",
    "from utils import post_config_hook\n",
    "\n",
    "from modules import LogisticRegression\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQ3jq3cWynLf"
   },
   "source": [
    "# Part 1:\n",
    "## SimCLR pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jhAv3hv8IHn"
   },
   "outputs": [],
   "source": [
    "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
    "use_tpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwW10d2O7pn8"
   },
   "source": [
    "#### Install PyTorch/XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj84aiC27oxS"
   },
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNDRcPbbymlX",
    "outputId": "383ea8ab-6aaf-40fd-8e59-57ee443371ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if use_tpu:\n",
    "    # imports the torch_xla package for TPU support\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    dev = xm.xla_device()\n",
    "    print(dev)\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "from model import load_model, save_model\n",
    "from modules import NT_Xent\n",
    "from modules.transformations import TransformsSimCLR\n",
    "from utils import post_config_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYbV0fa_y03Z"
   },
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klUf-IuyxdL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args.out_dir = \"logs\"\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "O86__UhA0Lvr",
    "outputId": "295583f8-ba5b-488e-ac1a-58015273bb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "args.batch_size = 64\n",
    "args.resnet = \"resnet18\" # se_resnet50, resnet18, se_resnext101_32x4d, resnet50\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'casava'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.epochs = 100\n",
    "# args.epoch_num = 100\n",
    "\n",
    "# args.projection_dim = 64\n",
    "\n",
    "# args.logistic_epochs = 100\n",
    "\n",
    "# args.optimizer = \"LARS\" #\"Adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJfeOM9PzNoF"
   },
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/train/train\"\n",
    "test_path = \"../data/test/test\"\n",
    "extraimage_path = \"../data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cbb:466\n",
      "healthy:316\n",
      "cbsd:1443\n",
      "cmd:2658\n",
      "cgm:773\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cbb': 466, 'cbsd': 1443, 'cgm': 773, 'cmd': 2658, 'healthy': 316}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, size, s=1, mutation = False):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.mutation = mutation\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        \n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((size, size)),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        image = Image.open(fileName)\n",
    "\n",
    "        if self.mutation:\n",
    "            image1 = self.train_transform(image)\n",
    "            image2 = self.train_transform(image)\n",
    "            \n",
    "            sample = [[image1, image2], classCategory]\n",
    "        else:\n",
    "            \n",
    "            image = self.test_transform(image)\n",
    "            sample = [image, classCategory]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 448\n",
    "\n",
    "train_data = CassavaDataset(data_path, size, s=1, mutation = False)\n",
    "\n",
    "test_data = CassavaDataset(test_path, size, s=1, mutation = False)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, size, s=1, mutation = True)\n",
    "\n",
    "#######################################################################\n",
    "validation_split = 0.0\n",
    "shuffle_dataset = True\n",
    "# random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "########################################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size_train = args.batch_size# 125\n",
    "batch_size_eval = args.batch_size#250\n",
    "n_workers = 2\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "#                                              sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "# valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_eval,\n",
    "#                                              sampler = valid_sampler, num_workers = n_workers)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size = batch_size_eval, \n",
    "                                              shuffle =shuffle_dataset, num_workers = n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of subprocesses to use for data loading\n",
    "# num_workers = 6\n",
    "# # how many samples per batch to load\n",
    "# batch_size = 125\n",
    "\n",
    "# train_data = datasets.ImageFolder(data_path, transform=train_transforms)\n",
    "# test_data = datasets.ImageFolder(test_path, transform=test_transforms)\n",
    "# extraimage_data = datasets.ImageFolder(extraimage_path, transform=train_transforms)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "#                                            num_workers=num_workers, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "#                                           num_workers=num_workers)\n",
    "\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=batch_size,\n",
    "#                                                num_workers=num_workers) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(unlabeled_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(next(unlabeled_loader.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e100213220094b8cbf3e9578bc3a1554",
      "8ecfd2a00a874c6cacacbe39ab3f87cc",
      "e3834039bcc6436489e4b5fc04fb4664",
      "554f93f21a4344ada4a1e7c74fe386b7",
      "6f1d2aed682f44f98524873f26408de6",
      "5bb79baa5d7b4c81896e083f9543b33c",
      "56b658779c7745a885cde6850fae178f",
      "1f62ac17ac704e108fa3ea5f52a9ea8d"
     ]
    },
    "colab_type": "code",
    "id": "YGcskdBsytbj",
    "outputId": "48f0c2a3-9800-4c52-cb8a-071e119c5d0d"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "\n",
    "# train_sampler = None\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"unlabeled\", download=True, transform=TransformsSimCLR(size=96)\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, download=True, transform=TransformsSimCLR(size=32)\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.batch_size,\n",
    "#     shuffle=(train_sampler is None),\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "#     sampler=train_sampler,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBlXZwvjzPmp"
   },
   "source": [
    "### Load the SimCLR model, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataset': 'casava',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.projection_dim = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xERq_yHSzJRX"
   },
   "outputs": [],
   "source": [
    "model, optimizer, scheduler = load_model(args, unlabeled_loader, reload_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyJ3ulWqzViL"
   },
   "source": [
    "### Setup TensorBoard for logging experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZNieMqfzU7H"
   },
   "outputs": [],
   "source": [
    "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "writer = SummaryWriter(log_dir=tb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xpl6uQiIzbvK"
   },
   "source": [
    "### Create the mask that will remove correlated samples from the negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtNCVEynzjtV"
   },
   "source": [
    "### Initialize the criterion (NT-Xent loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u067AY93zh-k"
   },
   "outputs": [],
   "source": [
    "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NT_Xent(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (similarity_f): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN5KBK-yztGD"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer):\n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "\n",
    "        if x_i.shape[0] != args.batch_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.to(args.device)\n",
    "        x_j = x_j.to(args.device)\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        h_i, z_i = model(x_i)\n",
    "        h_j, z_j = model(x_j)\n",
    "\n",
    "#         ipdb.set_trace()\n",
    "        loss = criterion(z_i, z_j)\n",
    "\n",
    "        if apex and args.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        loss_epoch += loss.item()\n",
    "        args.global_step += 1\n",
    "\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/197]\t Loss: 4.825965881347656\n",
      "Step [50/197]\t Loss: 4.679616451263428\n",
      "Step [100/197]\t Loss: 4.63761043548584\n",
      "Step [150/197]\t Loss: 4.709129333496094\n",
      "Epoch [0/100]\t Loss: 4.6434118445149535\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 4.479612827301025\n",
      "Step [50/197]\t Loss: 4.378774166107178\n",
      "Step [100/197]\t Loss: 4.248110294342041\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        \n",
    "        args.global_step = 0\n",
    "        args.current_epoch = 0\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        #     ipdb.set_trace()\n",
    "            loss_epoch = train(args, unlabeled_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                save_model(args, model, optimizer)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(unlabeled_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(unlabeled_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "        ## end training\n",
    "        save_model(args, model, optimizer)\n",
    "    except:\n",
    "        extype, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb, traceback, sys\n",
    "\n",
    "# def bombs():\n",
    "#     a = []\n",
    "#     print (a[0])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     try:\n",
    "#         bombs()\n",
    "#     except:\n",
    "#         extype, value, tb = sys.exc_info()\n",
    "#         traceback.print_exc()\n",
    "#         pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77BXUR9_4hNc"
   },
   "source": [
    "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7eHATk04Sgu"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download('./logs/checkpoint_'+args.epochs.tar) # checkpoint_100.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAQpjiuJy61N"
   },
   "source": [
    "# Part 2:\n",
    "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24wrzMP2vYcV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFyS9RvpuCuC"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZRtPBCLvgqz"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skBYAPb2uKB5"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "OJk4-nc-vkF0",
    "outputId": "403ed12f-844f-4a05-e0db-cc5ffca627d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "# from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "# config = yaml_config_hook(\"./config/config.yaml\")\n",
    "# pprint(config)\n",
    "# args = argparse.Namespace(**config)\n",
    "\n",
    "# if use_tpu:\n",
    "#     args.device = dev\n",
    "# else:\n",
    "#     args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7cSwhu55KJc"
   },
   "outputs": [],
   "source": [
    "# args.batch_size = 32\n",
    "# args.resnet = \"se_resnext101_32x4d\" # \n",
    "# args.model_path = \"logs\"\n",
    "# args.epoch_num = 20 # 100\n",
    "# args.projection_dim = 32\n",
    "\n",
    "# args.logistic_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWRuVrZZ5Vm1"
   },
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iPGuFjLW5PF9",
    "outputId": "42131d22-129f-4d12-efaf-b01c29d78588"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=True, download=True, transform=transform\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=False, download=True, transform=transform\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load SimCLR model and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_eval,\n",
    "                                             sampler = valid_sampler, num_workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RTVnvx2a5QnX",
    "outputId": "380865bd-d974-45c4-cf81-956366ddf0f2"
   },
   "outputs": [],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZoABGRr5Q8_"
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = 5 # stl-10\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T694n_HQ5Tad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.91\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "    if accuracy_epoch / len(train_loader) > best_acc :  \n",
    "        print(f\"Model {train_loader}_{accuracy_epoch / len(train_loader)} saved\")\n",
    "        save_model(args, simclr_model, optimizer)\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(valid_loader)}\\t Accuracy: {accuracy_epoch / len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL]\t Loss: 1.3014336422913604\t Accuracy: 0.8099747474747475\n"
     ]
    }
   ],
   "source": [
    "oss_epoch, accuracy_epoch = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(valid_loader)}\\t Accuracy: {accuracy_epoch / len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL]\t Loss: 2.2546271115541456\t Accuracy: 0.7482666666666666\n"
     ]
    }
   ],
   "source": [
    "oss_epoch, accuracy_epoch = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(valid_loader)}\\t Accuracy: {accuracy_epoch / len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vLaebM9Qvztx",
    "outputId": "17fd9ef1-5154-41f5-e8f0-0959e0f82f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/37]\t Loss: 1.8033009767532349\t Accuracy: 0.136\n",
      "Epoch [0/500]\t Loss: 1.3058979640135895\t Accuracy: 0.5074594594594597\n",
      "Step [0/37]\t Loss: 1.1310392618179321\t Accuracy: 0.56\n",
      "Epoch [1/500]\t Loss: 1.1025966373649803\t Accuracy: 0.5943783783783785\n",
      "Step [0/37]\t Loss: 1.1083776950836182\t Accuracy: 0.608\n",
      "Epoch [2/500]\t Loss: 1.0608275178316477\t Accuracy: 0.6023783783783784\n",
      "Step [0/37]\t Loss: 0.9856696724891663\t Accuracy: 0.672\n",
      "Epoch [3/500]\t Loss: 1.0526621744439408\t Accuracy: 0.6019459459459459\n",
      "Step [0/37]\t Loss: 1.1596343517303467\t Accuracy: 0.56\n",
      "Epoch [4/500]\t Loss: 1.0424807184451335\t Accuracy: 0.6056216216216217\n",
      "Step [0/37]\t Loss: 1.0736558437347412\t Accuracy: 0.576\n",
      "Epoch [5/500]\t Loss: 1.0309529691129118\t Accuracy: 0.6099459459459459\n",
      "Step [0/37]\t Loss: 1.16108238697052\t Accuracy: 0.544\n",
      "Epoch [6/500]\t Loss: 1.0287092763024408\t Accuracy: 0.6116756756756757\n",
      "Step [0/37]\t Loss: 0.9434301853179932\t Accuracy: 0.688\n",
      "Epoch [7/500]\t Loss: 1.0198058888718888\t Accuracy: 0.6147027027027027\n",
      "Step [0/37]\t Loss: 1.113943099975586\t Accuracy: 0.552\n",
      "Epoch [8/500]\t Loss: 1.0225735532270896\t Accuracy: 0.6101621621621621\n",
      "Step [0/37]\t Loss: 1.0189629793167114\t Accuracy: 0.6\n",
      "Epoch [9/500]\t Loss: 1.0173781030886881\t Accuracy: 0.6142702702702704\n",
      "Step [0/37]\t Loss: 1.0884902477264404\t Accuracy: 0.536\n",
      "Epoch [10/500]\t Loss: 1.0238684464145351\t Accuracy: 0.6114594594594596\n",
      "Step [0/37]\t Loss: 1.0873640775680542\t Accuracy: 0.6\n",
      "Epoch [11/500]\t Loss: 1.0141767488943565\t Accuracy: 0.612972972972973\n",
      "Step [0/37]\t Loss: 1.033854365348816\t Accuracy: 0.64\n",
      "Epoch [12/500]\t Loss: 1.008228297169144\t Accuracy: 0.6229189189189188\n",
      "Step [0/37]\t Loss: 0.9485524296760559\t Accuracy: 0.648\n",
      "Epoch [13/500]\t Loss: 1.012501690838788\t Accuracy: 0.616\n",
      "Step [0/37]\t Loss: 1.1229203939437866\t Accuracy: 0.608\n",
      "Epoch [14/500]\t Loss: 1.011778104949642\t Accuracy: 0.6116756756756757\n",
      "Step [0/37]\t Loss: 0.9500762224197388\t Accuracy: 0.672\n",
      "Epoch [15/500]\t Loss: 1.0029996681857754\t Accuracy: 0.6214054054054055\n",
      "Step [0/37]\t Loss: 0.9587697386741638\t Accuracy: 0.648\n",
      "Epoch [16/500]\t Loss: 1.0014339411580884\t Accuracy: 0.6201081081081081\n",
      "Step [0/37]\t Loss: 0.9559009671211243\t Accuracy: 0.68\n",
      "Epoch [17/500]\t Loss: 1.0083174367208738\t Accuracy: 0.6183783783783784\n",
      "Step [0/37]\t Loss: 1.1889280080795288\t Accuracy: 0.552\n",
      "Epoch [18/500]\t Loss: 1.0010022537128345\t Accuracy: 0.6194594594594595\n",
      "Step [0/37]\t Loss: 1.0365569591522217\t Accuracy: 0.624\n",
      "Epoch [19/500]\t Loss: 0.9979361182934529\t Accuracy: 0.6261621621621621\n",
      "Step [0/37]\t Loss: 1.013893961906433\t Accuracy: 0.648\n",
      "Epoch [20/500]\t Loss: 0.9931009814545915\t Accuracy: 0.6220540540540539\n",
      "Step [0/37]\t Loss: 1.1179018020629883\t Accuracy: 0.616\n",
      "Epoch [21/500]\t Loss: 0.9930059426539654\t Accuracy: 0.6218378378378379\n",
      "Step [0/37]\t Loss: 1.015285849571228\t Accuracy: 0.6\n",
      "Epoch [22/500]\t Loss: 1.0047405507113483\t Accuracy: 0.6224864864864865\n",
      "Step [0/37]\t Loss: 0.9152193069458008\t Accuracy: 0.672\n",
      "Epoch [23/500]\t Loss: 0.9946665779964344\t Accuracy: 0.6252972972972973\n",
      "Step [0/37]\t Loss: 1.115788459777832\t Accuracy: 0.584\n",
      "Epoch [24/500]\t Loss: 0.9997544755806794\t Accuracy: 0.619891891891892\n",
      "Step [0/37]\t Loss: 0.9976512789726257\t Accuracy: 0.608\n",
      "Epoch [25/500]\t Loss: 0.9928673473564354\t Accuracy: 0.6257297297297297\n",
      "Step [0/37]\t Loss: 0.9223300814628601\t Accuracy: 0.68\n",
      "Epoch [26/500]\t Loss: 0.9976288740699356\t Accuracy: 0.6214054054054055\n",
      "Step [0/37]\t Loss: 0.9461998343467712\t Accuracy: 0.656\n",
      "Epoch [27/500]\t Loss: 0.9956010032344509\t Accuracy: 0.6211891891891892\n",
      "Step [0/37]\t Loss: 1.0611393451690674\t Accuracy: 0.576\n",
      "Epoch [28/500]\t Loss: 0.9861307160274403\t Accuracy: 0.6276756756756757\n",
      "Step [0/37]\t Loss: 1.0447298288345337\t Accuracy: 0.584\n",
      "Epoch [29/500]\t Loss: 0.9891293886545542\t Accuracy: 0.628108108108108\n",
      "Step [0/37]\t Loss: 1.0635769367218018\t Accuracy: 0.6\n",
      "Epoch [30/500]\t Loss: 0.9943820109238496\t Accuracy: 0.6235675675675676\n",
      "Step [0/37]\t Loss: 1.1241897344589233\t Accuracy: 0.584\n",
      "Epoch [31/500]\t Loss: 0.9889136891107302\t Accuracy: 0.6255135135135134\n",
      "Step [0/37]\t Loss: 0.8885579705238342\t Accuracy: 0.672\n",
      "Epoch [32/500]\t Loss: 0.9877686903283402\t Accuracy: 0.624864864864865\n",
      "Step [0/37]\t Loss: 0.9491863250732422\t Accuracy: 0.656\n",
      "Epoch [33/500]\t Loss: 0.9808122612334587\t Accuracy: 0.6302702702702703\n",
      "Step [0/37]\t Loss: 0.9717525243759155\t Accuracy: 0.64\n",
      "Epoch [34/500]\t Loss: 0.9800167293161959\t Accuracy: 0.6296216216216217\n",
      "Step [0/37]\t Loss: 0.9412503838539124\t Accuracy: 0.656\n",
      "Epoch [35/500]\t Loss: 0.978393591739036\t Accuracy: 0.6324324324324325\n",
      "Step [0/37]\t Loss: 0.8845765590667725\t Accuracy: 0.648\n",
      "Epoch [36/500]\t Loss: 0.9832291538650925\t Accuracy: 0.6255135135135135\n",
      "Step [0/37]\t Loss: 1.1710538864135742\t Accuracy: 0.48\n",
      "Epoch [37/500]\t Loss: 0.9889631947955569\t Accuracy: 0.6233513513513514\n",
      "Step [0/37]\t Loss: 0.9217975735664368\t Accuracy: 0.656\n",
      "Epoch [38/500]\t Loss: 0.9858019754693315\t Accuracy: 0.6263783783783785\n",
      "Step [0/37]\t Loss: 1.0927571058273315\t Accuracy: 0.608\n",
      "Epoch [39/500]\t Loss: 0.9774902028006476\t Accuracy: 0.6311351351351352\n",
      "Step [0/37]\t Loss: 1.013459324836731\t Accuracy: 0.648\n",
      "Epoch [40/500]\t Loss: 0.9844006364409988\t Accuracy: 0.6259459459459459\n",
      "Step [0/37]\t Loss: 0.96531081199646\t Accuracy: 0.624\n",
      "Epoch [41/500]\t Loss: 0.9799570795652028\t Accuracy: 0.6300540540540539\n",
      "Step [0/37]\t Loss: 0.9787879586219788\t Accuracy: 0.648\n",
      "Epoch [42/500]\t Loss: 0.980630244757678\t Accuracy: 0.6322162162162163\n",
      "Step [0/37]\t Loss: 0.916633665561676\t Accuracy: 0.672\n",
      "Epoch [43/500]\t Loss: 0.9758370550903114\t Accuracy: 0.6281081081081081\n",
      "Step [0/37]\t Loss: 0.9701990485191345\t Accuracy: 0.624\n",
      "Epoch [44/500]\t Loss: 0.9809103157069232\t Accuracy: 0.6291891891891892\n",
      "Step [0/37]\t Loss: 0.95835280418396\t Accuracy: 0.632\n",
      "Epoch [45/500]\t Loss: 0.975676860358264\t Accuracy: 0.6274594594594595\n",
      "Step [0/37]\t Loss: 0.9946370720863342\t Accuracy: 0.632\n",
      "Epoch [46/500]\t Loss: 0.9775510639757723\t Accuracy: 0.6324324324324326\n",
      "Step [0/37]\t Loss: 0.9622368812561035\t Accuracy: 0.656\n",
      "Epoch [47/500]\t Loss: 0.9740126712902172\t Accuracy: 0.6315675675675674\n",
      "Step [0/37]\t Loss: 1.0243192911148071\t Accuracy: 0.616\n",
      "Epoch [48/500]\t Loss: 0.9699419173034461\t Accuracy: 0.6343783783783784\n",
      "Step [0/37]\t Loss: 1.0600663423538208\t Accuracy: 0.624\n",
      "Epoch [49/500]\t Loss: 0.9704662029807632\t Accuracy: 0.6352432432432433\n",
      "Step [0/37]\t Loss: 0.9606145024299622\t Accuracy: 0.624\n",
      "Epoch [50/500]\t Loss: 0.9722542988287436\t Accuracy: 0.6322162162162164\n",
      "Step [0/37]\t Loss: 1.1357265710830688\t Accuracy: 0.592\n",
      "Epoch [51/500]\t Loss: 0.9715521657789076\t Accuracy: 0.6345945945945947\n",
      "Step [0/37]\t Loss: 0.8836181163787842\t Accuracy: 0.656\n",
      "Epoch [52/500]\t Loss: 0.9718232170955555\t Accuracy: 0.6315675675675676\n",
      "Step [0/37]\t Loss: 1.0258432626724243\t Accuracy: 0.608\n",
      "Epoch [53/500]\t Loss: 0.9720781058878512\t Accuracy: 0.6311351351351352\n",
      "Step [0/37]\t Loss: 0.9228202700614929\t Accuracy: 0.648\n",
      "Epoch [54/500]\t Loss: 0.973266289040849\t Accuracy: 0.6343783783783784\n",
      "Step [0/37]\t Loss: 1.1420886516571045\t Accuracy: 0.536\n",
      "Epoch [55/500]\t Loss: 0.974487757360613\t Accuracy: 0.6296216216216216\n",
      "Step [0/37]\t Loss: 1.024275302886963\t Accuracy: 0.608\n",
      "Epoch [56/500]\t Loss: 0.970441773131087\t Accuracy: 0.6313513513513516\n",
      "Step [0/37]\t Loss: 0.9729394912719727\t Accuracy: 0.64\n",
      "Epoch [57/500]\t Loss: 0.9699945030985652\t Accuracy: 0.6345945945945948\n",
      "Step [0/37]\t Loss: 0.929798424243927\t Accuracy: 0.68\n",
      "Epoch [58/500]\t Loss: 0.9590459627074164\t Accuracy: 0.6404324324324325\n",
      "Step [0/37]\t Loss: 1.0574895143508911\t Accuracy: 0.576\n",
      "Epoch [59/500]\t Loss: 0.9644181760581764\t Accuracy: 0.6365405405405405\n",
      "Step [0/37]\t Loss: 1.0646651983261108\t Accuracy: 0.56\n",
      "Epoch [60/500]\t Loss: 0.9665242949047604\t Accuracy: 0.6341621621621624\n",
      "Step [0/37]\t Loss: 0.8326179385185242\t Accuracy: 0.688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aab1da4690d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# final testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-4f1c640c4e7f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SimCLR Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f62ac17ac704e108fa3ea5f52a9ea8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554f93f21a4344ada4a1e7c74fe386b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62ac17ac704e108fa3ea5f52a9ea8d",
      "placeholder": "​",
      "style": "IPY_MODEL_56b658779c7745a885cde6850fae178f",
      "value": " 170500096/? [00:19&lt;00:00, 93331221.18it/s]"
     }
    },
    "56b658779c7745a885cde6850fae178f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb79baa5d7b4c81896e083f9543b33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f1d2aed682f44f98524873f26408de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8ecfd2a00a874c6cacacbe39ab3f87cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e100213220094b8cbf3e9578bc3a1554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3834039bcc6436489e4b5fc04fb4664",
       "IPY_MODEL_554f93f21a4344ada4a1e7c74fe386b7"
      ],
      "layout": "IPY_MODEL_8ecfd2a00a874c6cacacbe39ab3f87cc"
     }
    },
    "e3834039bcc6436489e4b5fc04fb4664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb79baa5d7b4c81896e083f9543b33c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f1d2aed682f44f98524873f26408de6",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
