{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "zwoPOoaBb0oA",
    "outputId": "1f7c9d64-cfab-4b85-cc58-bc57bc604f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'imagenet-5-categories'...\n",
      "remote: Enumerating objects: 15, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 1532 (delta 1), reused 9 (delta 0), pack-reused 1517\u001b[K\n",
      "Receiving objects: 100% (1532/1532), 88.56 MiB | 50.30 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "# Getting the dataset from the github repo of imagenet 5 categories\n",
    "!git clone https://github.com/thunderInfy/imagenet-5-categories.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HfY5issLHJg"
   },
   "outputs": [],
   "source": [
    "# Some useful imports to get resnet SimCLR results folder\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyonhZFdVwhn"
   },
   "outputs": [],
   "source": [
    "# Getting simCLR results folder\n",
    "r = requests.get('https://github.com/thunderInfy/resnet-simclr/blob/master/results.zip?raw=true')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5eKrpS6OBZHW",
    "outputId": "4542b5f1-22a9-40a1-def5-089cea6a134d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Useful imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKUuE5E_DXNU"
   },
   "outputs": [],
   "source": [
    "# device is set to cuda if cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# root folder is the name of the folder where data is contained\n",
    "root_folder = 'imagenet-5-categories'\n",
    "\n",
    "train_names = sorted(os.listdir(root_folder + '/train'))\n",
    "test_names = sorted(os.listdir(root_folder + '/test'))\n",
    "\n",
    "# setting random seed to ensure the same 10% labelled data is used when training the linear classifier\n",
    "random.seed(0)\n",
    "\n",
    "names_train_10_percent = random.sample(train_names, len(train_names) // 10)\n",
    "names_train = random.sample(train_names, len(train_names))\n",
    "names_test = random.sample(test_names, len(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYwcOUWbBk5l"
   },
   "outputs": [],
   "source": [
    "# defining a mapping between class names and numbers\n",
    "mapping = {'car': 0, 'dog': 1, 'elephant': 2, 'cat': 3, 'airplane': 4}\n",
    "inverse_mapping = ['car', 'dog', 'elephant', 'cat', 'airplane']\n",
    "\n",
    "# getting labels based on filenames, note that the filenames themselves contain classnames\n",
    "# also note that these labels won't be used to actually train the base model\n",
    "# these are just for visualization purposes\n",
    "labels_train = [mapping[x.split('_')[0]] for x in names_train]\n",
    "labels_test = [mapping[x.split('_')[0]] for x in names_test]\n",
    "\n",
    "# these 10 percent labels will be used for training the linear classifer\n",
    "labels_train_10_percent = [mapping[x.split('_')[0]] for x in names_train_10_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbxUjK9ZD90A"
   },
   "outputs": [],
   "source": [
    "# A function to perform color distortion in images\n",
    "# It is used in SimCLR alongwith random resized cropping\n",
    "# Here, s is the strength of color distortion.\n",
    "\n",
    "def get_color_distortion(s=1.0):\n",
    "    color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "    rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n",
    "    \n",
    "    # p is the probability of grayscale, here 0.2\n",
    "    rnd_gray = T.RandomGrayscale(p=0.2)\n",
    "    color_distort = T.Compose([rnd_color_jitter, rnd_gray])\n",
    "    \n",
    "    return color_distort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEP9MZKoE463"
   },
   "outputs": [],
   "source": [
    "# this is the dataset class\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir, filenames, labels, mutation=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_names = filenames\n",
    "        self.labels = labels\n",
    "        self.mutation = mutation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def tensorify(self, img):\n",
    "        res = T.ToTensor()(img)\n",
    "        res = T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(res)\n",
    "        return res\n",
    "\n",
    "    def mutate_image(self, img):\n",
    "        res = T.RandomResizedCrop(224)(img)\n",
    "        res = get_color_distortion(1)(res)\n",
    "        return res\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.file_names[idx])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.labels[idx]\n",
    "        image = T.Resize((250, 250))(image)\n",
    "\n",
    "        if self.mutation:\n",
    "            image1 = self.mutate_image(image)\n",
    "            image1 = self.tensorify(image1)\n",
    "            image2 = self.mutate_image(image)\n",
    "            image2 = self.tensorify(image2)\n",
    "            sample = {'image1': image1, 'image2': image2, 'label': label}\n",
    "        else:\n",
    "            image = T.Resize((224, 224))(image)\n",
    "            image = self.tensorify(image)\n",
    "            sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IqfsF8MHYnb"
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "training_dataset_mutated = MyDataset(root_folder + '/train', names_train, labels_train, mutation=True)\n",
    "training_dataset = MyDataset(root_folder + '/train', names_train_10_percent, labels_train_10_percent, mutation=False)\n",
    "testing_dataset = MyDataset(root_folder + '/test', names_test, labels_test, mutation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZ8eFhqbHeTh"
   },
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "dataloader_training_dataset_mutated = DataLoader(training_dataset_mutated, batch_size=250, shuffle=True, num_workers=2)\n",
    "dataloader_training_dataset = DataLoader(training_dataset, batch_size=125, shuffle=True, num_workers=2)\n",
    "dataloader_testing_dataset = DataLoader(testing_dataset, batch_size=250, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJUXtxYiHnxz"
   },
   "outputs": [],
   "source": [
    "# defining our deep learning architecture\n",
    "resnet = resnet18(pretrained=False)\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(resnet.fc.in_features, 100)),\n",
    "    ('added_relu1', nn.ReLU(inplace=True)),\n",
    "    ('fc2', nn.Linear(100, 50)),\n",
    "    ('added_relu2', nn.ReLU(inplace=True)),\n",
    "    ('fc3', nn.Linear(50, 25))\n",
    "]))\n",
    "\n",
    "resnet.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HQJywp9Hq_2"
   },
   "outputs": [],
   "source": [
    "# can view the summary if you like\n",
    "# summary(resnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_bP5-FOJHyaN",
    "outputId": "cdc8ddbe-ce0b-4773-c1fe-d58c5bff5311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (fc1): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (added_relu1): ReLU(inplace=True)\n",
       "    (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (added_relu2): ReLU(inplace=True)\n",
       "    (fc3): Linear(in_features=50, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving the resnet architecture to device\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtBEidRXIAyP"
   },
   "outputs": [],
   "source": [
    "# Code for NT-Xent Loss function, explained in more detail in the article\n",
    "\n",
    "tau = 0.05\n",
    "\n",
    "def loss_function(a, b):\n",
    "    a_norm = torch.norm(a, dim=1).reshape(-1, 1)\n",
    "    a_cap = torch.div(a, a_norm)\n",
    "    b_norm = torch.norm(b, dim=1).reshape(-1, 1)\n",
    "    b_cap = torch.div(b, b_norm)\n",
    "    a_cap_b_cap = torch.cat([a_cap, b_cap], dim=0)\n",
    "    a_cap_b_cap_transpose = torch.t(a_cap_b_cap)\n",
    "    b_cap_a_cap = torch.cat([b_cap, a_cap], dim=0)\n",
    "    sim = torch.mm(a_cap_b_cap, a_cap_b_cap_transpose)\n",
    "    sim_by_tau = torch.div(sim, tau)\n",
    "    exp_sim_by_tau = torch.exp(sim_by_tau)\n",
    "    sum_of_rows = torch.sum(exp_sim_by_tau, dim=1)\n",
    "    exp_sim_by_tau_diag = torch.diag(exp_sim_by_tau)\n",
    "    numerators = torch.exp(torch.div(torch.nn.CosineSimilarity()(a_cap_b_cap, b_cap_a_cap), tau))\n",
    "    denominators = sum_of_rows - exp_sim_by_tau_diag\n",
    "    num_by_den = torch.div(numerators, denominators)\n",
    "    neglog_num_by_den = -torch.log(num_by_den)\n",
    "    return torch.mean(neglog_num_by_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "z5OwRijMIOtc",
    "outputId": "c542c382-9590-4440-e9cb-5a72d5948ab1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7c2b35afe9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# load pretrained model, optimizer and training losses file if model.pth file is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/optimizer.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\". \n\tUnexpected key(s) in state_dict: \"fc.fc1.weight\", \"fc.fc1.bias\", \"fc.fc2.weight\", \"fc.fc2.bias\", \"fc.fc3.weight\", \"fc.fc3.bias\". "
     ]
    }
   ],
   "source": [
    "# Defining data structures for storing training info\n",
    "\n",
    "losses_train = []\n",
    "num_epochs = 20\n",
    "\n",
    "# using SGD optimizer\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "\n",
    "# load pretrained model, optimizer and training losses file if model.pth file is available\n",
    "if(os.path.isfile(\"results/model.pth\")):\n",
    "    resnet.load_state_dict(torch.load(\"results/model.pth\"))\n",
    "    optimizer.load_state_dict(torch.load(\"results/optimizer.pth\"))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['weight_decay'] = 1e-6\n",
    "        param_group['lr'] = 0.000003\n",
    "\n",
    "    temp = np.load(\"results/lossesfile.npz\")\n",
    "    losses_train = list(temp['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "M2UQmK5hIyPS",
    "outputId": "861ba39e-f57e-4221-c46a-4d215368978a"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e70aa16d8c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# get their outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# get loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.90 GiB total capacity; 14.63 GiB already allocated; 21.88 MiB free; 15.18 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Boolean variable on whether to perform training or not \n",
    "# Note that this training is unsupervised, it uses the NT-Xent Loss function\n",
    "\n",
    "TRAINING = True\n",
    "\n",
    "def get_mean_of_list(L):\n",
    "    return sum(L) / len(L)\n",
    "\n",
    "if TRAINING:\n",
    "    # get resnet in train mode\n",
    "    resnet.train()\n",
    "\n",
    "    # run a for loop for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # a list to store losses for each epoch\n",
    "        epoch_losses_train = []\n",
    "\n",
    "        # run a for loop for each batch\n",
    "        for (_, sample_batched) in enumerate(dataloader_training_dataset_mutated):\n",
    "            \n",
    "            # zero out grads\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # retrieve x1 and x2 the two image batches\n",
    "            x1 = sample_batched['image1']\n",
    "            x2 = sample_batched['image2']\n",
    "\n",
    "            # move them to the device\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "\n",
    "            # get their outputs\n",
    "            y1 = resnet(x1)\n",
    "            y2 = resnet(x2)\n",
    "\n",
    "            # get loss value\n",
    "            loss = loss_function(y1, y2)\n",
    "            \n",
    "            # put that loss value in the epoch losses list\n",
    "            epoch_losses_train.append(loss.cpu().data.item())\n",
    "\n",
    "            # perform backprop on loss value to get gradient values\n",
    "            loss.backward()\n",
    "\n",
    "            # run the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "        # append mean of epoch losses to losses_train, essentially this will reflect mean batch loss\n",
    "        losses_train.append(get_mean_of_list(epoch_losses_train))\n",
    "\n",
    "        # Plot the training losses Graph and save it\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        sns.set_style('darkgrid')\n",
    "        plt.plot(losses_train)\n",
    "        plt.legend(['Training Losses'])\n",
    "        plt.savefig('losses.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Store model and optimizer files\n",
    "        torch.save(resnet.state_dict(), 'results/model.pth')\n",
    "        torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "        np.savez(\"results/lossesfile\", np.array(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7DE4cHeKah6"
   },
   "outputs": [],
   "source": [
    "# a function used to plot t-SNE visualizations\n",
    "def plot_vecs_n_labels(v,labels,fname):\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    plt.axis('off')\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.scatterplot(v[:,0], v[:,1], hue=labels, legend='full', palette=sns.color_palette(\"bright\", 5))\n",
    "    plt.legend(['car', 'dog', 'elephant','cat','airplane'])\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "# Boolean variable to control whether to perform t-SNE visualization or not\n",
    "TSNEVIS = False\n",
    "\n",
    "if TSNEVIS:\n",
    "    # run resnet in eval mode\n",
    "    resnet.eval()\n",
    "\n",
    "    # get TSNE visualizations of 10% training dataset\n",
    "    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_train_last_layer.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "\n",
    "    # get TSNE visualizations of testing dataset\n",
    "    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_test_last_layer.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "\n",
    "# Removing the last layer and the relu layer, we remove layers incrementally and look t-SNE visualizations\n",
    "resnet.fc = nn.Sequential(*list(resnet.fc.children())[:-2])\n",
    "\n",
    "if TSNEVIS:\n",
    "    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_train_second_last_layer.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "\n",
    "    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_test_second_last_layer.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "\n",
    "# removing one more layer, our entire projection head will be removed afte this\n",
    "resnet.fc = nn.Sequential(*list(resnet.fc.children())[:-1])\n",
    "\n",
    "if TSNEVIS:\n",
    "    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_hidden_train.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "\n",
    "    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n",
    "        x = sample_batched['image']\n",
    "        x = x.to(device)\n",
    "        y = resnet(x)\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = sample_batched['label']\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_hidden_test.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "YXHcn2d0HglN",
    "outputId": "b82f1ea9-b052-4d75-e0e9-292dc8c5decd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "Epoch completed\n",
      "0.3\n",
      "Epoch completed\n",
      "0.344\n",
      "Epoch completed\n",
      "0.396\n",
      "Epoch completed\n",
      "0.508\n",
      "Epoch completed\n",
      "0.544\n",
      "Epoch completed\n",
      "0.6\n",
      "Epoch completed\n",
      "0.6\n",
      "Epoch completed\n",
      "0.6\n",
      "Epoch completed\n",
      "0.596\n",
      "Epoch completed\n"
     ]
    }
   ],
   "source": [
    "# Boolean variable to control whether to train the linear classifier or not\n",
    "LINEAR = True\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return(x)\n",
    "\n",
    "if LINEAR:\n",
    "\n",
    "    if not os.path.exists('linear'):\n",
    "        os.makedirs('linear')\n",
    "\n",
    "    # getting our linear classifier\n",
    "    linear_classifier = LinearNet()\n",
    "\n",
    "    # moving it to device\n",
    "    linear_classifier.to(device)\n",
    "\n",
    "    # using SGD as a linear optimizer\n",
    "    linear_optimizer = optim.SGD(linear_classifier.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-6)\n",
    "\n",
    "    #number of epochs\n",
    "    num_epochs_linear = 10\n",
    "\n",
    "    # Boolean variable to control training of linear classifier\n",
    "    LINEAR_TRAINING = True\n",
    "\n",
    "    # Defining data structures to store train and test info for linear classifier\n",
    "    losses_train_linear = []\n",
    "    acc_train_linear = []\n",
    "    losses_test_linear = []\n",
    "    acc_test_linear = []\n",
    "\n",
    "    # a variable to keep track of the maximum test accuracy, will be useful to store \n",
    "    # model parameters with the best test accuracy\n",
    "    max_test_acc = 0\n",
    "\n",
    "    # if a model exists in the linear folder, load it\n",
    "    if(os.path.isfile(\"linear/model.pth\")):\n",
    "\n",
    "        # load state dict for linear model and optimizer\n",
    "        linear_classifier.load_state_dict(torch.load(\"linear/model.pth\"))\n",
    "        linear_optimizer.load_state_dict(torch.load(\"linear/optimizer.pth\"))\n",
    "\n",
    "        # change learning rate, you can change its values if you don't feel its necessity while training\n",
    "        for g in linear_optimizer.param_groups:\n",
    "          g['lr'] = 0.001\n",
    "          g['weight_decay'] = 0\n",
    "\n",
    "        # load data structures\n",
    "        temp = np.load(\"linear/linear_losses_train_file.npz\")\n",
    "        losses_train_linear = list(temp['arr_0'])\n",
    "        temp = np.load(\"linear/linear_losses_test_file.npz\")\n",
    "        losses_test_linear = list(temp['arr_0'])\n",
    "        temp = np.load(\"linear/linear_acc_train_file.npz\")\n",
    "        acc_train_linear = list(temp['arr_0'])\n",
    "        temp = np.load(\"linear/linear_acc_test_file.npz\")\n",
    "        acc_test_linear = list(temp['arr_0'])\n",
    "\n",
    "    # Run a for loop for training the linear classifier\n",
    "    for epoch in range(num_epochs_linear):\n",
    "\n",
    "        if LINEAR_TRAINING:\n",
    "\n",
    "            # run linear classifier in train mode\n",
    "            linear_classifier.train()\n",
    "\n",
    "            # a list to store losses for each batch in an epoch\n",
    "            epoch_losses_train_linear = []\n",
    "            epoch_acc_train_num_linear = 0.0\n",
    "            epoch_acc_train_den_linear = 0.0\n",
    "\n",
    "            # for loop for running through each batch\n",
    "            for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
    "\n",
    "                # get x and y from the batch\n",
    "                x = sample_batched['image']\n",
    "                y_actual = sample_batched['label']\n",
    "\n",
    "                # move them to the device\n",
    "                x = x.to(device)\n",
    "                y_actual  = y_actual.to(device)\n",
    "\n",
    "                # get output from resnet architecture\n",
    "                y_intermediate = resnet(x)\n",
    "\n",
    "                # zero the grad values\n",
    "                linear_optimizer.zero_grad()\n",
    "\n",
    "                # run y_intermediate through the linear classifier\n",
    "                y_predicted = linear_classifier(y_intermediate)\n",
    "\n",
    "                # get the cross entropy loss value\n",
    "                loss = nn.CrossEntropyLoss()(y_predicted, y_actual)\n",
    "\n",
    "                # add the obtained loss value to this list\n",
    "                epoch_losses_train_linear.append(loss.data.item())\n",
    "                \n",
    "                # perform backprop through the loss value\n",
    "                loss.backward()\n",
    "\n",
    "                # call the linear_optimizer step function\n",
    "                linear_optimizer.step()\n",
    "\n",
    "                # get predictions and actual values to cpu  \n",
    "                pred = np.argmax(y_predicted.cpu().data, axis=1)\n",
    "                actual = y_actual.cpu().data\n",
    "\n",
    "                #update the numerators and denominators of accuracy\n",
    "                epoch_acc_train_num_linear += (actual == pred).sum().item()\n",
    "                epoch_acc_train_den_linear += len(actual)\n",
    "\n",
    "                x = None\n",
    "                y_intermediate = None\n",
    "                y_predicted = None\n",
    "                sample_batched = None\n",
    "\n",
    "            # update losses and acc lists    \n",
    "            losses_train_linear.append(get_mean_of_list(epoch_losses_train_linear))\n",
    "            acc_train_linear.append(epoch_acc_train_num_linear / epoch_acc_train_den_linear)\n",
    "        \n",
    "        # run linear classifier in eval mode\n",
    "        linear_classifier.eval()\n",
    "\n",
    "        # essential variables to keep track of losses and acc\n",
    "        epoch_losses_test_linear = []\n",
    "        epoch_acc_test_num_linear = 0.0\n",
    "        epoch_acc_test_den_linear = 0.0\n",
    "\n",
    "        # run a for loop through each batch\n",
    "        for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n",
    "            x = sample_batched['image']\n",
    "            y_actual = sample_batched['label']\n",
    "\n",
    "            x = x.to(device)\n",
    "            y_actual  = y_actual.to(device)\n",
    "\n",
    "            y_intermediate = resnet(x)\n",
    "\n",
    "            y_predicted = linear_classifier(y_intermediate)\n",
    "            loss = nn.CrossEntropyLoss()(y_predicted, y_actual)\n",
    "            epoch_losses_test_linear.append(loss.data.item())\n",
    "\n",
    "            pred = np.argmax(y_predicted.cpu().data, axis=1)\n",
    "            actual = y_actual.cpu().data\n",
    "            epoch_acc_test_num_linear += (actual == pred).sum().item()\n",
    "            epoch_acc_test_den_linear += len(actual)\n",
    "\n",
    "        # calculate test_acc\n",
    "        test_acc = epoch_acc_test_num_linear / epoch_acc_test_den_linear\n",
    "        print(test_acc)\n",
    "\n",
    "        if LINEAR_TRAINING:\n",
    "            losses_test_linear.append(get_mean_of_list(epoch_losses_test_linear))\n",
    "            acc_test_linear.append(epoch_acc_test_num_linear / epoch_acc_test_den_linear)\n",
    "\n",
    "            # plotting losses and accuracies\n",
    "\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            sns.set_style('darkgrid')\n",
    "            plt.plot(losses_train_linear)\n",
    "            plt.plot(losses_test_linear)\n",
    "            plt.legend(['Training Losses', 'Testing Losses'])\n",
    "            plt.savefig('linear/losses.png')\n",
    "            plt.close()\n",
    "\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            sns.set_style('darkgrid')\n",
    "            plt.plot(acc_train_linear)\n",
    "            plt.plot(acc_test_linear)\n",
    "            plt.legend(['Training Accuracy', 'Testing Accuracy'])\n",
    "            plt.savefig('linear/accuracy.png')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Epoch completed\")\n",
    "\n",
    "            if test_acc >= max_test_acc:\n",
    "\n",
    "                # save the model only when test_acc exceeds the current max_test_acc\n",
    "\n",
    "                max_test_acc = test_acc\n",
    "                torch.save(linear_classifier.state_dict(), 'linear/model.pth')\n",
    "                torch.save(linear_optimizer.state_dict(), 'linear/optimizer.pth')\n",
    "\n",
    "        # save data structures\n",
    "        np.savez(\"linear/linear_losses_train_file\", np.array(losses_train_linear))\n",
    "        np.savez(\"linear/linear_losses_test_file\", np.array(losses_test_linear))\n",
    "        np.savez(\"linear/linear_acc_train_file\", np.array(acc_train_linear))\n",
    "        np.savez(\"linear/linear_acc_test_file\", np.array(acc_test_linear))\n",
    "\n",
    "# Afunction to get PIL image from tensor\n",
    "\n",
    "# def deprocess_and_show(img_tensor):\n",
    "#     return T.Compose([\n",
    "#             T.Normalize((0, 0, 0), (2, 2, 2)),\n",
    "#             T.Normalize((-0.5, -0.5, -0.5), (1, 1, 1)),\n",
    "#             T.ToPILImage()\n",
    "#           ])(img_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZIzUT2IDHry"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SimCLR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
