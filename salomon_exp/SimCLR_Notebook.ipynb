{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF8ZoVrwt0n0"
   },
   "source": [
    "# SimCLR\n",
    "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
    "\n",
    "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt6WMxjCvN3o"
   },
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/spijkervet/SimCLR.git\n",
    "# %cd SimCLR\n",
    "# # !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels\n",
    "\n",
    "# # !git clone https://github.com/spijkervet/SimCLR.git\n",
    "# %cd SimCLR\n",
    "# # !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "53JMIYtat8tT",
    "outputId": "82df4c10-ad67-4917-8963-43ee477f666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/cassava_disease_classification/salomon_exp/SimCLR-1\n"
     ]
    }
   ],
   "source": [
    "# # !git clone https://github.com/Kabongosalomon/SimCLR-1.git\n",
    "%cd SimCLR-1\n",
    "# # !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.1.3)\n",
      "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
      "Requirement already satisfied: cmaes in /usr/local/lib/python3.6/dist-packages (from optuna) (0.5.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.16)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.14.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.1.0)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.2)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.2)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.3.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.4.5)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
      "Requirement already satisfied: cmd2!=0.8.3,<0.9.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.8.9)\n",
      "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.32.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna) (0.1.9)\n",
      "Requirement already satisfied: pyperclip in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "!pip install optuna\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "\n",
    "# from experiment import ex\n",
    "from model import load_model\n",
    "from utils import post_config_hook\n",
    "\n",
    "from modules import LogisticRegression\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQ3jq3cWynLf"
   },
   "source": [
    "# Part 1:\n",
    "## SimCLR pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jhAv3hv8IHn"
   },
   "outputs": [],
   "source": [
    "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
    "use_tpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwW10d2O7pn8"
   },
   "source": [
    "#### Install PyTorch/XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj84aiC27oxS"
   },
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNDRcPbbymlX",
    "outputId": "383ea8ab-6aaf-40fd-8e59-57ee443371ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if use_tpu:\n",
    "    # imports the torch_xla package for TPU support\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    dev = xm.xla_device()\n",
    "    print(dev)\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "from model import load_model, save_model\n",
    "from modules import NT_Xent\n",
    "from modules.transformations import TransformsSimCLR\n",
    "from utils import post_config_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYbV0fa_y03Z"
   },
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klUf-IuyxdL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args.out_dir = \"logs\"\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "O86__UhA0Lvr",
    "outputId": "295583f8-ba5b-488e-ac1a-58015273bb4e"
   },
   "outputs": [],
   "source": [
    "# ### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "# args.batch_size = 64\n",
    "# args.resnet = \"resnet18\" # se_resnet50, resnet18, se_resnext101_32x4d, resnet50\n",
    "# pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'casava'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.epochs = 100\n",
    "# args.epoch_num = 100\n",
    "\n",
    "# args.projection_dim = 64\n",
    "\n",
    "# args.logistic_epochs = 100\n",
    "\n",
    "# args.optimizer = \"LARS\" #\"Adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJfeOM9PzNoF"
   },
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/train/train\"\n",
    "test_path = \"../data/test/test\"\n",
    "extraimage_path = \"../data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cgm:773\n",
      "cbb:466\n",
      "cmd:2658\n",
      "cbsd:1443\n",
      "healthy:316\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cbb': 466, 'cbsd': 1443, 'cgm': 773, 'cmd': 2658, 'healthy': 316}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.4543, 0.5137, 0.3240]\n",
    "std=[0.1949, 0.1977, 0.1661]\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, size, s=1, mutation = False):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.mutation = mutation\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        \n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((size, size)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=mean,std=std)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        image = Image.open(fileName)\n",
    "\n",
    "        if self.mutation:\n",
    "            image1 = self.train_transform(image)\n",
    "            image2 = self.train_transform(image)\n",
    "            \n",
    "            sample = [[image1, image2], classCategory]\n",
    "        else:\n",
    "            \n",
    "            image = self.test_transform(image)\n",
    "            sample = [image, classCategory]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 448\n",
    "\n",
    "train_data = CassavaDataset(data_path, size, s=1, mutation = False)\n",
    "\n",
    "test_data = CassavaDataset(test_path, size, s=1, mutation = False)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, size, s=1, mutation = True)\n",
    "\n",
    "#######################################################################\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "# random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "########################################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size_train = args.batch_size# 125\n",
    "batch_size_eval = args.batch_size#250\n",
    "n_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_eval,\n",
    "                                             sampler = valid_sampler, num_workers = n_workers)\n",
    "\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size = batch_size_eval, \n",
    "#                                               shuffle =shuffle_dataset, num_workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of subprocesses to use for data loading\n",
    "# num_workers = 6\n",
    "# # how many samples per batch to load\n",
    "# batch_size = 125\n",
    "\n",
    "# train_data = datasets.ImageFolder(data_path, transform=train_transforms)\n",
    "# test_data = datasets.ImageFolder(test_path, transform=test_transforms)\n",
    "# extraimage_data = datasets.ImageFolder(extraimage_path, transform=train_transforms)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "#                                            num_workers=num_workers, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "#                                           num_workers=num_workers)\n",
    "\n",
    "# unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size=batch_size,\n",
    "#                                                num_workers=num_workers) # to make batch_size work, I had to moove all the unlabeled data in a 0 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(unlabeled_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(next(unlabeled_loader.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e100213220094b8cbf3e9578bc3a1554",
      "8ecfd2a00a874c6cacacbe39ab3f87cc",
      "e3834039bcc6436489e4b5fc04fb4664",
      "554f93f21a4344ada4a1e7c74fe386b7",
      "6f1d2aed682f44f98524873f26408de6",
      "5bb79baa5d7b4c81896e083f9543b33c",
      "56b658779c7745a885cde6850fae178f",
      "1f62ac17ac704e108fa3ea5f52a9ea8d"
     ]
    },
    "colab_type": "code",
    "id": "YGcskdBsytbj",
    "outputId": "48f0c2a3-9800-4c52-cb8a-071e119c5d0d"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "\n",
    "# train_sampler = None\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"unlabeled\", download=True, transform=TransformsSimCLR(size=96)\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, download=True, transform=TransformsSimCLR(size=32)\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.batch_size,\n",
    "#     shuffle=(train_sampler is None),\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "#     sampler=train_sampler,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBlXZwvjzPmp"
   },
   "source": [
    "### Load the SimCLR model, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataset': 'casava',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.projection_dim = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xERq_yHSzJRX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth\" to /root/.cache/torch/checkpoints/se_resnet50-ce0d4300.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd8db70b85844a589ba9564a82a8190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=112611220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to /root/.cache/torch/checkpoints/se_resnext101_32x4d-3b2fe3d8.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961b6fd077fe420bbd29d220120ac648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196466866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, scheduler = load_model(args, unlabeled_loader, reload_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyJ3ulWqzViL"
   },
   "source": [
    "### Setup TensorBoard for logging experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZNieMqfzU7H"
   },
   "outputs": [],
   "source": [
    "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "writer = SummaryWriter(log_dir=tb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xpl6uQiIzbvK"
   },
   "source": [
    "### Create the mask that will remove correlated samples from the negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtNCVEynzjtV"
   },
   "source": [
    "### Initialize the criterion (NT-Xent loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u067AY93zh-k"
   },
   "outputs": [],
   "source": [
    "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NT_Xent(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (similarity_f): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN5KBK-yztGD"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer):\n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "\n",
    "        if x_i.shape[0] != args.batch_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.to(args.device)\n",
    "        x_j = x_j.to(args.device)\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        h_i, z_i = model(x_i)\n",
    "        h_j, z_j = model(x_j)\n",
    "        \n",
    "        #h = self.encoder(x)\n",
    "        #z = self.projector(h)\n",
    "\n",
    "#         ipdb.set_trace()\n",
    "        loss = criterion(z_i, z_j)\n",
    "\n",
    "        if apex and args.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        loss_epoch += loss.item()\n",
    "        args.global_step += 1\n",
    "\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/197]\t Loss: 4.831396102905273\n",
      "Step [50/197]\t Loss: 4.74738883972168\n",
      "Step [100/197]\t Loss: 4.656131267547607\n",
      "Step [150/197]\t Loss: 4.717471122741699\n",
      "Epoch [0/100]\t Loss: 4.653891478698266\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 4.50970458984375\n",
      "Step [50/197]\t Loss: 4.5008721351623535\n",
      "Step [100/197]\t Loss: 4.5789875984191895\n",
      "Step [150/197]\t Loss: 4.267772674560547\n",
      "Epoch [1/100]\t Loss: 4.360394860282162\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 4.344832897186279\n",
      "Step [50/197]\t Loss: 4.176105976104736\n",
      "Step [100/197]\t Loss: 4.2121806144714355\n",
      "Step [150/197]\t Loss: 4.231607437133789\n",
      "Epoch [2/100]\t Loss: 4.078589260275594\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.914879083633423\n",
      "Step [50/197]\t Loss: 4.05787467956543\n",
      "Step [100/197]\t Loss: 4.022071361541748\n",
      "Step [150/197]\t Loss: 4.030446529388428\n",
      "Epoch [3/100]\t Loss: 3.89950888290018\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.766413927078247\n",
      "Step [50/197]\t Loss: 3.8228940963745117\n",
      "Step [100/197]\t Loss: 3.826023578643799\n",
      "Step [150/197]\t Loss: 3.6736721992492676\n",
      "Epoch [4/100]\t Loss: 3.78241759992493\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.7888987064361572\n",
      "Step [50/197]\t Loss: 3.782742977142334\n",
      "Step [100/197]\t Loss: 3.756063222885132\n",
      "Step [150/197]\t Loss: 3.655003309249878\n",
      "Epoch [5/100]\t Loss: 3.70477210688712\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.755751371383667\n",
      "Step [50/197]\t Loss: 3.708254337310791\n",
      "Step [100/197]\t Loss: 3.5652923583984375\n",
      "Step [150/197]\t Loss: 3.5865066051483154\n",
      "Epoch [6/100]\t Loss: 3.6534037614231787\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.710538387298584\n",
      "Step [50/197]\t Loss: 3.4955692291259766\n",
      "Step [100/197]\t Loss: 3.6952157020568848\n",
      "Step [150/197]\t Loss: 3.586036205291748\n",
      "Epoch [7/100]\t Loss: 3.6078250202430686\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.518611431121826\n",
      "Step [50/197]\t Loss: 3.824342727661133\n",
      "Step [100/197]\t Loss: 3.496121883392334\n",
      "Step [150/197]\t Loss: 3.5612380504608154\n",
      "Epoch [8/100]\t Loss: 3.594873791418705\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.6521763801574707\n",
      "Step [50/197]\t Loss: 3.578655481338501\n",
      "Step [100/197]\t Loss: 3.543135404586792\n",
      "Step [150/197]\t Loss: 3.5795071125030518\n",
      "Epoch [9/100]\t Loss: 3.5623823289338707\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.519641876220703\n",
      "Step [50/197]\t Loss: 3.6131160259246826\n",
      "Step [100/197]\t Loss: 3.5918922424316406\n",
      "Step [150/197]\t Loss: 3.566377878189087\n",
      "Epoch [10/100]\t Loss: 3.5347395415233476\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.611201047897339\n",
      "Step [50/197]\t Loss: 3.580173969268799\n",
      "Step [100/197]\t Loss: 3.463028907775879\n",
      "Step [150/197]\t Loss: 3.5290346145629883\n",
      "Epoch [11/100]\t Loss: 3.5237621897973384\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.5521833896636963\n",
      "Step [50/197]\t Loss: 3.5088448524475098\n",
      "Step [100/197]\t Loss: 3.487870216369629\n",
      "Step [150/197]\t Loss: 3.538266658782959\n",
      "Epoch [12/100]\t Loss: 3.4949421338018425\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.6722171306610107\n",
      "Step [50/197]\t Loss: 3.4291813373565674\n",
      "Step [100/197]\t Loss: 3.4957773685455322\n",
      "Step [150/197]\t Loss: 3.4373738765716553\n",
      "Epoch [13/100]\t Loss: 3.4821175778577778\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.4539270401000977\n",
      "Step [50/197]\t Loss: 3.4497170448303223\n",
      "Step [100/197]\t Loss: 3.486302375793457\n",
      "Step [150/197]\t Loss: 3.4601902961730957\n",
      "Epoch [14/100]\t Loss: 3.471021174174275\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.4314281940460205\n",
      "Step [50/197]\t Loss: 3.5071933269500732\n",
      "Step [100/197]\t Loss: 3.5297703742980957\n",
      "Step [150/197]\t Loss: 3.5137505531311035\n",
      "Epoch [15/100]\t Loss: 3.4685945184097675\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.5364186763763428\n",
      "Step [50/197]\t Loss: 3.472055673599243\n",
      "Step [100/197]\t Loss: 3.431929349899292\n",
      "Step [150/197]\t Loss: 3.4963459968566895\n",
      "Epoch [16/100]\t Loss: 3.4534999343949524\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.4364798069000244\n",
      "Step [50/197]\t Loss: 3.4811275005340576\n",
      "Step [100/197]\t Loss: 3.5006601810455322\n",
      "Step [150/197]\t Loss: 3.4496195316314697\n",
      "Epoch [17/100]\t Loss: 3.4425789269093934\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.475980758666992\n",
      "Step [50/197]\t Loss: 3.4590747356414795\n",
      "Step [100/197]\t Loss: 3.4111757278442383\n",
      "Step [150/197]\t Loss: 3.4400341510772705\n",
      "Epoch [18/100]\t Loss: 3.4350516989751516\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.40981388092041\n",
      "Step [50/197]\t Loss: 3.400355339050293\n",
      "Step [100/197]\t Loss: 3.5097286701202393\n",
      "Step [150/197]\t Loss: 3.3849942684173584\n",
      "Epoch [19/100]\t Loss: 3.4228743526536194\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3931987285614014\n",
      "Step [50/197]\t Loss: 3.4355416297912598\n",
      "Step [100/197]\t Loss: 3.3653881549835205\n",
      "Step [150/197]\t Loss: 3.4431939125061035\n",
      "Epoch [20/100]\t Loss: 3.40959448499728\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.37455415725708\n",
      "Step [50/197]\t Loss: 3.475569486618042\n",
      "Step [100/197]\t Loss: 3.456070899963379\n",
      "Epoch [21/100]\t Loss: 3.4044677037272963\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.5219569206237793\n",
      "Step [50/197]\t Loss: 3.413069009780884\n",
      "Step [100/197]\t Loss: 3.460374355316162\n",
      "Step [150/197]\t Loss: 3.326172113418579\n",
      "Epoch [22/100]\t Loss: 3.3999739685639514\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.468564510345459\n",
      "Step [50/197]\t Loss: 3.4438107013702393\n",
      "Step [100/197]\t Loss: 3.4214437007904053\n",
      "Step [150/197]\t Loss: 3.3573811054229736\n",
      "Epoch [23/100]\t Loss: 3.3936127938594915\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.4154980182647705\n",
      "Step [50/197]\t Loss: 3.5853335857391357\n",
      "Step [100/197]\t Loss: 3.442253351211548\n",
      "Step [150/197]\t Loss: 3.3663272857666016\n",
      "Epoch [24/100]\t Loss: 3.38571046693676\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3508384227752686\n",
      "Step [50/197]\t Loss: 3.41677188873291\n",
      "Step [100/197]\t Loss: 3.3532958030700684\n",
      "Step [150/197]\t Loss: 3.443305492401123\n",
      "Epoch [25/100]\t Loss: 3.376181155897034\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3366267681121826\n",
      "Step [50/197]\t Loss: 3.3481485843658447\n",
      "Step [100/197]\t Loss: 3.3930554389953613\n",
      "Step [150/197]\t Loss: 3.4348411560058594\n",
      "Epoch [26/100]\t Loss: 3.364963889727133\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3344664573669434\n",
      "Step [50/197]\t Loss: 3.427732229232788\n",
      "Step [100/197]\t Loss: 3.380200147628784\n",
      "Step [150/197]\t Loss: 3.3759517669677734\n",
      "Epoch [27/100]\t Loss: 3.3632077021042104\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.405968189239502\n",
      "Step [50/197]\t Loss: 3.405277967453003\n",
      "Step [100/197]\t Loss: 3.423107385635376\n",
      "Step [150/197]\t Loss: 3.3160157203674316\n",
      "Epoch [28/100]\t Loss: 3.360554541428077\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.365509271621704\n",
      "Step [50/197]\t Loss: 3.3458046913146973\n",
      "Step [100/197]\t Loss: 3.3774330615997314\n",
      "Step [150/197]\t Loss: 3.396927833557129\n",
      "Epoch [29/100]\t Loss: 3.356892204526717\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3844218254089355\n",
      "Step [50/197]\t Loss: 3.392836570739746\n",
      "Step [100/197]\t Loss: 3.287736415863037\n",
      "Step [150/197]\t Loss: 3.350865602493286\n",
      "Epoch [30/100]\t Loss: 3.352617792671707\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3934035301208496\n",
      "Step [50/197]\t Loss: 3.333791971206665\n",
      "Step [100/197]\t Loss: 3.3589906692504883\n",
      "Step [150/197]\t Loss: 3.447385549545288\n",
      "Epoch [31/100]\t Loss: 3.342899938525282\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3140761852264404\n",
      "Step [50/197]\t Loss: 3.4315576553344727\n",
      "Step [100/197]\t Loss: 3.423781633377075\n",
      "Step [150/197]\t Loss: 3.3901476860046387\n",
      "Epoch [32/100]\t Loss: 3.341482584851647\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3585050106048584\n",
      "Step [50/197]\t Loss: 3.365771532058716\n",
      "Step [100/197]\t Loss: 3.4229652881622314\n",
      "Step [150/197]\t Loss: 3.402647018432617\n",
      "Epoch [33/100]\t Loss: 3.338117111757927\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3673834800720215\n",
      "Step [50/197]\t Loss: 3.3522534370422363\n",
      "Step [100/197]\t Loss: 3.372157335281372\n",
      "Step [150/197]\t Loss: 3.3360671997070312\n",
      "Epoch [34/100]\t Loss: 3.326208900074063\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.310614585876465\n",
      "Step [50/197]\t Loss: 3.2909951210021973\n",
      "Step [100/197]\t Loss: 3.3955721855163574\n",
      "Step [150/197]\t Loss: 3.3483941555023193\n",
      "Epoch [35/100]\t Loss: 3.3251281305012967\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.4602649211883545\n",
      "Step [50/197]\t Loss: 3.342303514480591\n",
      "Step [100/197]\t Loss: 3.336055278778076\n",
      "Step [150/197]\t Loss: 3.3215157985687256\n",
      "Epoch [36/100]\t Loss: 3.3265706972422335\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2625269889831543\n",
      "Step [50/197]\t Loss: 3.3446033000946045\n",
      "Step [100/197]\t Loss: 3.3328962326049805\n",
      "Step [150/197]\t Loss: 3.323390483856201\n",
      "Epoch [37/100]\t Loss: 3.325649849654454\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.374892234802246\n",
      "Step [50/197]\t Loss: 3.327752113342285\n",
      "Step [100/197]\t Loss: 3.3644981384277344\n",
      "Step [150/197]\t Loss: 3.362602949142456\n",
      "Epoch [38/100]\t Loss: 3.3163276820013365\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3539299964904785\n",
      "Step [50/197]\t Loss: 3.400826930999756\n",
      "Step [100/197]\t Loss: 3.2755990028381348\n",
      "Step [150/197]\t Loss: 3.303039312362671\n",
      "Epoch [39/100]\t Loss: 3.30967177473349\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3406970500946045\n",
      "Step [50/197]\t Loss: 3.299351215362549\n",
      "Step [100/197]\t Loss: 3.275940418243408\n",
      "Step [150/197]\t Loss: 3.2576630115509033\n",
      "Epoch [40/100]\t Loss: 3.306329621881398\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3791046142578125\n",
      "Step [50/197]\t Loss: 3.2996842861175537\n",
      "Step [100/197]\t Loss: 3.2819550037384033\n",
      "Step [150/197]\t Loss: 3.3515994548797607\n",
      "Epoch [41/100]\t Loss: 3.3016268626082366\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3182365894317627\n",
      "Step [50/197]\t Loss: 3.3378028869628906\n",
      "Step [100/197]\t Loss: 3.336199998855591\n",
      "Step [150/197]\t Loss: 3.3468527793884277\n",
      "Epoch [42/100]\t Loss: 3.305488458139642\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3339695930480957\n",
      "Step [50/197]\t Loss: 3.283602476119995\n",
      "Step [100/197]\t Loss: 3.317258358001709\n",
      "Step [150/197]\t Loss: 3.3236491680145264\n",
      "Epoch [43/100]\t Loss: 3.3007907250205877\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2580690383911133\n",
      "Step [50/197]\t Loss: 3.287454128265381\n",
      "Step [100/197]\t Loss: 3.3416943550109863\n",
      "Step [150/197]\t Loss: 3.331435203552246\n",
      "Epoch [44/100]\t Loss: 3.294454914664254\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3771584033966064\n",
      "Step [50/197]\t Loss: 3.2727715969085693\n",
      "Step [100/197]\t Loss: 3.3080575466156006\n",
      "Step [150/197]\t Loss: 3.361553192138672\n",
      "Epoch [45/100]\t Loss: 3.2934139319482796\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.372039556503296\n",
      "Step [50/197]\t Loss: 3.2900357246398926\n",
      "Step [100/197]\t Loss: 3.3130440711975098\n",
      "Step [150/197]\t Loss: 3.2652804851531982\n",
      "Epoch [46/100]\t Loss: 3.2907454664937132\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.298923969268799\n",
      "Step [50/197]\t Loss: 3.2806448936462402\n",
      "Step [100/197]\t Loss: 3.272976875305176\n",
      "Step [150/197]\t Loss: 3.302063465118408\n",
      "Epoch [47/100]\t Loss: 3.2882972320324275\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.316505193710327\n",
      "Step [50/197]\t Loss: 3.2808213233947754\n",
      "Step [100/197]\t Loss: 3.306810140609741\n",
      "Step [150/197]\t Loss: 3.4013898372650146\n",
      "Epoch [48/100]\t Loss: 3.2909970985451324\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.364105224609375\n",
      "Step [50/197]\t Loss: 3.358962059020996\n",
      "Step [100/197]\t Loss: 3.3115153312683105\n",
      "Step [150/197]\t Loss: 3.239563465118408\n",
      "Epoch [49/100]\t Loss: 3.288232773088562\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.235031843185425\n",
      "Step [50/197]\t Loss: 3.297196626663208\n",
      "Step [100/197]\t Loss: 3.225799560546875\n",
      "Step [150/197]\t Loss: 3.3328285217285156\n",
      "Epoch [50/100]\t Loss: 3.2839366312559486\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.331773281097412\n",
      "Step [50/197]\t Loss: 3.2870168685913086\n",
      "Step [100/197]\t Loss: 3.2518296241760254\n",
      "Step [150/197]\t Loss: 3.366708278656006\n",
      "Epoch [51/100]\t Loss: 3.276351612836576\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.318368673324585\n",
      "Step [50/197]\t Loss: 3.299431085586548\n",
      "Step [100/197]\t Loss: 3.29058575630188\n",
      "Step [150/197]\t Loss: 3.348414182662964\n",
      "Epoch [52/100]\t Loss: 3.275447073321657\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.316315174102783\n",
      "Step [50/197]\t Loss: 3.271394729614258\n",
      "Step [100/197]\t Loss: 3.3365347385406494\n",
      "Step [150/197]\t Loss: 3.2269742488861084\n",
      "Epoch [53/100]\t Loss: 3.2691629453358915\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.291268825531006\n",
      "Step [50/197]\t Loss: 3.227715253829956\n",
      "Step [100/197]\t Loss: 3.306952953338623\n",
      "Step [150/197]\t Loss: 3.2753536701202393\n",
      "Epoch [54/100]\t Loss: 3.2689095656883898\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2825779914855957\n",
      "Step [50/197]\t Loss: 3.2645983695983887\n",
      "Step [100/197]\t Loss: 3.2208635807037354\n",
      "Step [150/197]\t Loss: 3.3674027919769287\n",
      "Epoch [55/100]\t Loss: 3.2661862276532325\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2361819744110107\n",
      "Step [50/197]\t Loss: 3.293950080871582\n",
      "Step [100/197]\t Loss: 3.2534708976745605\n",
      "Step [150/197]\t Loss: 3.253626823425293\n",
      "Epoch [56/100]\t Loss: 3.2689364355832793\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3373327255249023\n",
      "Step [50/197]\t Loss: 3.267507314682007\n",
      "Step [100/197]\t Loss: 3.3097596168518066\n",
      "Step [150/197]\t Loss: 3.380850076675415\n",
      "Epoch [57/100]\t Loss: 3.2672623329356236\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2790451049804688\n",
      "Step [50/197]\t Loss: 3.2438337802886963\n",
      "Step [100/197]\t Loss: 3.263165235519409\n",
      "Step [150/197]\t Loss: 3.283046245574951\n",
      "Epoch [58/100]\t Loss: 3.2634418083326464\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2941994667053223\n",
      "Step [50/197]\t Loss: 3.243466377258301\n",
      "Step [100/197]\t Loss: 3.315857410430908\n",
      "Step [150/197]\t Loss: 3.2348380088806152\n",
      "Epoch [59/100]\t Loss: 3.2627575760565435\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3006696701049805\n",
      "Step [50/197]\t Loss: 3.2793853282928467\n",
      "Step [100/197]\t Loss: 3.24504017829895\n",
      "Step [150/197]\t Loss: 3.2820756435394287\n",
      "Epoch [60/100]\t Loss: 3.2566669786036924\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.332573175430298\n",
      "Step [50/197]\t Loss: 3.242335557937622\n",
      "Step [100/197]\t Loss: 3.299086332321167\n",
      "Step [150/197]\t Loss: 3.2714602947235107\n",
      "Epoch [61/100]\t Loss: 3.2584286607461532\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2954001426696777\n",
      "Step [50/197]\t Loss: 3.287822961807251\n",
      "Step [100/197]\t Loss: 3.2299766540527344\n",
      "Step [150/197]\t Loss: 3.2564198970794678\n",
      "Epoch [62/100]\t Loss: 3.2570012269286335\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2575440406799316\n",
      "Step [50/197]\t Loss: 3.2317745685577393\n",
      "Step [100/197]\t Loss: 3.307654619216919\n",
      "Step [150/197]\t Loss: 3.234137535095215\n",
      "Epoch [63/100]\t Loss: 3.2550807519612577\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.335954189300537\n",
      "Step [50/197]\t Loss: 3.259042739868164\n",
      "Step [100/197]\t Loss: 3.286876678466797\n",
      "Step [150/197]\t Loss: 3.2804417610168457\n",
      "Epoch [64/100]\t Loss: 3.2522985632649535\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.202674388885498\n",
      "Step [50/197]\t Loss: 3.362112283706665\n",
      "Step [100/197]\t Loss: 3.257906913757324\n",
      "Step [150/197]\t Loss: 3.3058571815490723\n",
      "Epoch [65/100]\t Loss: 3.248410090577179\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2987608909606934\n",
      "Step [50/197]\t Loss: 3.217507839202881\n",
      "Step [100/197]\t Loss: 3.3150200843811035\n",
      "Step [150/197]\t Loss: 3.29805850982666\n",
      "Epoch [66/100]\t Loss: 3.2509617067230536\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.222054958343506\n",
      "Step [50/197]\t Loss: 3.2717044353485107\n",
      "Step [100/197]\t Loss: 3.20554256439209\n",
      "Step [150/197]\t Loss: 3.1824564933776855\n",
      "Epoch [67/100]\t Loss: 3.2400295819122777\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2659711837768555\n",
      "Step [50/197]\t Loss: 3.3397955894470215\n",
      "Step [100/197]\t Loss: 3.3030898571014404\n",
      "Step [150/197]\t Loss: 3.288950204849243\n",
      "Epoch [68/100]\t Loss: 3.2433683436534126\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.238297462463379\n",
      "Step [50/197]\t Loss: 3.264841318130493\n",
      "Step [100/197]\t Loss: 3.25933837890625\n",
      "Step [150/197]\t Loss: 3.260230779647827\n",
      "Epoch [69/100]\t Loss: 3.246362406590263\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2978439331054688\n",
      "Step [50/197]\t Loss: 3.2693541049957275\n",
      "Step [100/197]\t Loss: 3.2786166667938232\n",
      "Step [150/197]\t Loss: 3.231630802154541\n",
      "Epoch [70/100]\t Loss: 3.2440622433793123\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2348520755767822\n",
      "Step [50/197]\t Loss: 3.2138965129852295\n",
      "Step [100/197]\t Loss: 3.2700035572052\n",
      "Step [150/197]\t Loss: 3.2119691371917725\n",
      "Epoch [71/100]\t Loss: 3.246926078941616\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.3025588989257812\n",
      "Step [50/197]\t Loss: 3.2558681964874268\n",
      "Step [100/197]\t Loss: 3.264378309249878\n",
      "Step [150/197]\t Loss: 3.230062246322632\n",
      "Epoch [72/100]\t Loss: 3.2330407660624703\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.289557695388794\n",
      "Step [50/197]\t Loss: 3.2286133766174316\n",
      "Step [100/197]\t Loss: 3.279261589050293\n",
      "Step [150/197]\t Loss: 3.2167699337005615\n",
      "Epoch [73/100]\t Loss: 3.2337093861575053\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.327700614929199\n",
      "Step [50/197]\t Loss: 3.259040594100952\n",
      "Step [100/197]\t Loss: 3.2444851398468018\n",
      "Step [150/197]\t Loss: 3.2685959339141846\n",
      "Epoch [74/100]\t Loss: 3.2331182932490625\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.258380651473999\n",
      "Step [50/197]\t Loss: 3.2332961559295654\n",
      "Step [100/197]\t Loss: 3.2618274688720703\n",
      "Step [150/197]\t Loss: 3.2809746265411377\n",
      "Epoch [75/100]\t Loss: 3.2381497276615976\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2538487911224365\n",
      "Step [50/197]\t Loss: 3.266558885574341\n",
      "Step [100/197]\t Loss: 3.297245979309082\n",
      "Step [150/197]\t Loss: 3.255784511566162\n",
      "Epoch [76/100]\t Loss: 3.235759364771964\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.207087516784668\n",
      "Step [50/197]\t Loss: 3.2314188480377197\n",
      "Step [100/197]\t Loss: 3.272981643676758\n",
      "Step [150/197]\t Loss: 3.266916513442993\n",
      "Epoch [77/100]\t Loss: 3.2262535724543073\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2582650184631348\n",
      "Step [50/197]\t Loss: 3.249150037765503\n",
      "Step [100/197]\t Loss: 3.2546563148498535\n",
      "Step [150/197]\t Loss: 3.2309038639068604\n",
      "Epoch [78/100]\t Loss: 3.2292564096789675\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.233569622039795\n",
      "Step [50/197]\t Loss: 3.2670063972473145\n",
      "Step [100/197]\t Loss: 3.203930377960205\n",
      "Step [150/197]\t Loss: 3.270453691482544\n",
      "Epoch [79/100]\t Loss: 3.225989128732439\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2641217708587646\n",
      "Step [50/197]\t Loss: 3.2175590991973877\n",
      "Step [100/197]\t Loss: 3.2173526287078857\n",
      "Step [150/197]\t Loss: 3.2388932704925537\n",
      "Epoch [80/100]\t Loss: 3.2266833576454124\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.1957004070281982\n",
      "Step [50/197]\t Loss: 3.2726869583129883\n",
      "Step [100/197]\t Loss: 3.278754949569702\n",
      "Step [150/197]\t Loss: 3.2512993812561035\n",
      "Epoch [81/100]\t Loss: 3.2279356905651575\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2535619735717773\n",
      "Step [50/197]\t Loss: 3.26343035697937\n",
      "Step [100/197]\t Loss: 3.250357151031494\n",
      "Step [150/197]\t Loss: 3.210564136505127\n",
      "Epoch [82/100]\t Loss: 3.2224243836959605\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.211446523666382\n",
      "Step [50/197]\t Loss: 3.197166919708252\n",
      "Step [100/197]\t Loss: 3.2561404705047607\n",
      "Step [150/197]\t Loss: 3.232337236404419\n",
      "Epoch [83/100]\t Loss: 3.2180687340382996\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.215536117553711\n",
      "Step [50/197]\t Loss: 3.1791253089904785\n",
      "Step [100/197]\t Loss: 3.2431156635284424\n",
      "Step [150/197]\t Loss: 3.1791648864746094\n",
      "Epoch [84/100]\t Loss: 3.2216195394545037\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2266249656677246\n",
      "Step [50/197]\t Loss: 3.1789016723632812\n",
      "Step [100/197]\t Loss: 3.2518622875213623\n",
      "Step [150/197]\t Loss: 3.264645576477051\n",
      "Epoch [85/100]\t Loss: 3.221766525113643\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2239861488342285\n",
      "Step [50/197]\t Loss: 3.227053165435791\n",
      "Step [100/197]\t Loss: 3.1900904178619385\n",
      "Step [150/197]\t Loss: 3.231889009475708\n",
      "Epoch [86/100]\t Loss: 3.2148462939383413\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.249650716781616\n",
      "Step [50/197]\t Loss: 3.255174398422241\n",
      "Step [100/197]\t Loss: 3.1844000816345215\n",
      "Step [150/197]\t Loss: 3.216049909591675\n",
      "Epoch [87/100]\t Loss: 3.213514980325844\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2723093032836914\n",
      "Step [50/197]\t Loss: 3.216691732406616\n",
      "Step [100/197]\t Loss: 3.283496618270874\n",
      "Step [150/197]\t Loss: 3.2308058738708496\n",
      "Epoch [88/100]\t Loss: 3.215764964292497\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.227827787399292\n",
      "Step [50/197]\t Loss: 3.2134902477264404\n",
      "Step [100/197]\t Loss: 3.222659111022949\n",
      "Step [150/197]\t Loss: 3.2336394786834717\n",
      "Epoch [89/100]\t Loss: 3.2130581679077923\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2593750953674316\n",
      "Step [50/197]\t Loss: 3.206857919692993\n",
      "Step [100/197]\t Loss: 3.207439661026001\n",
      "Step [150/197]\t Loss: 3.251497507095337\n",
      "Epoch [90/100]\t Loss: 3.210031419841166\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.1988399028778076\n",
      "Step [50/197]\t Loss: 3.2334413528442383\n",
      "Step [100/197]\t Loss: 3.218010902404785\n",
      "Step [150/197]\t Loss: 3.23773455619812\n",
      "Epoch [91/100]\t Loss: 3.21042090987191\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2537903785705566\n",
      "Step [50/197]\t Loss: 3.1868770122528076\n",
      "Step [100/197]\t Loss: 3.1852235794067383\n",
      "Step [150/197]\t Loss: 3.1999776363372803\n",
      "Epoch [92/100]\t Loss: 3.213589423804114\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2062582969665527\n",
      "Step [50/197]\t Loss: 3.238793134689331\n",
      "Step [100/197]\t Loss: 3.27638840675354\n",
      "Step [150/197]\t Loss: 3.1707050800323486\n",
      "Epoch [93/100]\t Loss: 3.207384461678829\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2123970985412598\n",
      "Step [50/197]\t Loss: 3.1783485412597656\n",
      "Step [100/197]\t Loss: 3.2602527141571045\n",
      "Step [150/197]\t Loss: 3.2620933055877686\n",
      "Epoch [94/100]\t Loss: 3.2076493314074987\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2498538494110107\n",
      "Step [50/197]\t Loss: 3.1669070720672607\n",
      "Step [100/197]\t Loss: 3.2002694606781006\n",
      "Step [150/197]\t Loss: 3.1844544410705566\n",
      "Epoch [95/100]\t Loss: 3.2046177556672073\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.208240270614624\n",
      "Step [50/197]\t Loss: 3.2688801288604736\n",
      "Step [100/197]\t Loss: 3.24160099029541\n",
      "Step [150/197]\t Loss: 3.272873640060425\n",
      "Epoch [96/100]\t Loss: 3.205620360253426\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2096996307373047\n",
      "Step [50/197]\t Loss: 3.1800270080566406\n",
      "Step [100/197]\t Loss: 3.2492008209228516\n",
      "Step [150/197]\t Loss: 3.221081018447876\n",
      "Epoch [97/100]\t Loss: 3.2066140695271756\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.2775402069091797\n",
      "Step [50/197]\t Loss: 3.2370903491973877\n",
      "Step [100/197]\t Loss: 3.19618558883667\n",
      "Step [150/197]\t Loss: 3.237680673599243\n",
      "Epoch [98/100]\t Loss: 3.2052138190584136\t lr: 0.0002\n",
      "Step [0/197]\t Loss: 3.1630985736846924\n",
      "Step [50/197]\t Loss: 3.232889175415039\n",
      "Step [100/197]\t Loss: 3.1969118118286133\n",
      "Step [150/197]\t Loss: 3.17921781539917\n",
      "Epoch [99/100]\t Loss: 3.20346329296906\t lr: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        \n",
    "        args.global_step = 0\n",
    "        args.current_epoch = 0\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        #     ipdb.set_trace()\n",
    "            loss_epoch = train(args, unlabeled_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                save_model(args, model, optimizer)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(unlabeled_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(unlabeled_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "        ## end training\n",
    "        save_model(args, model, optimizer)\n",
    "    except:\n",
    "        extype, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb, traceback, sys\n",
    "\n",
    "# def bombs():\n",
    "#     a = []\n",
    "#     print (a[0])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     try:\n",
    "#         bombs()\n",
    "#     except:\n",
    "#         extype, value, tb = sys.exc_info()\n",
    "#         traceback.print_exc()\n",
    "#         pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77BXUR9_4hNc"
   },
   "source": [
    "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7eHATk04Sgu"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download('./logs/checkpoint_'+args.epochs.tar) # checkpoint_100.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAQpjiuJy61N"
   },
   "source": [
    "# Part 2:\n",
    "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZRtPBCLvgqz"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "            # h = self.encoder(x)\n",
    "            # z = self.projector(h)\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skBYAPb2uKB5"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "            # h = self.encoder(x)\n",
    "            # z = self.projector(h)\n",
    "\n",
    "        output = model(z)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "OJk4-nc-vkF0",
    "outputId": "403ed12f-844f-4a05-e0db-cc5ffca627d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "pprint(config)\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7cSwhu55KJc"
   },
   "outputs": [],
   "source": [
    "# args.batch_size = 32\n",
    "# args.resnet = \"se_resnext101_32x4d\" # \n",
    "# args.model_path = \"logs\"\n",
    "# args.epoch_num = 20 # 100\n",
    "# args.projection_dim = 32\n",
    "\n",
    "# args.logistic_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWRuVrZZ5Vm1"
   },
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iPGuFjLW5PF9",
    "outputId": "42131d22-129f-4d12-efaf-b01c29d78588"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=True, download=True, transform=transform\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=False, download=True, transform=transform\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load SimCLR model and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resnet = \"resnet18\" # se_resnet50, resnet18, se_resnext101_32x4d, resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 40,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = 40,\n",
    "                                             sampler = valid_sampler, num_workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      environment.yml  media\t\trun_all.sh     tsne_on_h.png\n",
      "README.md    experiment.py    model.py\t\tsetup.sh       tsne_on_z.png\n",
      "__pycache__  logs\t      modules\t\tsetup_apex.sh  utils\n",
      "config\t     main.py\t      requirements.txt\ttesting\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RTVnvx2a5QnX",
    "outputId": "380865bd-d974-45c4-cf81-956366ddf0f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, dataset='casava', device=device(type='cuda', index=0), epoch_num=100, epochs=100, fp16=False, fp16_opt_level='O2', logistic_batch_size=256, logistic_epochs=500, model_path='logs', normalize=True, optimizer='LARS', out_dir='logs', pretrain=True, projection_dim=64, resnet='resnet18', seed=42, start_epoch=0, temperature=0.5, weight_decay=1e-06, workers=16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.logistic_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZoABGRr5Q8_"
   },
   "outputs": [],
   "source": [
    "# ## Logistic Regression\n",
    "# n_classes = 5 # stl-10\n",
    "# model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "# model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T694n_HQ5Tad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.logistic_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc = 0.80\n",
    "# for epoch in range(args.logistic_epochs):\n",
    "#     loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "#     print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "    \n",
    "#     # final testing\n",
    "#     loss_epoch, accuracy_epoch = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "#     print(f\"[FINAL]\\t Loss: {loss_epoch / len(valid_loader)}\\t Accuracy: {accuracy_epoch / len(valid_loader)}\")\n",
    "#     if accuracy_epoch / len(valid_loader) > best_acc :  \n",
    "#         print(f\"Model {valid_loader}_{accuracy_epoch / len(valid_loader)} saved\")\n",
    "#         save_model(args, simclr_model, optimizer)\n",
    "\n",
    "# # final testing\n",
    "# loss_epoch, accuracy_epoch = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "# print(f\"[FINAL]\\t Loss: {loss_epoch / len(valid_loader)}\\t Accuracy: {accuracy_epoch / len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model my trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load SimCLR model and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "#     model = model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet18', pretrained=True)\n",
    "\n",
    "    args.resnet = \"resnet18\" \n",
    "    args.model_path = 'logs'\n",
    "    \n",
    "    simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "    simclr_model = simclr_model.to(args.device)\n",
    "    simclr_model.eval()   \n",
    "    \n",
    "    n_classes = 5 # stl-10\n",
    "    \n",
    "    model = LogisticRegression(64, n_classes)\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    lr  = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "    args.logistic_epochs = 10\n",
    "#     args.resnet = \"resnet18\" \n",
    "    \n",
    "    for epoch in range(args.logistic_epochs):\n",
    "        loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "        print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "    # final testing\n",
    "    loss_epoch_val, accuracy_epoch_val = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"[FINAL]\\t Loss: {loss_epoch_val / len(valid_loader)}\\t Accuracy: {accuracy_epoch_val / len(valid_loader)}\")\n",
    "            \n",
    "     # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "            \n",
    "    return (accuracy_epoch_val / len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "            # h = self.encoder(x)\n",
    "            # z = self.projector(h)\n",
    "\n",
    "        output = model(z)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/36]\t Loss: 1.5597878694534302\t Accuracy: 0.5078125\n",
      "Epoch [0/10]\t Loss: 1.5654357704851363\t Accuracy: 0.4626157407407407\n",
      "Step [0/36]\t Loss: 1.5543488264083862\t Accuracy: 0.4765625\n",
      "Epoch [1/10]\t Loss: 1.5546982023451064\t Accuracy: 0.4673080632716049\n",
      "Step [0/36]\t Loss: 1.5475690364837646\t Accuracy: 0.484375\n",
      "Epoch [2/10]\t Loss: 1.5425658259126875\t Accuracy: 0.4704282407407407\n",
      "Step [0/36]\t Loss: 1.523428201675415\t Accuracy: 0.5390625\n",
      "Epoch [3/10]\t Loss: 1.5298074351416693\t Accuracy: 0.4688271604938271\n",
      "Step [0/36]\t Loss: 1.5295724868774414\t Accuracy: 0.4609375\n",
      "Epoch [4/10]\t Loss: 1.515473657184177\t Accuracy: 0.47122878086419756\n",
      "Step [0/36]\t Loss: 1.4940001964569092\t Accuracy: 0.5078125\n",
      "Epoch [5/10]\t Loss: 1.4999496671888564\t Accuracy: 0.47082851080246907\n",
      "Step [0/36]\t Loss: 1.5320987701416016\t Accuracy: 0.3671875\n",
      "Epoch [6/10]\t Loss: 1.484392782052358\t Accuracy: 0.4700279706790123\n",
      "Step [0/36]\t Loss: 1.4794028997421265\t Accuracy: 0.4609375\n",
      "Epoch [7/10]\t Loss: 1.4688045978546143\t Accuracy: 0.47242959104938276\n",
      "Step [0/36]\t Loss: 1.4518415927886963\t Accuracy: 0.5\n",
      "Epoch [8/10]\t Loss: 1.4527537888950772\t Accuracy: 0.471629050925926\n",
      "Step [0/36]\t Loss: 1.4895551204681396\t Accuracy: 0.421875\n",
      "Epoch [9/10]\t Loss: 1.437597672144572\t Accuracy: 0.4696277006172839\n",
      "[FINAL]\t Loss: 1.4293787082036336\t Accuracy: 0.4673789589823468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-10 16:30:37,658] Finished trial#0 with value: 0.4673789589823468 with parameters: {'lr': 1.0268907214912501e-05}. Best is trial#0 with value: 0.4673789589823468.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/36]\t Loss: 1.5890510082244873\t Accuracy: 0.3515625\n",
      "Epoch [0/10]\t Loss: 1.251209106710222\t Accuracy: 0.5228105709876544\n",
      "Step [0/36]\t Loss: 1.2028460502624512\t Accuracy: 0.5625\n",
      "Epoch [1/10]\t Loss: 1.1441894753111734\t Accuracy: 0.5669801311728395\n",
      "Step [0/36]\t Loss: 1.0272876024246216\t Accuracy: 0.671875\n",
      "Epoch [2/10]\t Loss: 1.1268040090799332\t Accuracy: 0.572974537037037\n",
      "Step [0/36]\t Loss: 0.9981377720832825\t Accuracy: 0.6484375\n",
      "Epoch [3/10]\t Loss: 1.1056363234917324\t Accuracy: 0.5812548225308642\n",
      "Step [0/36]\t Loss: 1.072443962097168\t Accuracy: 0.5703125\n",
      "Epoch [4/10]\t Loss: 1.090991112920973\t Accuracy: 0.5927710262345679\n",
      "Step [0/36]\t Loss: 1.0818747282028198\t Accuracy: 0.5703125\n",
      "Epoch [5/10]\t Loss: 1.0834623393085268\t Accuracy: 0.5938753858024691\n",
      "Step [0/36]\t Loss: 0.9466356039047241\t Accuracy: 0.6640625\n",
      "Epoch [6/10]\t Loss: 1.0649780382712681\t Accuracy: 0.600535300925926\n",
      "Step [0/36]\t Loss: 1.0486745834350586\t Accuracy: 0.59375\n",
      "Epoch [7/10]\t Loss: 1.0546617988083098\t Accuracy: 0.6047067901234568\n",
      "Step [0/36]\t Loss: 1.078270673751831\t Accuracy: 0.59375\n",
      "Epoch [8/10]\t Loss: 1.0524734490447574\t Accuracy: 0.6118200231481482\n",
      "Step [0/36]\t Loss: 0.9759501218795776\t Accuracy: 0.6484375\n",
      "Epoch [9/10]\t Loss: 1.0314699063698451\t Accuracy: 0.6103153935185186\n",
      "[FINAL]\t Loss: 1.057123641173045\t Accuracy: 0.6026090342679127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-10 16:37:13,254] Finished trial#1 with value: 0.6026090342679127 with parameters: {'lr': 0.0033413692566497443}. Best is trial#1 with value: 0.6026090342679127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/36]\t Loss: 1.5895073413848877\t Accuracy: 0.453125\n",
      "Epoch [0/10]\t Loss: 1.5149625937143962\t Accuracy: 0.46715856481481477\n",
      "Step [0/36]\t Loss: 1.4617310762405396\t Accuracy: 0.421875\n",
      "Epoch [1/10]\t Loss: 1.3746660384866927\t Accuracy: 0.4700279706790123\n",
      "Step [0/36]\t Loss: 1.4152501821517944\t Accuracy: 0.375\n",
      "Epoch [2/10]\t Loss: 1.3153442243734996\t Accuracy: 0.4720293209876544\n",
      "Step [0/36]\t Loss: 1.3149607181549072\t Accuracy: 0.4609375\n",
      "Epoch [3/10]\t Loss: 1.2867509656482272\t Accuracy: 0.4728153935185185\n",
      "Step [0/36]\t Loss: 1.2565126419067383\t Accuracy: 0.46875\n",
      "Epoch [4/10]\t Loss: 1.250851270225313\t Accuracy: 0.511058063271605\n",
      "Step [0/36]\t Loss: 1.2592544555664062\t Accuracy: 0.515625\n",
      "Epoch [5/10]\t Loss: 1.2117097742027707\t Accuracy: 0.5469810956790124\n",
      "Step [0/36]\t Loss: 1.1422476768493652\t Accuracy: 0.609375\n",
      "Epoch [6/10]\t Loss: 1.1882009969817267\t Accuracy: 0.5589023919753087\n",
      "Step [0/36]\t Loss: 1.1197820901870728\t Accuracy: 0.5546875\n",
      "Epoch [7/10]\t Loss: 1.1670451760292053\t Accuracy: 0.5642746913580248\n",
      "Step [0/36]\t Loss: 1.089612603187561\t Accuracy: 0.625\n",
      "Epoch [8/10]\t Loss: 1.1586215827200148\t Accuracy: 0.5637249228395063\n",
      "Step [0/36]\t Loss: 1.1473571062088013\t Accuracy: 0.5859375\n",
      "Epoch [9/10]\t Loss: 1.1562951041592493\t Accuracy: 0.5619405864197531\n",
      "[FINAL]\t Loss: 1.1424397362603083\t Accuracy: 0.5767052829698858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-10 16:43:46,653] Finished trial#2 with value: 0.5767052829698858 with parameters: {'lr': 0.00011379177522615647}. Best is trial#1 with value: 0.6026090342679127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/36]\t Loss: 1.614890217781067\t Accuracy: 0.1328125\n",
      "Epoch [0/10]\t Loss: 1.60211577018102\t Accuracy: 0.2480565200617284\n",
      "Step [0/36]\t Loss: 1.589152216911316\t Accuracy: 0.3671875\n",
      "Epoch [1/10]\t Loss: 1.575769864850574\t Accuracy: 0.4674238040123456\n",
      "Step [0/36]\t Loss: 1.555338740348816\t Accuracy: 0.5\n",
      "Epoch [2/10]\t Loss: 1.546531852748659\t Accuracy: 0.4702112268518518\n",
      "Step [0/36]\t Loss: 1.5245764255523682\t Accuracy: 0.5\n",
      "Epoch [3/10]\t Loss: 1.5133103165361617\t Accuracy: 0.4696277006172839\n",
      "Step [0/36]\t Loss: 1.4855536222457886\t Accuracy: 0.484375\n",
      "Epoch [4/10]\t Loss: 1.4763211376137204\t Accuracy: 0.4692274305555555\n",
      "Step [0/36]\t Loss: 1.4497541189193726\t Accuracy: 0.53125\n",
      "Epoch [5/10]\t Loss: 1.4384895198875003\t Accuracy: 0.47122878086419756\n",
      "Step [0/36]\t Loss: 1.4050042629241943\t Accuracy: 0.5078125\n",
      "Epoch [6/10]\t Loss: 1.407761851946513\t Accuracy: 0.4688271604938271\n",
      "Step [0/36]\t Loss: 1.381539225578308\t Accuracy: 0.4609375\n",
      "Epoch [7/10]\t Loss: 1.3780446118778653\t Accuracy: 0.47122878086419756\n",
      "Step [0/36]\t Loss: 1.3581351041793823\t Accuracy: 0.484375\n",
      "Epoch [8/10]\t Loss: 1.3564496768845453\t Accuracy: 0.4704282407407407\n",
      "Step [0/36]\t Loss: 1.3337944746017456\t Accuracy: 0.5\n",
      "Epoch [9/10]\t Loss: 1.3436400956577725\t Accuracy: 0.4692274305555555\n",
      "[FINAL]\t Loss: 1.3374692466523912\t Accuracy: 0.46652712876427826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-10 16:50:23,830] Finished trial#3 with value: 0.46652712876427826 with parameters: {'lr': 2.2826254631909797e-05}. Best is trial#1 with value: 0.6026090342679127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/36]\t Loss: 1.632752776145935\t Accuracy: 0.09375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-7c8f8b96e354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 )\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-54-9900124a1ee8>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-fdac4b663ffc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 448\n",
    "\n",
    "train_data = CassavaDataset(data_path, size, s=1, mutation = False)\n",
    "\n",
    "test_data = CassavaDataset(test_path, size, s=1, mutation = False)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, size, s=1, mutation = True)\n",
    "\n",
    "#######################################################################\n",
    "validation_split = 0.0\n",
    "shuffle_dataset = True\n",
    "# random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "########################################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size_train = args.batch_size# 125\n",
    "batch_size_eval = args.batch_size#250\n",
    "n_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/45]\t Loss: 1.6216480731964111\t Accuracy: 0.15625\n",
      "Epoch [0/100]\t Loss: 1.2076541662216187\t Accuracy: 0.5449652777777778\n",
      "Step [0/45]\t Loss: 1.11709725856781\t Accuracy: 0.546875\n",
      "Epoch [1/100]\t Loss: 1.0561380452579923\t Accuracy: 0.6009837962962963\n",
      "Step [0/45]\t Loss: 0.9637601971626282\t Accuracy: 0.6640625\n",
      "Epoch [2/100]\t Loss: 0.9941215303209093\t Accuracy: 0.6255208333333333\n",
      "Step [0/45]\t Loss: 1.0275079011917114\t Accuracy: 0.59375\n",
      "Epoch [3/100]\t Loss: 0.9609492195977105\t Accuracy: 0.6366898148148148\n",
      "Step [0/45]\t Loss: 0.9461528062820435\t Accuracy: 0.6796875\n",
      "Epoch [4/100]\t Loss: 0.9621600641144646\t Accuracy: 0.6425347222222222\n",
      "Step [0/45]\t Loss: 0.815538763999939\t Accuracy: 0.6796875\n",
      "Epoch [5/100]\t Loss: 0.9265490889549255\t Accuracy: 0.6528935185185185\n",
      "Step [0/45]\t Loss: 0.898435652256012\t Accuracy: 0.671875\n",
      "Epoch [6/100]\t Loss: 0.9259289158715143\t Accuracy: 0.6500578703703704\n",
      "Step [0/45]\t Loss: 0.9151264429092407\t Accuracy: 0.65625\n",
      "Epoch [7/100]\t Loss: 0.9125212960773044\t Accuracy: 0.6596064814814815\n",
      "Step [0/45]\t Loss: 0.7880647778511047\t Accuracy: 0.7265625\n",
      "Epoch [8/100]\t Loss: 0.887449226114485\t Accuracy: 0.6665509259259259\n",
      "Step [0/45]\t Loss: 0.8066011071205139\t Accuracy: 0.640625\n",
      "Epoch [9/100]\t Loss: 0.8726566513379415\t Accuracy: 0.6689814814814815\n",
      "Step [0/45]\t Loss: 0.8527241945266724\t Accuracy: 0.6484375\n",
      "Epoch [10/100]\t Loss: 0.8613032274776035\t Accuracy: 0.6844328703703704\n",
      "Step [0/45]\t Loss: 0.8850226402282715\t Accuracy: 0.6328125\n",
      "Epoch [11/100]\t Loss: 0.8566377017233107\t Accuracy: 0.6744791666666666\n",
      "Step [0/45]\t Loss: 0.8503375053405762\t Accuracy: 0.6796875\n",
      "Epoch [12/100]\t Loss: 0.8542763034502665\t Accuracy: 0.6789930555555556\n",
      "Step [0/45]\t Loss: 0.757836103439331\t Accuracy: 0.7421875\n",
      "Epoch [13/100]\t Loss: 0.8368339101473491\t Accuracy: 0.6810763888888889\n",
      "Step [0/45]\t Loss: 0.7843355536460876\t Accuracy: 0.6875\n",
      "Epoch [14/100]\t Loss: 0.8361629446347555\t Accuracy: 0.6776041666666667\n",
      "Step [0/45]\t Loss: 0.676361620426178\t Accuracy: 0.71875\n",
      "Epoch [15/100]\t Loss: 0.8185529192288716\t Accuracy: 0.6916087962962962\n",
      "Step [0/45]\t Loss: 0.7347002029418945\t Accuracy: 0.7734375\n",
      "Epoch [16/100]\t Loss: 0.8084637880325317\t Accuracy: 0.7001157407407407\n",
      "Step [0/45]\t Loss: 0.7058348059654236\t Accuracy: 0.7421875\n",
      "Epoch [17/100]\t Loss: 0.8084641946686639\t Accuracy: 0.6940393518518518\n",
      "Step [0/45]\t Loss: 0.847910463809967\t Accuracy: 0.6796875\n",
      "Epoch [18/100]\t Loss: 0.7946533335579766\t Accuracy: 0.6983217592592593\n",
      "Step [0/45]\t Loss: 0.7425324320793152\t Accuracy: 0.7109375\n",
      "Epoch [19/100]\t Loss: 0.7966200298733181\t Accuracy: 0.7041666666666667\n",
      "Step [0/45]\t Loss: 0.8285698294639587\t Accuracy: 0.7109375\n",
      "Epoch [20/100]\t Loss: 0.7979379415512085\t Accuracy: 0.7022569444444444\n",
      "Step [0/45]\t Loss: 0.7621768116950989\t Accuracy: 0.6953125\n",
      "Epoch [21/100]\t Loss: 0.7709079715940688\t Accuracy: 0.7115162037037036\n",
      "Step [0/45]\t Loss: 0.7644914984703064\t Accuracy: 0.6875\n",
      "Epoch [22/100]\t Loss: 0.7645673566394382\t Accuracy: 0.7126736111111112\n",
      "Step [0/45]\t Loss: 0.6959973573684692\t Accuracy: 0.7265625\n",
      "Epoch [23/100]\t Loss: 0.7672742380036248\t Accuracy: 0.7044560185185185\n",
      "Step [0/45]\t Loss: 0.8028383851051331\t Accuracy: 0.71875\n",
      "Epoch [24/100]\t Loss: 0.7571745912233988\t Accuracy: 0.7127314814814815\n",
      "Step [0/45]\t Loss: 0.6845637559890747\t Accuracy: 0.7421875\n",
      "Epoch [25/100]\t Loss: 0.7566168056594\t Accuracy: 0.7148726851851852\n",
      "Step [0/45]\t Loss: 0.7398198843002319\t Accuracy: 0.7265625\n",
      "Epoch [26/100]\t Loss: 0.7400499688254463\t Accuracy: 0.7138888888888889\n",
      "Step [0/45]\t Loss: 0.7734792232513428\t Accuracy: 0.71875\n",
      "Epoch [27/100]\t Loss: 0.7344441877471076\t Accuracy: 0.7237268518518519\n",
      "Step [0/45]\t Loss: 0.6950010061264038\t Accuracy: 0.734375\n",
      "Epoch [28/100]\t Loss: 0.7441050383779738\t Accuracy: 0.7210648148148148\n",
      "Step [0/45]\t Loss: 0.5689560770988464\t Accuracy: 0.8046875\n",
      "Epoch [29/100]\t Loss: 0.6988203134801653\t Accuracy: 0.7318865740740741\n",
      "Step [0/45]\t Loss: 0.7518578171730042\t Accuracy: 0.78125\n",
      "Epoch [30/100]\t Loss: 0.7293034540282355\t Accuracy: 0.7255787037037037\n",
      "Step [0/45]\t Loss: 0.5670672059059143\t Accuracy: 0.8046875\n",
      "Epoch [31/100]\t Loss: 0.6943051709069146\t Accuracy: 0.7355324074074074\n",
      "Step [0/45]\t Loss: 0.6681283712387085\t Accuracy: 0.734375\n",
      "Epoch [32/100]\t Loss: 0.7006977399190267\t Accuracy: 0.7362847222222222\n",
      "Step [0/45]\t Loss: 0.7181887030601501\t Accuracy: 0.7265625\n",
      "Epoch [33/100]\t Loss: 0.6874341898494296\t Accuracy: 0.7355902777777777\n",
      "Step [0/45]\t Loss: 0.5988894701004028\t Accuracy: 0.7734375\n",
      "Epoch [34/100]\t Loss: 0.6818735453817579\t Accuracy: 0.7399305555555555\n",
      "Step [0/45]\t Loss: 0.7160118818283081\t Accuracy: 0.75\n",
      "Epoch [35/100]\t Loss: 0.679946259657542\t Accuracy: 0.7378472222222222\n",
      "Step [0/45]\t Loss: 0.6347686648368835\t Accuracy: 0.78125\n",
      "Epoch [36/100]\t Loss: 0.6620333472887675\t Accuracy: 0.7491898148148147\n",
      "Step [0/45]\t Loss: 0.6061662435531616\t Accuracy: 0.7890625\n",
      "Epoch [37/100]\t Loss: 0.6652807255585989\t Accuracy: 0.7482638888888888\n",
      "Step [0/45]\t Loss: 0.7905676960945129\t Accuracy: 0.703125\n",
      "Epoch [38/100]\t Loss: 0.6490724159611596\t Accuracy: 0.7517939814814815\n",
      "Step [0/45]\t Loss: 0.6837069988250732\t Accuracy: 0.765625\n",
      "Epoch [39/100]\t Loss: 0.6503192491001553\t Accuracy: 0.75\n",
      "Step [0/45]\t Loss: 0.7016165256500244\t Accuracy: 0.7109375\n",
      "Epoch [40/100]\t Loss: 0.6294553173912896\t Accuracy: 0.7629050925925925\n",
      "Step [0/45]\t Loss: 0.7104427814483643\t Accuracy: 0.734375\n",
      "Epoch [41/100]\t Loss: 0.6191263622707791\t Accuracy: 0.7653356481481481\n",
      "Step [0/45]\t Loss: 0.6964678168296814\t Accuracy: 0.75\n",
      "Epoch [42/100]\t Loss: 0.6292214373747508\t Accuracy: 0.7564236111111111\n",
      "Step [0/45]\t Loss: 0.5082096457481384\t Accuracy: 0.8046875\n",
      "Epoch [43/100]\t Loss: 0.6181426776780022\t Accuracy: 0.7669560185185186\n",
      "Step [0/45]\t Loss: 0.5387133359909058\t Accuracy: 0.796875\n",
      "Epoch [44/100]\t Loss: 0.6119751579231686\t Accuracy: 0.766087962962963\n",
      "Step [0/45]\t Loss: 0.6483421325683594\t Accuracy: 0.75\n",
      "Epoch [45/100]\t Loss: 0.6091135746902889\t Accuracy: 0.7644675925925926\n",
      "Step [0/45]\t Loss: 0.5952734351158142\t Accuracy: 0.765625\n",
      "Epoch [46/100]\t Loss: 0.6051741328504351\t Accuracy: 0.7648148148148147\n",
      "Step [0/45]\t Loss: 0.6322152018547058\t Accuracy: 0.7421875\n",
      "Epoch [47/100]\t Loss: 0.6075748642285664\t Accuracy: 0.7637152777777778\n",
      "Step [0/45]\t Loss: 0.47613659501075745\t Accuracy: 0.8125\n",
      "Epoch [48/100]\t Loss: 0.5924214230643379\t Accuracy: 0.7720486111111111\n",
      "Step [0/45]\t Loss: 0.5577067732810974\t Accuracy: 0.8046875\n",
      "Epoch [49/100]\t Loss: 0.5749553905593024\t Accuracy: 0.7740740740740741\n",
      "Step [0/45]\t Loss: 0.4594725966453552\t Accuracy: 0.8203125\n",
      "Epoch [50/100]\t Loss: 0.5608319401741028\t Accuracy: 0.7896412037037036\n",
      "Step [0/45]\t Loss: 0.7236082553863525\t Accuracy: 0.7265625\n",
      "Epoch [51/100]\t Loss: 0.5599947697586484\t Accuracy: 0.7828703703703703\n",
      "Step [0/45]\t Loss: 0.42927297949790955\t Accuracy: 0.859375\n",
      "Epoch [52/100]\t Loss: 0.5510436607731714\t Accuracy: 0.787789351851852\n",
      "Step [0/45]\t Loss: 0.5020497441291809\t Accuracy: 0.8125\n",
      "Epoch [53/100]\t Loss: 0.5422645946343739\t Accuracy: 0.796412037037037\n",
      "Step [0/45]\t Loss: 0.5419974327087402\t Accuracy: 0.7890625\n",
      "Epoch [54/100]\t Loss: 0.5472770551840465\t Accuracy: 0.7934027777777778\n",
      "Step [0/45]\t Loss: 0.5641605854034424\t Accuracy: 0.8125\n",
      "Epoch [55/100]\t Loss: 0.5463024814923604\t Accuracy: 0.7958333333333333\n",
      "Step [0/45]\t Loss: 0.5220481157302856\t Accuracy: 0.78125\n",
      "Epoch [56/100]\t Loss: 0.5407522565788693\t Accuracy: 0.7935763888888889\n",
      "Step [0/45]\t Loss: 0.5850033164024353\t Accuracy: 0.7890625\n",
      "Epoch [57/100]\t Loss: 0.532422493563758\t Accuracy: 0.7956597222222223\n",
      "Step [0/45]\t Loss: 0.426887184381485\t Accuracy: 0.84375\n",
      "Epoch [58/100]\t Loss: 0.5434866024388207\t Accuracy: 0.7986111111111112\n",
      "Step [0/45]\t Loss: 0.5877444744110107\t Accuracy: 0.7734375\n",
      "Epoch [59/100]\t Loss: 0.506962184773551\t Accuracy: 0.8083912037037037\n",
      "Step [0/45]\t Loss: 0.5264533162117004\t Accuracy: 0.796875\n",
      "Epoch [60/100]\t Loss: 0.500451519091924\t Accuracy: 0.8094907407407408\n",
      "Step [0/45]\t Loss: 0.4480472207069397\t Accuracy: 0.8125\n",
      "Epoch [61/100]\t Loss: 0.4945476724041833\t Accuracy: 0.8148148148148148\n",
      "Step [0/45]\t Loss: 0.5606380105018616\t Accuracy: 0.7734375\n",
      "Epoch [62/100]\t Loss: 0.5127704216374291\t Accuracy: 0.8050347222222223\n",
      "Step [0/45]\t Loss: 0.45015013217926025\t Accuracy: 0.828125\n",
      "Epoch [63/100]\t Loss: 0.489166616068946\t Accuracy: 0.8152199074074075\n",
      "Step [0/45]\t Loss: 0.4255213141441345\t Accuracy: 0.796875\n",
      "Epoch [64/100]\t Loss: 0.4868292987346649\t Accuracy: 0.8159143518518519\n",
      "Step [0/45]\t Loss: 0.4717232584953308\t Accuracy: 0.84375\n",
      "Epoch [65/100]\t Loss: 0.46995605296558807\t Accuracy: 0.8232060185185186\n",
      "Step [0/45]\t Loss: 0.46091243624687195\t Accuracy: 0.8515625\n",
      "Epoch [66/100]\t Loss: 0.4723331782552931\t Accuracy: 0.8145833333333333\n",
      "Step [0/45]\t Loss: 0.4869326055049896\t Accuracy: 0.8203125\n",
      "Epoch [67/100]\t Loss: 0.4708834535545773\t Accuracy: 0.8189814814814814\n",
      "Step [0/45]\t Loss: 0.3603837490081787\t Accuracy: 0.8515625\n",
      "Epoch [68/100]\t Loss: 0.45431031584739684\t Accuracy: 0.8291087962962963\n",
      "Step [0/45]\t Loss: 0.37940868735313416\t Accuracy: 0.8671875\n",
      "Epoch [69/100]\t Loss: 0.48635208076900904\t Accuracy: 0.8170717592592592\n",
      "Step [0/45]\t Loss: 0.5151374340057373\t Accuracy: 0.8359375\n",
      "Epoch [70/100]\t Loss: 0.47114073899057174\t Accuracy: 0.8138310185185186\n",
      "Step [0/45]\t Loss: 0.5901287198066711\t Accuracy: 0.734375\n",
      "Epoch [71/100]\t Loss: 0.46784524586465626\t Accuracy: 0.8172453703703704\n",
      "Step [0/45]\t Loss: 0.5217581391334534\t Accuracy: 0.765625\n",
      "Epoch [72/100]\t Loss: 0.4390167666806115\t Accuracy: 0.8367476851851853\n",
      "Step [0/45]\t Loss: 0.47237300872802734\t Accuracy: 0.8359375\n",
      "Epoch [73/100]\t Loss: 0.4322511268986596\t Accuracy: 0.8325810185185186\n",
      "Step [0/45]\t Loss: 0.37200647592544556\t Accuracy: 0.8515625\n",
      "Epoch [74/100]\t Loss: 0.42948692970805696\t Accuracy: 0.8347800925925926\n",
      "Step [0/45]\t Loss: 0.4616870880126953\t Accuracy: 0.828125\n",
      "Epoch [75/100]\t Loss: 0.42790858348210653\t Accuracy: 0.8346064814814814\n",
      "Step [0/45]\t Loss: 0.43316397070884705\t Accuracy: 0.8203125\n",
      "Epoch [76/100]\t Loss: 0.43389813899993895\t Accuracy: 0.8334490740740741\n",
      "Step [0/45]\t Loss: 0.38366180658340454\t Accuracy: 0.8203125\n",
      "Epoch [77/100]\t Loss: 0.41535857915878294\t Accuracy: 0.8424189814814814\n",
      "Step [0/45]\t Loss: 0.3884196877479553\t Accuracy: 0.875\n",
      "Epoch [78/100]\t Loss: 0.4072831511497498\t Accuracy: 0.8472222222222222\n",
      "Step [0/45]\t Loss: 0.342885822057724\t Accuracy: 0.8671875\n",
      "Epoch [79/100]\t Loss: 0.39782841238710615\t Accuracy: 0.8471064814814814\n",
      "Step [0/45]\t Loss: 0.47547000646591187\t Accuracy: 0.8046875\n",
      "Epoch [80/100]\t Loss: 0.4004489170180427\t Accuracy: 0.8440393518518519\n",
      "Step [0/45]\t Loss: 0.4780910909175873\t Accuracy: 0.8203125\n",
      "Epoch [81/100]\t Loss: 0.4109446154700385\t Accuracy: 0.8383680555555556\n",
      "Step [0/45]\t Loss: 0.4210648834705353\t Accuracy: 0.84375\n",
      "Epoch [82/100]\t Loss: 0.40762844383716584\t Accuracy: 0.8428819444444444\n",
      "Step [0/45]\t Loss: 0.4335193634033203\t Accuracy: 0.796875\n",
      "Epoch [83/100]\t Loss: 0.3818322178390291\t Accuracy: 0.8546296296296296\n",
      "Step [0/45]\t Loss: 0.5279704928398132\t Accuracy: 0.78125\n",
      "Epoch [84/100]\t Loss: 0.3948145614729987\t Accuracy: 0.8471643518518519\n",
      "Step [0/45]\t Loss: 0.40676960349082947\t Accuracy: 0.8515625\n",
      "Epoch [85/100]\t Loss: 0.38482261498769127\t Accuracy: 0.8534722222222222\n",
      "Step [0/45]\t Loss: 0.3984648287296295\t Accuracy: 0.84375\n",
      "Epoch [86/100]\t Loss: 0.36633667084905835\t Accuracy: 0.8627893518518519\n",
      "Step [0/45]\t Loss: 0.29378804564476013\t Accuracy: 0.8671875\n",
      "Epoch [87/100]\t Loss: 0.3674968510866165\t Accuracy: 0.8601273148148147\n",
      "Step [0/45]\t Loss: 0.3175279498100281\t Accuracy: 0.84375\n",
      "Epoch [88/100]\t Loss: 0.3495965547031826\t Accuracy: 0.8650462962962964\n",
      "Step [0/45]\t Loss: 0.4526060223579407\t Accuracy: 0.8046875\n",
      "Epoch [89/100]\t Loss: 0.3491072118282318\t Accuracy: 0.8650462962962964\n",
      "Step [0/45]\t Loss: 0.3125366270542145\t Accuracy: 0.8984375\n",
      "Epoch [90/100]\t Loss: 0.3574742982784907\t Accuracy: 0.8642361111111111\n",
      "Step [0/45]\t Loss: 0.35668471455574036\t Accuracy: 0.8515625\n",
      "Epoch [91/100]\t Loss: 0.35388709439171684\t Accuracy: 0.8631944444444445\n",
      "Step [0/45]\t Loss: 0.2713037133216858\t Accuracy: 0.90625\n",
      "Epoch [92/100]\t Loss: 0.3333726879623201\t Accuracy: 0.8703703703703703\n",
      "Step [0/45]\t Loss: 0.2511579692363739\t Accuracy: 0.90625\n",
      "Epoch [93/100]\t Loss: 0.32655856808026634\t Accuracy: 0.871412037037037\n",
      "Step [0/45]\t Loss: 0.2800067961215973\t Accuracy: 0.890625\n",
      "Epoch [94/100]\t Loss: 0.32981991039382086\t Accuracy: 0.8748263888888889\n",
      "Step [0/45]\t Loss: 0.40086349844932556\t Accuracy: 0.8515625\n",
      "Epoch [95/100]\t Loss: 0.32158537374602425\t Accuracy: 0.8760416666666667\n",
      "Step [0/45]\t Loss: 0.3256949782371521\t Accuracy: 0.8671875\n",
      "Epoch [96/100]\t Loss: 0.31794182856877645\t Accuracy: 0.8814236111111111\n",
      "Step [0/45]\t Loss: 0.30080917477607727\t Accuracy: 0.875\n",
      "Epoch [97/100]\t Loss: 0.3174740860859553\t Accuracy: 0.8786458333333333\n",
      "Step [0/45]\t Loss: 0.31074732542037964\t Accuracy: 0.875\n",
      "Epoch [98/100]\t Loss: 0.3116411116388109\t Accuracy: 0.8805555555555555\n",
      "Step [0/45]\t Loss: 0.29063236713409424\t Accuracy: 0.859375\n",
      "Epoch [99/100]\t Loss: 0.3145303845405579\t Accuracy: 0.8731481481481481\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "#     model = model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet18', pretrained=True)\n",
    "\n",
    "args.resnet = \"resnet18\" \n",
    "args.model_path = 'logs'\n",
    "\n",
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()   \n",
    "\n",
    "n_classes = 5 # stl-10\n",
    "\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(args.device)\n",
    "\n",
    "lr  = 0.000979019687620664 #trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "args.logistic_epochs = 100\n",
    "#     args.resnet = \"resnet18\" \n",
    "\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "# final testing\n",
    "# loss_epoch_val, accuracy_epoch_val = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "# print(f\"[FINAL]\\t Loss: {loss_epoch_val / len(valid_loader)}\\t Accuracy: {accuracy_epoch_val / len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to rename the model saved on path, to allow the model load it instaed of our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    from pprint import pprint\n",
    "    from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "    config = yaml_config_hook(\"./config/config.yaml\")\n",
    "#     pprint(config)\n",
    "    args = argparse.Namespace(**config)\n",
    "\n",
    "    if use_tpu:\n",
    "        args.device = dev\n",
    "    else:\n",
    "        args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "#     model = model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet18', pretrained=True)\n",
    "\n",
    "    args.model_path = 'logs'\n",
    "    \n",
    "    simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "    simclr_model = simclr_model.to(args.device)\n",
    "    simclr_model.eval()   \n",
    "    \n",
    "    n_classes = 5 # stl-10\n",
    "    \n",
    "    model = LogisticRegression(64, n_classes)\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    lr  = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "    args.logistic_epochs = 10\n",
    "#     args.resnet = \"resnet18\" \n",
    "    \n",
    "    for epoch in range(args.logistic_epochs):\n",
    "        loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "        print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "    # final testing\n",
    "    loss_epoch_val, accuracy_epoch_val = test(args, valid_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"[FINAL]\\t Loss: {loss_epoch_val / len(valid_loader)}\\t Accuracy: {accuracy_epoch_val / len(valid_loader)}\")\n",
    "            \n",
    "     # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "            \n",
    "    return (accuracy_epoch_val / len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (model): Linear(in_features=64, out_features=5, bias=True)\n",
       "  (fc_1): Linear(in_features=64, out_features=700, bias=True)\n",
       "  (fc_2): Linear(in_features=700, out_features=200, bias=True)\n",
       "  (fc_out): Linear(in_features=200, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval() \n",
    "\n",
    "model = LogisticRegression(64, 5)\n",
    "model = model.to(args.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, z = simclr_model(next(train_loader.__iter__())[0].to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2020-05-10 16:15:19,018] Setting status of trial#0 as TrialState.FAIL because of the following error: RuntimeError('Error(s) in loading state_dict for SimCLR:\\n\\tMissing key(s) in state_dict: \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \\n\\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\\n\\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\\n\\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\\n\\tsize mismatch for encoder.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\\n\\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for encoder.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for encoder.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for encoder.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\\n\\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\\n\\tsize mismatch for encoder.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\\n\\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encoder.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encoder.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encoder.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\\n\\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\\n\\tsize mismatch for encoder.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\\n\\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for encoder.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for encoder.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for encoder.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\\n\\tsize mismatch for projector.0.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\\n\\tsize mismatch for projector.2.weight: copying a param with shape torch.Size([64, 512]) from checkpoint, the shape in current model is torch.Size([64, 2048]).',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/optuna/study.py\", line 677, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-36-de9f48302a02>\", line 20, in objective\n",
      "    simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
      "  File \"/root/cassava_disease_classification/salomon_exp/SimCLR-1/model.py\", line 13, in load_model\n",
      "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 847, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for SimCLR:\n",
      "\tMissing key(s) in state_dict: \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \n",
      "\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for encoder.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for encoder.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for encoder.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for encoder.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "\tsize mismatch for encoder.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n",
      "\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for encoder.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for encoder.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for encoder.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
      "\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "\tsize mismatch for encoder.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n",
      "\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for encoder.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for encoder.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for encoder.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
      "\tsize mismatch for projector.0.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n",
      "\tsize mismatch for projector.2.weight: copying a param with shape torch.Size([64, 512]) from checkpoint, the shape in current model is torch.Size([64, 2048]).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SimCLR:\n\tMissing key(s) in state_dict: \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for projector.0.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for projector.2.weight: copying a param with shape torch.Size([64, 512]) from checkpoint, the shape in current model is torch.Size([64, 2048]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-19db579a97c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 )\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-36-de9f48302a02>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0msimclr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msimclr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/cassava_disease_classification/salomon_exp/SimCLR-1/model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(args, loader, reload_model)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"checkpoint_{}.tar\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SimCLR:\n\tMissing key(s) in state_dict: \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for projector.0.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).\n\tsize mismatch for projector.2.weight: copying a param with shape torch.Size([64, 512]) from checkpoint, the shape in current model is torch.Size([64, 2048])."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cgm', 'cbb', 'cmd', 'cbsd', 'healthy']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size = 50,\n",
    "#                                              sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset.classes) == len(['green','orange','brown','dodgerblue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 15.90 GiB total capacity; 14.90 GiB already allocated; 165.81 MiB free; 15.04 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9396f2a13b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#h, z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/cassava_disease_classification/salomon_exp/SimCLR-1/modules/simclr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 15.90 GiB total capacity; 14.90 GiB already allocated; 165.81 MiB free; 15.04 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# a function used to plot t-SNE visualizations\n",
    "def plot_vecs_n_labels(v,labels,fname):\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    plt.axis('off')\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.scatterplot(v[:,0], v[:,1], hue=labels, legend='full', palette=['green','orange','brown','dodgerblue','red'])\n",
    "    plt.legend(train_loader.dataset.classes)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "# Boolean variable to control whether to perform t-SNE visualization or not\n",
    "TSNEVIS = True\n",
    "# \n",
    "if TSNEVIS:\n",
    "    # run resnet in eval mode\n",
    "    simclr_model.eval()\n",
    "\n",
    "    # get TSNE visualizations of training dataset\n",
    "    for (i, (input, output)) in enumerate(train_loader):\n",
    "        x = input\n",
    "        x = x.to(device)\n",
    "        y = simclr_model(x)[0] #h, z\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = output\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_on_z'+str(i)+'.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "        if i==5:\n",
    "            break\n",
    "#         break\n",
    "            \n",
    "    # get TSNE visualizations of training dataset\n",
    "    for (i, (input, output)) in enumerate(train_loader):\n",
    "        x = input\n",
    "        x = x.to(device)\n",
    "        y = simclr_model(x)[0] #h, z\n",
    "        y_tsne = tsne.fit_transform(y.cpu().data)\n",
    "        labels = output\n",
    "        plot_vecs_n_labels(y_tsne,labels,'tsne_on_h'+str(i)+'.png')\n",
    "        x = None\n",
    "        y = None\n",
    "        y_tsne = None\n",
    "        sample_batched = None\n",
    "        break\n",
    "        \n",
    "        if i==5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cgm', 'cbb', 'cmd', 'cbsd', 'healthy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cgm', 1: 'cbb', 2: 'cmd', 3: 'cbsd', 4: 'healthy'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = {i:label for i, label in enumerate(train_loader.dataset.classes)}\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, makedirs, getcwd, remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_dir):\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # tensor.numpy().transpose(1, 2, 0)\n",
    "    image = Image.open(image_dir)\n",
    "#     preprocess = torchvision.transforms.Compose(\n",
    "#             [\n",
    "#                 torchvision.transforms.Resize((224, 224)),\n",
    "#                 torchvision.transforms.CenterCrop(224),\n",
    "#                 torchvision.transforms.ToTensor()\n",
    "#             ]\n",
    "#         )\n",
    "    \n",
    "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean,std=std)])\n",
    "    image = preprocess(image)\n",
    "    # Convert 2D image to 1D vector\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.from_numpy(image)\n",
    "    inputs = image.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the label\n",
    "def predict(image1, simclr_model, model):\n",
    "    # Pass the image through our model\n",
    "    output_hat = simclr_model(image1)\n",
    "    output = model(output_hat[0])\n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"../data/test/test/0\"\n",
    "predictions, test_image_fileName = [], []\n",
    "try:\n",
    "    test_images = listdir(test_directory)\n",
    "    for images in test_images:\n",
    "        test_image_fileName.append(images)\n",
    "        image = process_image(f'{test_directory}/{images}')\n",
    "        top_prob, top_class = predict(image, simclr_model, model)\n",
    "        predictions.append(class_names[top_class])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Creating pandas dataframe\")\n",
    "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
    "submission_data_frame = pd.DataFrame(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>test-img-1567.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cgm</td>\n",
       "      <td>test-img-2833.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healthy</td>\n",
       "      <td>test-img-1833.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>healthy</td>\n",
       "      <td>test-img-1916.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmd</td>\n",
       "      <td>test-img-1641.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                 Id\n",
       "0  healthy  test-img-1567.jpg\n",
       "1      cgm  test-img-2833.jpg\n",
       "2  healthy  test-img-1833.jpg\n",
       "3  healthy  test-img-1916.jpg\n",
       "4      cmd  test-img-1641.jpg"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_frame.to_csv('submission'+'_SimCLR.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SimCLR Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f62ac17ac704e108fa3ea5f52a9ea8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554f93f21a4344ada4a1e7c74fe386b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62ac17ac704e108fa3ea5f52a9ea8d",
      "placeholder": "​",
      "style": "IPY_MODEL_56b658779c7745a885cde6850fae178f",
      "value": " 170500096/? [00:19&lt;00:00, 93331221.18it/s]"
     }
    },
    "56b658779c7745a885cde6850fae178f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb79baa5d7b4c81896e083f9543b33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f1d2aed682f44f98524873f26408de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8ecfd2a00a874c6cacacbe39ab3f87cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e100213220094b8cbf3e9578bc3a1554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3834039bcc6436489e4b5fc04fb4664",
       "IPY_MODEL_554f93f21a4344ada4a1e7c74fe386b7"
      ],
      "layout": "IPY_MODEL_8ecfd2a00a874c6cacacbe39ab3f87cc"
     }
    },
    "e3834039bcc6436489e4b5fc04fb4664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb79baa5d7b4c81896e083f9543b33c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f1d2aed682f44f98524873f26408de6",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
