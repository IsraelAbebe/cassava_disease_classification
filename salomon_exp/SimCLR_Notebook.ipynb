{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF8ZoVrwt0n0"
   },
   "source": [
    "# SimCLR\n",
    "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
    "\n",
    "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt6WMxjCvN3o"
   },
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "53JMIYtat8tT",
    "outputId": "82df4c10-ad67-4917-8963-43ee477f666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cassava_disease_classification/salomon_exp/SimCLR\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/spijkervet/SimCLR.git\n",
    "%cd SimCLR\n",
    "# !wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "\n",
    "from experiment import ex\n",
    "from model import load_model\n",
    "from utils import post_config_hook\n",
    "\n",
    "from modules import LogisticRegression\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQ3jq3cWynLf"
   },
   "source": [
    "# Part 1:\n",
    "## SimCLR pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jhAv3hv8IHn"
   },
   "outputs": [],
   "source": [
    "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
    "use_tpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwW10d2O7pn8"
   },
   "source": [
    "#### Install PyTorch/XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj84aiC27oxS"
   },
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNDRcPbbymlX",
    "outputId": "383ea8ab-6aaf-40fd-8e59-57ee443371ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if use_tpu:\n",
    "    # imports the torch_xla package for TPU support\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    dev = xm.xla_device()\n",
    "    print(dev)\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "from model import load_model, save_model\n",
    "from modules import NT_Xent\n",
    "from modules.transformations import TransformsSimCLR\n",
    "from utils import post_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Abk6aFZxyedW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYbV0fa_y03Z"
   },
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klUf-IuyxdL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args.out_dir = \"logs\"\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "O86__UhA0Lvr",
    "outputId": "295583f8-ba5b-488e-ac1a-58015273bb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "args.batch_size = 64\n",
    "args.resnet = \"resnet18\"\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'casava'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJfeOM9PzNoF"
   },
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/train/train\"\n",
    "test_path = \"../data/test/test\"\n",
    "extraimage_path = \"../data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "cmd:2658\n",
      "healthy:316\n",
      "cbsd:1443\n",
      "cbb:466\n",
      "cgm:773\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cmd': 2658, 'healthy': 316, 'cbsd': 1443, 'cbb': 466, 'cgm': 773}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, size, s=1, mutation = False):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.mutation = mutation\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        \n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((size, size)),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        image = Image.open(fileName)\n",
    "\n",
    "        if self.mutation:\n",
    "            image1 = self.train_transform(image)\n",
    "            image2 = self.train_transform(image)\n",
    "            \n",
    "            sample = [[image1, image2], classCategory]\n",
    "        else:\n",
    "            \n",
    "            image = self.test_transform(image)\n",
    "            sample = [image, classCategory]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "\n",
    "train_data = CassavaDataset(data_path, size, s=1, mutation = False)\n",
    "\n",
    "test_data = CassavaDataset(test_path, size, s=1, mutation = False)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, size, s=1, mutation = True)\n",
    "\n",
    "#######################################################################\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "########################################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size_train = 64# 125\n",
    "batch_size_eval = 64 #250\n",
    "n_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_eval,\n",
    "                                             sampler = valid_sampler, num_workers = n_workers)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size = batch_size_eval, \n",
    "                                              shuffle =shuffle_dataset, num_workers = n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(unlabeled_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(next(unlabeled_loader.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e100213220094b8cbf3e9578bc3a1554",
      "8ecfd2a00a874c6cacacbe39ab3f87cc",
      "e3834039bcc6436489e4b5fc04fb4664",
      "554f93f21a4344ada4a1e7c74fe386b7",
      "6f1d2aed682f44f98524873f26408de6",
      "5bb79baa5d7b4c81896e083f9543b33c",
      "56b658779c7745a885cde6850fae178f",
      "1f62ac17ac704e108fa3ea5f52a9ea8d"
     ]
    },
    "colab_type": "code",
    "id": "YGcskdBsytbj",
    "outputId": "48f0c2a3-9800-4c52-cb8a-071e119c5d0d"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "\n",
    "# train_sampler = None\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"unlabeled\", download=True, transform=TransformsSimCLR(size=96)\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, download=True, transform=TransformsSimCLR(size=32)\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.batch_size,\n",
    "#     shuffle=(train_sampler is None),\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "#     sampler=train_sampler,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBlXZwvjzPmp"
   },
   "source": [
    "### Load the SimCLR model, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataset': 'casava',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xERq_yHSzJRX"
   },
   "outputs": [],
   "source": [
    "model, optimizer, scheduler = load_model(args, unlabeled_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0003\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyJ3ulWqzViL"
   },
   "source": [
    "### Setup TensorBoard for logging experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZNieMqfzU7H"
   },
   "outputs": [],
   "source": [
    "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "writer = SummaryWriter(log_dir=tb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xpl6uQiIzbvK"
   },
   "source": [
    "### Create the mask that will remove correlated samples from the negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtNCVEynzjtV"
   },
   "source": [
    "### Initialize the criterion (NT-Xent loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u067AY93zh-k"
   },
   "outputs": [],
   "source": [
    "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NT_Xent(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (similarity_f): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN5KBK-yztGD"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer):\n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "\n",
    "        if x_i.shape[0] != args.batch_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.to(args.device)\n",
    "        x_j = x_j.to(args.device)\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        h_i, z_i = model(x_i)\n",
    "        h_j, z_j = model(x_j)\n",
    "\n",
    "#         ipdb.set_trace()\n",
    "        loss = criterion(z_i, z_j)\n",
    "\n",
    "        if apex and args.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        loss_epoch += loss.item()\n",
    "        args.global_step += 1\n",
    "\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "TdCrD62hzjDQ",
    "outputId": "259e91ae-1fa9-4ccf-b978-9f4ce14c7f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/197]\t Loss: 4.515799522399902\n",
      "Step [50/197]\t Loss: 4.516963481903076\n",
      "Step [100/197]\t Loss: 4.4952311515808105\n",
      "Step [150/197]\t Loss: 4.5351481437683105\n",
      "Epoch [0/100]\t Loss: 4.49011571274191\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 4.470291614532471\n",
      "Step [50/197]\t Loss: 4.598147392272949\n",
      "Step [100/197]\t Loss: 4.407454967498779\n",
      "Step [150/197]\t Loss: 4.158841609954834\n",
      "Epoch [1/100]\t Loss: 4.3127174353236475\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 4.162941932678223\n",
      "Step [50/197]\t Loss: 4.267168998718262\n",
      "Step [100/197]\t Loss: 4.181676864624023\n",
      "Step [150/197]\t Loss: 4.039258003234863\n",
      "Epoch [2/100]\t Loss: 4.127113335023677\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 4.064942359924316\n",
      "Step [50/197]\t Loss: 3.9076011180877686\n",
      "Step [100/197]\t Loss: 3.8971030712127686\n",
      "Step [150/197]\t Loss: 4.091803073883057\n",
      "Epoch [3/100]\t Loss: 4.026782896312965\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 4.051982879638672\n",
      "Step [50/197]\t Loss: 3.994680881500244\n",
      "Step [100/197]\t Loss: 3.9155969619750977\n",
      "Step [150/197]\t Loss: 3.856182336807251\n",
      "Epoch [4/100]\t Loss: 3.9555884871991154\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 3.961850166320801\n",
      "Step [50/197]\t Loss: 3.9322359561920166\n",
      "Step [100/197]\t Loss: 3.9311716556549072\n",
      "Step [150/197]\t Loss: 3.9840571880340576\n",
      "Epoch [5/100]\t Loss: 3.9000035820878702\t lr: 0.0003\n",
      "Step [0/197]\t Loss: 4.004683971405029\n",
      "Step [50/197]\t Loss: 3.7998197078704834\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        \n",
    "        args.global_step = 0\n",
    "        args.current_epoch = 0\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        #     ipdb.set_trace()\n",
    "            loss_epoch = train(args, unlabeled_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                save_model(args, model, optimizer)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(unlabeled_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(unlabeled_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "        ## end training\n",
    "        save_model(args, model, optimizer)\n",
    "    except:\n",
    "        extype, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb, traceback, sys\n",
    "\n",
    "# def bombs():\n",
    "#     a = []\n",
    "#     print (a[0])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     try:\n",
    "#         bombs()\n",
    "#     except:\n",
    "#         extype, value, tb = sys.exc_info()\n",
    "#         traceback.print_exc()\n",
    "#         pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77BXUR9_4hNc"
   },
   "source": [
    "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7eHATk04Sgu"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('./logs/checkpoint_args.epochs.tar') # checkpoint_100.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAQpjiuJy61N"
   },
   "source": [
    "# Part 2:\n",
    "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24wrzMP2vYcV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFyS9RvpuCuC"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZRtPBCLvgqz"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        if step % 1 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skBYAPb2uKB5"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "OJk4-nc-vkF0",
    "outputId": "403ed12f-844f-4a05-e0db-cc5ffca627d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256,\n",
      " 'dataset': 'STL10',\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 100,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "pprint(config)\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "  args.device = dev\n",
    "else:\n",
    "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7cSwhu55KJc"
   },
   "outputs": [],
   "source": [
    "args.batch_size = 64\n",
    "args.resnet = \"resnet18\"\n",
    "args.model_path = \"logs\"\n",
    "args.epoch_num = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWRuVrZZ5Vm1"
   },
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iPGuFjLW5PF9",
    "outputId": "42131d22-129f-4d12-efaf-b01c29d78588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = \"./datasets\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root, train=True, download=True, transform=transform\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root, train=False, download=True, transform=transform\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load SimCLR model and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RTVnvx2a5QnX",
    "outputId": "380865bd-d974-45c4-cf81-956366ddf0f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZoABGRr5Q8_"
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = 10 # stl-10\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T694n_HQ5Tad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vLaebM9Qvztx",
    "outputId": "17fd9ef1-5154-41f5-e8f0-0959e0f82f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/19]\t Loss: 2.544018268585205\t Accuracy: 0.078125\n",
      "Step [1/19]\t Loss: 2.3547680377960205\t Accuracy: 0.15234375\n",
      "Step [2/19]\t Loss: 2.3515422344207764\t Accuracy: 0.140625\n",
      "Step [3/19]\t Loss: 2.2883174419403076\t Accuracy: 0.15234375\n",
      "Step [4/19]\t Loss: 2.2646541595458984\t Accuracy: 0.15625\n",
      "Step [5/19]\t Loss: 2.1859045028686523\t Accuracy: 0.16796875\n",
      "Step [6/19]\t Loss: 2.098809242248535\t Accuracy: 0.25\n",
      "Step [7/19]\t Loss: 2.1023709774017334\t Accuracy: 0.19140625\n",
      "Step [8/19]\t Loss: 2.0565273761749268\t Accuracy: 0.23046875\n",
      "Step [9/19]\t Loss: 2.0184667110443115\t Accuracy: 0.2421875\n",
      "Step [10/19]\t Loss: 1.9349607229232788\t Accuracy: 0.265625\n",
      "Step [11/19]\t Loss: 2.036658525466919\t Accuracy: 0.203125\n",
      "Step [12/19]\t Loss: 1.8934686183929443\t Accuracy: 0.2890625\n",
      "Step [13/19]\t Loss: 1.9491320848464966\t Accuracy: 0.29296875\n",
      "Step [14/19]\t Loss: 1.9400029182434082\t Accuracy: 0.24609375\n",
      "Step [15/19]\t Loss: 1.9001213312149048\t Accuracy: 0.26953125\n",
      "Step [16/19]\t Loss: 1.903915524482727\t Accuracy: 0.28125\n",
      "Step [17/19]\t Loss: 1.900787353515625\t Accuracy: 0.25390625\n",
      "Step [18/19]\t Loss: 1.7889193296432495\t Accuracy: 0.3203125\n",
      "Epoch [0/100]\t Loss: 2.079649755829259\t Accuracy: 0.22018914473684212\n",
      "Step [0/19]\t Loss: 1.8533344268798828\t Accuracy: 0.2578125\n",
      "Step [1/19]\t Loss: 1.820494532585144\t Accuracy: 0.30859375\n",
      "Step [2/19]\t Loss: 1.7906221151351929\t Accuracy: 0.3359375\n",
      "Step [3/19]\t Loss: 1.7609542608261108\t Accuracy: 0.34765625\n",
      "Step [4/19]\t Loss: 1.7768001556396484\t Accuracy: 0.296875\n",
      "Step [5/19]\t Loss: 1.7732914686203003\t Accuracy: 0.3046875\n",
      "Step [6/19]\t Loss: 1.7988678216934204\t Accuracy: 0.30859375\n",
      "Step [7/19]\t Loss: 1.7810144424438477\t Accuracy: 0.296875\n",
      "Step [8/19]\t Loss: 1.761595606803894\t Accuracy: 0.3515625\n",
      "Step [9/19]\t Loss: 1.6519140005111694\t Accuracy: 0.40234375\n",
      "Step [10/19]\t Loss: 1.8189666271209717\t Accuracy: 0.27734375\n",
      "Step [11/19]\t Loss: 1.7181609869003296\t Accuracy: 0.34765625\n",
      "Step [12/19]\t Loss: 1.7759021520614624\t Accuracy: 0.33984375\n",
      "Step [13/19]\t Loss: 1.8043068647384644\t Accuracy: 0.31640625\n",
      "Step [14/19]\t Loss: 1.7252463102340698\t Accuracy: 0.31640625\n",
      "Step [15/19]\t Loss: 1.7353330850601196\t Accuracy: 0.39453125\n",
      "Step [16/19]\t Loss: 1.7285571098327637\t Accuracy: 0.37890625\n",
      "Step [17/19]\t Loss: 1.671054482460022\t Accuracy: 0.3828125\n",
      "Step [18/19]\t Loss: 1.7371623516082764\t Accuracy: 0.34375\n",
      "Epoch [1/100]\t Loss: 1.762293621113426\t Accuracy: 0.33203125\n",
      "Step [0/19]\t Loss: 1.6977534294128418\t Accuracy: 0.35546875\n",
      "Step [1/19]\t Loss: 1.7349754571914673\t Accuracy: 0.328125\n",
      "Step [2/19]\t Loss: 1.7344335317611694\t Accuracy: 0.33984375\n",
      "Step [3/19]\t Loss: 1.6833996772766113\t Accuracy: 0.3359375\n",
      "Step [4/19]\t Loss: 1.7711995840072632\t Accuracy: 0.35546875\n",
      "Step [5/19]\t Loss: 1.7154812812805176\t Accuracy: 0.34375\n",
      "Step [6/19]\t Loss: 1.704146146774292\t Accuracy: 0.3515625\n",
      "Step [7/19]\t Loss: 1.6665728092193604\t Accuracy: 0.40625\n",
      "Step [8/19]\t Loss: 1.7013130187988281\t Accuracy: 0.37890625\n",
      "Step [9/19]\t Loss: 1.7014870643615723\t Accuracy: 0.34375\n",
      "Step [10/19]\t Loss: 1.7236402034759521\t Accuracy: 0.36328125\n",
      "Step [11/19]\t Loss: 1.7269539833068848\t Accuracy: 0.33984375\n",
      "Step [12/19]\t Loss: 1.736963152885437\t Accuracy: 0.3671875\n",
      "Step [13/19]\t Loss: 1.6397716999053955\t Accuracy: 0.41015625\n",
      "Step [14/19]\t Loss: 1.635801911354065\t Accuracy: 0.3984375\n",
      "Step [15/19]\t Loss: 1.6240593194961548\t Accuracy: 0.38671875\n",
      "Step [16/19]\t Loss: 1.6851286888122559\t Accuracy: 0.3671875\n",
      "Step [17/19]\t Loss: 1.5985848903656006\t Accuracy: 0.38671875\n",
      "Step [18/19]\t Loss: 1.7491991519927979\t Accuracy: 0.3359375\n",
      "Epoch [2/100]\t Loss: 1.6963613158778141\t Accuracy: 0.3628700657894737\n",
      "Step [0/19]\t Loss: 1.6758651733398438\t Accuracy: 0.35546875\n",
      "Step [1/19]\t Loss: 1.6566591262817383\t Accuracy: 0.35546875\n",
      "Step [2/19]\t Loss: 1.642861247062683\t Accuracy: 0.37109375\n",
      "Step [3/19]\t Loss: 1.6006141901016235\t Accuracy: 0.3828125\n",
      "Step [4/19]\t Loss: 1.656095266342163\t Accuracy: 0.38671875\n",
      "Step [5/19]\t Loss: 1.6404799222946167\t Accuracy: 0.421875\n",
      "Step [6/19]\t Loss: 1.7699155807495117\t Accuracy: 0.33203125\n",
      "Step [7/19]\t Loss: 1.665748953819275\t Accuracy: 0.37890625\n",
      "Step [8/19]\t Loss: 1.764538049697876\t Accuracy: 0.33203125\n",
      "Step [9/19]\t Loss: 1.6436798572540283\t Accuracy: 0.4140625\n",
      "Step [10/19]\t Loss: 1.7194889783859253\t Accuracy: 0.328125\n",
      "Step [11/19]\t Loss: 1.6690914630889893\t Accuracy: 0.3515625\n",
      "Step [12/19]\t Loss: 1.6515367031097412\t Accuracy: 0.37109375\n",
      "Step [13/19]\t Loss: 1.6348271369934082\t Accuracy: 0.41015625\n",
      "Step [14/19]\t Loss: 1.687121033668518\t Accuracy: 0.33203125\n",
      "Step [15/19]\t Loss: 1.5850378274917603\t Accuracy: 0.41796875\n",
      "Step [16/19]\t Loss: 1.6161924600601196\t Accuracy: 0.42578125\n",
      "Step [17/19]\t Loss: 1.6766542196273804\t Accuracy: 0.3984375\n",
      "Step [18/19]\t Loss: 1.7353179454803467\t Accuracy: 0.32421875\n",
      "Epoch [3/100]\t Loss: 1.6679855334131342\t Accuracy: 0.3731496710526316\n",
      "Step [0/19]\t Loss: 1.5977303981781006\t Accuracy: 0.3984375\n",
      "Step [1/19]\t Loss: 1.7058717012405396\t Accuracy: 0.35546875\n",
      "Step [2/19]\t Loss: 1.6913551092147827\t Accuracy: 0.3515625\n",
      "Step [3/19]\t Loss: 1.6465357542037964\t Accuracy: 0.375\n",
      "Step [4/19]\t Loss: 1.5696672201156616\t Accuracy: 0.3984375\n",
      "Step [5/19]\t Loss: 1.6634827852249146\t Accuracy: 0.33984375\n",
      "Step [6/19]\t Loss: 1.6664822101593018\t Accuracy: 0.40234375\n",
      "Step [7/19]\t Loss: 1.5869122743606567\t Accuracy: 0.390625\n",
      "Step [8/19]\t Loss: 1.7268249988555908\t Accuracy: 0.36328125\n",
      "Step [9/19]\t Loss: 1.614964485168457\t Accuracy: 0.390625\n",
      "Step [10/19]\t Loss: 1.665494441986084\t Accuracy: 0.3671875\n",
      "Step [11/19]\t Loss: 1.644864797592163\t Accuracy: 0.375\n",
      "Step [12/19]\t Loss: 1.6790478229522705\t Accuracy: 0.37890625\n",
      "Step [13/19]\t Loss: 1.7043498754501343\t Accuracy: 0.35546875\n",
      "Step [14/19]\t Loss: 1.608950138092041\t Accuracy: 0.3984375\n",
      "Step [15/19]\t Loss: 1.7213793992996216\t Accuracy: 0.34765625\n",
      "Step [16/19]\t Loss: 1.6865922212600708\t Accuracy: 0.375\n",
      "Step [17/19]\t Loss: 1.6567524671554565\t Accuracy: 0.35546875\n",
      "Step [18/19]\t Loss: 1.5849287509918213\t Accuracy: 0.3984375\n",
      "Epoch [4/100]\t Loss: 1.6537993079737614\t Accuracy: 0.3745888157894737\n",
      "Step [0/19]\t Loss: 1.6765110492706299\t Accuracy: 0.34375\n",
      "Step [1/19]\t Loss: 1.6457583904266357\t Accuracy: 0.42578125\n",
      "Step [2/19]\t Loss: 1.6235965490341187\t Accuracy: 0.37890625\n",
      "Step [3/19]\t Loss: 1.622049331665039\t Accuracy: 0.359375\n",
      "Step [4/19]\t Loss: 1.6798615455627441\t Accuracy: 0.36328125\n",
      "Step [5/19]\t Loss: 1.613617181777954\t Accuracy: 0.41015625\n",
      "Step [6/19]\t Loss: 1.6025718450546265\t Accuracy: 0.40234375\n",
      "Step [7/19]\t Loss: 1.6513032913208008\t Accuracy: 0.390625\n",
      "Step [8/19]\t Loss: 1.6958941221237183\t Accuracy: 0.33203125\n",
      "Step [9/19]\t Loss: 1.6830137968063354\t Accuracy: 0.3359375\n",
      "Step [10/19]\t Loss: 1.6745353937149048\t Accuracy: 0.37109375\n",
      "Step [11/19]\t Loss: 1.6156269311904907\t Accuracy: 0.375\n",
      "Step [12/19]\t Loss: 1.5498963594436646\t Accuracy: 0.4375\n",
      "Step [13/19]\t Loss: 1.6878015995025635\t Accuracy: 0.34765625\n",
      "Step [14/19]\t Loss: 1.6699961423873901\t Accuracy: 0.38671875\n",
      "Step [15/19]\t Loss: 1.5118777751922607\t Accuracy: 0.46484375\n",
      "Step [16/19]\t Loss: 1.6297032833099365\t Accuracy: 0.3984375\n",
      "Step [17/19]\t Loss: 1.6996467113494873\t Accuracy: 0.3125\n",
      "Step [18/19]\t Loss: 1.612075686454773\t Accuracy: 0.3828125\n",
      "Epoch [5/100]\t Loss: 1.6392282623993724\t Accuracy: 0.37993421052631576\n",
      "Step [0/19]\t Loss: 1.6609069108963013\t Accuracy: 0.34765625\n",
      "Step [1/19]\t Loss: 1.7155994176864624\t Accuracy: 0.3203125\n",
      "Step [2/19]\t Loss: 1.5615382194519043\t Accuracy: 0.3828125\n",
      "Step [3/19]\t Loss: 1.630565881729126\t Accuracy: 0.4140625\n",
      "Step [4/19]\t Loss: 1.6479947566986084\t Accuracy: 0.40234375\n",
      "Step [5/19]\t Loss: 1.5975182056427002\t Accuracy: 0.37890625\n",
      "Step [6/19]\t Loss: 1.6780962944030762\t Accuracy: 0.328125\n",
      "Step [7/19]\t Loss: 1.6485215425491333\t Accuracy: 0.3828125\n",
      "Step [8/19]\t Loss: 1.708185076713562\t Accuracy: 0.33203125\n",
      "Step [9/19]\t Loss: 1.5721899271011353\t Accuracy: 0.4140625\n",
      "Step [10/19]\t Loss: 1.6629332304000854\t Accuracy: 0.41015625\n",
      "Step [11/19]\t Loss: 1.5741710662841797\t Accuracy: 0.3984375\n",
      "Step [12/19]\t Loss: 1.6042418479919434\t Accuracy: 0.359375\n",
      "Step [13/19]\t Loss: 1.6553959846496582\t Accuracy: 0.359375\n",
      "Step [14/19]\t Loss: 1.6007046699523926\t Accuracy: 0.421875\n",
      "Step [15/19]\t Loss: 1.6736980676651\t Accuracy: 0.3359375\n",
      "Step [16/19]\t Loss: 1.6082427501678467\t Accuracy: 0.421875\n",
      "Step [17/19]\t Loss: 1.6219245195388794\t Accuracy: 0.43359375\n",
      "Step [18/19]\t Loss: 1.593008279800415\t Accuracy: 0.35546875\n",
      "Epoch [6/100]\t Loss: 1.6323914025959216\t Accuracy: 0.37890625\n",
      "Step [0/19]\t Loss: 1.5854929685592651\t Accuracy: 0.34375\n",
      "Step [1/19]\t Loss: 1.6188125610351562\t Accuracy: 0.4140625\n",
      "Step [2/19]\t Loss: 1.7332983016967773\t Accuracy: 0.296875\n",
      "Step [3/19]\t Loss: 1.622652292251587\t Accuracy: 0.3671875\n",
      "Step [4/19]\t Loss: 1.6110721826553345\t Accuracy: 0.37109375\n",
      "Step [5/19]\t Loss: 1.581559419631958\t Accuracy: 0.4140625\n",
      "Step [6/19]\t Loss: 1.670680284500122\t Accuracy: 0.36328125\n",
      "Step [7/19]\t Loss: 1.6040613651275635\t Accuracy: 0.4296875\n",
      "Step [8/19]\t Loss: 1.5602174997329712\t Accuracy: 0.44140625\n",
      "Step [9/19]\t Loss: 1.6708269119262695\t Accuracy: 0.3515625\n",
      "Step [10/19]\t Loss: 1.615417242050171\t Accuracy: 0.3984375\n",
      "Step [11/19]\t Loss: 1.6206169128417969\t Accuracy: 0.34375\n",
      "Step [12/19]\t Loss: 1.6251261234283447\t Accuracy: 0.39453125\n",
      "Step [13/19]\t Loss: 1.7028546333312988\t Accuracy: 0.3671875\n",
      "Step [14/19]\t Loss: 1.6073291301727295\t Accuracy: 0.390625\n",
      "Step [15/19]\t Loss: 1.6358542442321777\t Accuracy: 0.36328125\n",
      "Step [16/19]\t Loss: 1.6093772649765015\t Accuracy: 0.41015625\n",
      "Step [17/19]\t Loss: 1.684207558631897\t Accuracy: 0.33984375\n",
      "Step [18/19]\t Loss: 1.5942816734313965\t Accuracy: 0.38671875\n",
      "Epoch [7/100]\t Loss: 1.6291441352743852\t Accuracy: 0.3782894736842105\n",
      "Step [0/19]\t Loss: 1.6709935665130615\t Accuracy: 0.34375\n",
      "Step [1/19]\t Loss: 1.5849086046218872\t Accuracy: 0.3984375\n",
      "Step [2/19]\t Loss: 1.5831149816513062\t Accuracy: 0.421875\n",
      "Step [3/19]\t Loss: 1.617908239364624\t Accuracy: 0.421875\n",
      "Step [4/19]\t Loss: 1.6089116334915161\t Accuracy: 0.390625\n",
      "Step [5/19]\t Loss: 1.6601451635360718\t Accuracy: 0.33203125\n",
      "Step [6/19]\t Loss: 1.6460832357406616\t Accuracy: 0.328125\n",
      "Step [7/19]\t Loss: 1.6959549188613892\t Accuracy: 0.33984375\n",
      "Step [8/19]\t Loss: 1.6516554355621338\t Accuracy: 0.3515625\n",
      "Step [9/19]\t Loss: 1.5723892450332642\t Accuracy: 0.40234375\n",
      "Step [10/19]\t Loss: 1.6796480417251587\t Accuracy: 0.33984375\n",
      "Step [11/19]\t Loss: 1.5526585578918457\t Accuracy: 0.41015625\n",
      "Step [12/19]\t Loss: 1.656624674797058\t Accuracy: 0.3671875\n",
      "Step [13/19]\t Loss: 1.6415741443634033\t Accuracy: 0.359375\n",
      "Step [14/19]\t Loss: 1.65240478515625\t Accuracy: 0.34375\n",
      "Step [15/19]\t Loss: 1.6464450359344482\t Accuracy: 0.38671875\n",
      "Step [16/19]\t Loss: 1.5443782806396484\t Accuracy: 0.43359375\n",
      "Step [17/19]\t Loss: 1.5477726459503174\t Accuracy: 0.40234375\n",
      "Step [18/19]\t Loss: 1.5683809518814087\t Accuracy: 0.41015625\n",
      "Epoch [8/100]\t Loss: 1.620102744353445\t Accuracy: 0.37808388157894735\n",
      "Step [0/19]\t Loss: 1.5455598831176758\t Accuracy: 0.42578125\n",
      "Step [1/19]\t Loss: 1.5993746519088745\t Accuracy: 0.38671875\n",
      "Step [2/19]\t Loss: 1.580363392829895\t Accuracy: 0.4375\n",
      "Step [3/19]\t Loss: 1.6168969869613647\t Accuracy: 0.37109375\n",
      "Step [4/19]\t Loss: 1.673485279083252\t Accuracy: 0.37109375\n",
      "Step [5/19]\t Loss: 1.5601886510849\t Accuracy: 0.390625\n",
      "Step [6/19]\t Loss: 1.595913052558899\t Accuracy: 0.38671875\n",
      "Step [7/19]\t Loss: 1.62919282913208\t Accuracy: 0.390625\n",
      "Step [8/19]\t Loss: 1.6934559345245361\t Accuracy: 0.3671875\n",
      "Step [9/19]\t Loss: 1.5992988348007202\t Accuracy: 0.3671875\n",
      "Step [10/19]\t Loss: 1.6330454349517822\t Accuracy: 0.3671875\n",
      "Step [11/19]\t Loss: 1.549881935119629\t Accuracy: 0.40234375\n",
      "Step [12/19]\t Loss: 1.6651560068130493\t Accuracy: 0.37109375\n",
      "Step [13/19]\t Loss: 1.5397133827209473\t Accuracy: 0.3984375\n",
      "Step [14/19]\t Loss: 1.6248360872268677\t Accuracy: 0.34765625\n",
      "Step [15/19]\t Loss: 1.6245613098144531\t Accuracy: 0.359375\n",
      "Step [16/19]\t Loss: 1.5741639137268066\t Accuracy: 0.3984375\n",
      "Step [17/19]\t Loss: 1.65854012966156\t Accuracy: 0.37109375\n",
      "Step [18/19]\t Loss: 1.637812614440918\t Accuracy: 0.39453125\n",
      "Epoch [9/100]\t Loss: 1.6106021216041164\t Accuracy: 0.38445723684210525\n",
      "Step [0/19]\t Loss: 1.5983933210372925\t Accuracy: 0.375\n",
      "Step [1/19]\t Loss: 1.6112325191497803\t Accuracy: 0.4140625\n",
      "Step [2/19]\t Loss: 1.593293309211731\t Accuracy: 0.41015625\n",
      "Step [3/19]\t Loss: 1.6514917612075806\t Accuracy: 0.35546875\n",
      "Step [4/19]\t Loss: 1.6371936798095703\t Accuracy: 0.390625\n",
      "Step [5/19]\t Loss: 1.5834516286849976\t Accuracy: 0.3828125\n",
      "Step [6/19]\t Loss: 1.6219559907913208\t Accuracy: 0.390625\n",
      "Step [7/19]\t Loss: 1.614629864692688\t Accuracy: 0.359375\n",
      "Step [8/19]\t Loss: 1.5588339567184448\t Accuracy: 0.4296875\n",
      "Step [9/19]\t Loss: 1.557079792022705\t Accuracy: 0.38671875\n",
      "Step [10/19]\t Loss: 1.5774118900299072\t Accuracy: 0.3828125\n",
      "Step [11/19]\t Loss: 1.6390622854232788\t Accuracy: 0.36328125\n",
      "Step [12/19]\t Loss: 1.6464207172393799\t Accuracy: 0.3984375\n",
      "Step [13/19]\t Loss: 1.6143687963485718\t Accuracy: 0.33984375\n",
      "Step [14/19]\t Loss: 1.6327375173568726\t Accuracy: 0.40625\n",
      "Step [15/19]\t Loss: 1.619753122329712\t Accuracy: 0.39453125\n",
      "Step [16/19]\t Loss: 1.6297775506973267\t Accuracy: 0.390625\n",
      "Step [17/19]\t Loss: 1.6863077878952026\t Accuracy: 0.36328125\n",
      "Step [18/19]\t Loss: 1.4886953830718994\t Accuracy: 0.4375\n",
      "Epoch [10/100]\t Loss: 1.6085310986167507\t Accuracy: 0.3879523026315789\n",
      "Step [0/19]\t Loss: 1.6645429134368896\t Accuracy: 0.39453125\n",
      "Step [1/19]\t Loss: 1.700981616973877\t Accuracy: 0.34375\n",
      "Step [2/19]\t Loss: 1.6445701122283936\t Accuracy: 0.3984375\n",
      "Step [3/19]\t Loss: 1.4894057512283325\t Accuracy: 0.39453125\n",
      "Step [4/19]\t Loss: 1.5790742635726929\t Accuracy: 0.44140625\n",
      "Step [5/19]\t Loss: 1.682930588722229\t Accuracy: 0.38671875\n",
      "Step [6/19]\t Loss: 1.5898480415344238\t Accuracy: 0.38671875\n",
      "Step [7/19]\t Loss: 1.6235228776931763\t Accuracy: 0.3671875\n",
      "Step [8/19]\t Loss: 1.5517734289169312\t Accuracy: 0.37890625\n",
      "Step [9/19]\t Loss: 1.5852473974227905\t Accuracy: 0.43359375\n",
      "Step [10/19]\t Loss: 1.5909358263015747\t Accuracy: 0.4140625\n",
      "Step [11/19]\t Loss: 1.5560544729232788\t Accuracy: 0.43359375\n",
      "Step [12/19]\t Loss: 1.6564710140228271\t Accuracy: 0.3203125\n",
      "Step [13/19]\t Loss: 1.619910717010498\t Accuracy: 0.35546875\n",
      "Step [14/19]\t Loss: 1.6468697786331177\t Accuracy: 0.35546875\n",
      "Step [15/19]\t Loss: 1.5295487642288208\t Accuracy: 0.4375\n",
      "Step [16/19]\t Loss: 1.5796728134155273\t Accuracy: 0.39453125\n",
      "Step [17/19]\t Loss: 1.6489187479019165\t Accuracy: 0.375\n",
      "Step [18/19]\t Loss: 1.554821491241455\t Accuracy: 0.42578125\n",
      "Epoch [11/100]\t Loss: 1.6050052956530922\t Accuracy: 0.39144736842105265\n",
      "Step [0/19]\t Loss: 1.65535306930542\t Accuracy: 0.36328125\n",
      "Step [1/19]\t Loss: 1.5960875749588013\t Accuracy: 0.3828125\n",
      "Step [2/19]\t Loss: 1.6357600688934326\t Accuracy: 0.3359375\n",
      "Step [3/19]\t Loss: 1.5602843761444092\t Accuracy: 0.39453125\n",
      "Step [4/19]\t Loss: 1.6417330503463745\t Accuracy: 0.3515625\n",
      "Step [5/19]\t Loss: 1.637134313583374\t Accuracy: 0.390625\n",
      "Step [6/19]\t Loss: 1.6138890981674194\t Accuracy: 0.38671875\n",
      "Step [7/19]\t Loss: 1.5908615589141846\t Accuracy: 0.4453125\n",
      "Step [8/19]\t Loss: 1.6812797784805298\t Accuracy: 0.37109375\n",
      "Step [9/19]\t Loss: 1.5694811344146729\t Accuracy: 0.4296875\n",
      "Step [10/19]\t Loss: 1.6294846534729004\t Accuracy: 0.3671875\n",
      "Step [11/19]\t Loss: 1.5059852600097656\t Accuracy: 0.44140625\n",
      "Step [12/19]\t Loss: 1.5108911991119385\t Accuracy: 0.43359375\n",
      "Step [13/19]\t Loss: 1.5671889781951904\t Accuracy: 0.41796875\n",
      "Step [14/19]\t Loss: 1.623499870300293\t Accuracy: 0.36328125\n",
      "Step [15/19]\t Loss: 1.6256581544876099\t Accuracy: 0.41015625\n",
      "Step [16/19]\t Loss: 1.559511423110962\t Accuracy: 0.40234375\n",
      "Step [17/19]\t Loss: 1.6267871856689453\t Accuracy: 0.3984375\n",
      "Step [18/19]\t Loss: 1.56148362159729\t Accuracy: 0.42578125\n",
      "Epoch [12/100]\t Loss: 1.599597598377027\t Accuracy: 0.39535361842105265\n",
      "Step [0/19]\t Loss: 1.6151013374328613\t Accuracy: 0.39453125\n",
      "Step [1/19]\t Loss: 1.479595422744751\t Accuracy: 0.44140625\n",
      "Step [2/19]\t Loss: 1.6732743978500366\t Accuracy: 0.37890625\n",
      "Step [3/19]\t Loss: 1.7234843969345093\t Accuracy: 0.33203125\n",
      "Step [4/19]\t Loss: 1.5153836011886597\t Accuracy: 0.40234375\n",
      "Step [5/19]\t Loss: 1.6630659103393555\t Accuracy: 0.3359375\n",
      "Step [6/19]\t Loss: 1.607507348060608\t Accuracy: 0.390625\n",
      "Step [7/19]\t Loss: 1.5361669063568115\t Accuracy: 0.41015625\n",
      "Step [8/19]\t Loss: 1.6107515096664429\t Accuracy: 0.37890625\n",
      "Step [9/19]\t Loss: 1.5588154792785645\t Accuracy: 0.4140625\n",
      "Step [10/19]\t Loss: 1.6353029012680054\t Accuracy: 0.4140625\n",
      "Step [11/19]\t Loss: 1.6044658422470093\t Accuracy: 0.375\n",
      "Step [12/19]\t Loss: 1.548543095588684\t Accuracy: 0.390625\n",
      "Step [13/19]\t Loss: 1.6177181005477905\t Accuracy: 0.4140625\n",
      "Step [14/19]\t Loss: 1.5038573741912842\t Accuracy: 0.4453125\n",
      "Step [15/19]\t Loss: 1.5843210220336914\t Accuracy: 0.375\n",
      "Step [16/19]\t Loss: 1.6463583707809448\t Accuracy: 0.38671875\n",
      "Step [17/19]\t Loss: 1.6049410104751587\t Accuracy: 0.41796875\n",
      "Step [18/19]\t Loss: 1.6622906923294067\t Accuracy: 0.3515625\n",
      "Epoch [13/100]\t Loss: 1.5995234062797146\t Accuracy: 0.3920641447368421\n",
      "Step [0/19]\t Loss: 1.5912044048309326\t Accuracy: 0.40625\n",
      "Step [1/19]\t Loss: 1.621862530708313\t Accuracy: 0.3828125\n",
      "Step [2/19]\t Loss: 1.6498146057128906\t Accuracy: 0.3515625\n",
      "Step [3/19]\t Loss: 1.6115361452102661\t Accuracy: 0.39453125\n",
      "Step [4/19]\t Loss: 1.5847315788269043\t Accuracy: 0.41015625\n",
      "Step [5/19]\t Loss: 1.6252859830856323\t Accuracy: 0.33203125\n",
      "Step [6/19]\t Loss: 1.5731561183929443\t Accuracy: 0.40625\n",
      "Step [7/19]\t Loss: 1.6003528833389282\t Accuracy: 0.41796875\n",
      "Step [8/19]\t Loss: 1.5631126165390015\t Accuracy: 0.41796875\n",
      "Step [9/19]\t Loss: 1.570780873298645\t Accuracy: 0.41796875\n",
      "Step [10/19]\t Loss: 1.575444221496582\t Accuracy: 0.4296875\n",
      "Step [11/19]\t Loss: 1.6237848997116089\t Accuracy: 0.390625\n",
      "Step [12/19]\t Loss: 1.6335185766220093\t Accuracy: 0.37109375\n",
      "Step [13/19]\t Loss: 1.589136004447937\t Accuracy: 0.4140625\n",
      "Step [14/19]\t Loss: 1.5611680746078491\t Accuracy: 0.40234375\n",
      "Step [15/19]\t Loss: 1.6170564889907837\t Accuracy: 0.38671875\n",
      "Step [16/19]\t Loss: 1.6051356792449951\t Accuracy: 0.37890625\n",
      "Step [17/19]\t Loss: 1.5803807973861694\t Accuracy: 0.42578125\n",
      "Step [18/19]\t Loss: 1.6419527530670166\t Accuracy: 0.37109375\n",
      "Epoch [14/100]\t Loss: 1.6010218545010215\t Accuracy: 0.3951480263157895\n",
      "Step [0/19]\t Loss: 1.5659587383270264\t Accuracy: 0.390625\n",
      "Step [1/19]\t Loss: 1.6240407228469849\t Accuracy: 0.37890625\n",
      "Step [2/19]\t Loss: 1.6798001527786255\t Accuracy: 0.3515625\n",
      "Step [3/19]\t Loss: 1.5405457019805908\t Accuracy: 0.40234375\n",
      "Step [4/19]\t Loss: 1.5795845985412598\t Accuracy: 0.43359375\n",
      "Step [5/19]\t Loss: 1.638419508934021\t Accuracy: 0.3828125\n",
      "Step [6/19]\t Loss: 1.5186413526535034\t Accuracy: 0.46484375\n",
      "Step [7/19]\t Loss: 1.6143360137939453\t Accuracy: 0.33984375\n",
      "Step [8/19]\t Loss: 1.5565897226333618\t Accuracy: 0.40625\n",
      "Step [9/19]\t Loss: 1.6767033338546753\t Accuracy: 0.375\n",
      "Step [10/19]\t Loss: 1.554260015487671\t Accuracy: 0.42578125\n",
      "Step [11/19]\t Loss: 1.5842801332473755\t Accuracy: 0.390625\n",
      "Step [12/19]\t Loss: 1.6256732940673828\t Accuracy: 0.37890625\n",
      "Step [13/19]\t Loss: 1.5799578428268433\t Accuracy: 0.37109375\n",
      "Step [14/19]\t Loss: 1.6374512910842896\t Accuracy: 0.35546875\n",
      "Step [15/19]\t Loss: 1.5311768054962158\t Accuracy: 0.4296875\n",
      "Step [16/19]\t Loss: 1.6027891635894775\t Accuracy: 0.3515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-aab1da4690d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# final testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-c3d5ef04111d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SimCLR Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:simclr]",
   "language": "python",
   "name": "conda-env-simclr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f62ac17ac704e108fa3ea5f52a9ea8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554f93f21a4344ada4a1e7c74fe386b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62ac17ac704e108fa3ea5f52a9ea8d",
      "placeholder": "​",
      "style": "IPY_MODEL_56b658779c7745a885cde6850fae178f",
      "value": " 170500096/? [00:19&lt;00:00, 93331221.18it/s]"
     }
    },
    "56b658779c7745a885cde6850fae178f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb79baa5d7b4c81896e083f9543b33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f1d2aed682f44f98524873f26408de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8ecfd2a00a874c6cacacbe39ab3f87cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e100213220094b8cbf3e9578bc3a1554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3834039bcc6436489e4b5fc04fb4664",
       "IPY_MODEL_554f93f21a4344ada4a1e7c74fe386b7"
      ],
      "layout": "IPY_MODEL_8ecfd2a00a874c6cacacbe39ab3f87cc"
     }
    },
    "e3834039bcc6436489e4b5fc04fb4664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb79baa5d7b4c81896e083f9543b33c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f1d2aed682f44f98524873f26408de6",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
