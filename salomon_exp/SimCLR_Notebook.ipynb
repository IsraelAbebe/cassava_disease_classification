{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF8ZoVrwt0n0"
   },
   "source": [
    "# SimCLR\n",
    "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
    "\n",
    "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt6WMxjCvN3o"
   },
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrainedmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.5.0+cu101)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.6.0+cu101)\n",
      "Collecting munch\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.38.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.18.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (7.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.12.0)\n",
      "Building wheels for collected packages: pretrainedmodels\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=9680c6892868aed95eade852935f5c7b209765d94739bac3c5dd8c5890587031\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
      "Successfully built pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels\n",
      "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "53JMIYtat8tT",
    "outputId": "82df4c10-ad67-4917-8963-43ee477f666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/cassava_disease_classification/salomon_exp/SimCLR-1\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/Kabongosalomon/SimCLR-1.git\n",
    "%cd SimCLR-1\n",
    "# !wget https://github.com/Kabongosalomon/SimCLR-1/releases/download/1.2/checkpoint_100.tar\n",
    "# !sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "# !pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.1.3)\n",
      "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "\n",
    "from experiment import ex\n",
    "from model import load_model\n",
    "from utils import post_config_hook\n",
    "\n",
    "from modules import LogisticRegression\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQ3jq3cWynLf"
   },
   "source": [
    "# Part 1:\n",
    "## SimCLR pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jhAv3hv8IHn"
   },
   "outputs": [],
   "source": [
    "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
    "use_tpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwW10d2O7pn8"
   },
   "source": [
    "#### Install PyTorch/XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj84aiC27oxS"
   },
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNDRcPbbymlX",
    "outputId": "383ea8ab-6aaf-40fd-8e59-57ee443371ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if use_tpu:\n",
    "    # imports the torch_xla package for TPU support\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    dev = xm.xla_device()\n",
    "    print(dev)\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "from model import load_model, save_model\n",
    "from modules import NT_Xent\n",
    "from modules.transformations import TransformsSimCLR\n",
    "from utils import post_config_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYbV0fa_y03Z"
   },
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klUf-IuyxdL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args.out_dir = \"logs\"\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "O86__UhA0Lvr",
    "outputId": "295583f8-ba5b-488e-ac1a-58015273bb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 125,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "args.batch_size = 125\n",
    "args.resnet = \"resnet18\" # \n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'casava'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 20\n",
    "args.epoch_num = 20\n",
    "\n",
    "args.projection_dim = 125\n",
    "\n",
    "args.logistic_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJfeOM9PzNoF"
   },
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/train/train\"\n",
    "test_path = \"../data/test/test\"\n",
    "extraimage_path = \"../data/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "healthy:316\n",
      "cbsd:1443\n",
      "cbb:466\n",
      "cgm:773\n",
      "cmd:2658\n",
      "(500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cbb': 466, 'cbsd': 1443, 'cgm': 773, 'cmd': 2658, 'healthy': 316}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train set:')\n",
    "class_distrbution = {}\n",
    "for cls in os.listdir(data_path):\n",
    "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
    "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
    "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
    "print(im.size)\n",
    "class_distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, size, s=1, mutation = False):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.mutation = mutation\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        \n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((size, size)),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        files = []\n",
    "        class_names = {}\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "\n",
    "                name = str(i)+'-'+className\n",
    "                if name not in class_names:\n",
    "                    class_names[name] = 1\n",
    "                else:\n",
    "                    class_names[name] += 1\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        image = Image.open(fileName)\n",
    "\n",
    "        if self.mutation:\n",
    "            image1 = self.train_transform(image)\n",
    "            image2 = self.train_transform(image)\n",
    "            \n",
    "            sample = [[image1, image2], classCategory]\n",
    "        else:\n",
    "            \n",
    "            image = self.test_transform(image)\n",
    "            sample = [image, classCategory]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "\n",
    "train_data = CassavaDataset(data_path, size, s=1, mutation = False)\n",
    "\n",
    "test_data = CassavaDataset(test_path, size, s=1, mutation = False)\n",
    "\n",
    "extraimage_data = CassavaDataset(extraimage_path, size, s=1, mutation = True)\n",
    "\n",
    "#######################################################################\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42 #42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "########################################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "batch_size_train = 125# 125\n",
    "batch_size_eval = 125 #250\n",
    "n_workers = 2\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_train,\n",
    "                                             sampler = train_sampler, num_workers = n_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size_eval,\n",
    "                                             sampler = valid_sampler, num_workers = n_workers)\n",
    "\n",
    "unlabeled_loader = torch.utils.data.DataLoader(extraimage_data, batch_size = batch_size_eval, \n",
    "                                              shuffle =shuffle_dataset, num_workers = n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(unlabeled_loader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(next(unlabeled_loader.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e100213220094b8cbf3e9578bc3a1554",
      "8ecfd2a00a874c6cacacbe39ab3f87cc",
      "e3834039bcc6436489e4b5fc04fb4664",
      "554f93f21a4344ada4a1e7c74fe386b7",
      "6f1d2aed682f44f98524873f26408de6",
      "5bb79baa5d7b4c81896e083f9543b33c",
      "56b658779c7745a885cde6850fae178f",
      "1f62ac17ac704e108fa3ea5f52a9ea8d"
     ]
    },
    "colab_type": "code",
    "id": "YGcskdBsytbj",
    "outputId": "48f0c2a3-9800-4c52-cb8a-071e119c5d0d"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "\n",
    "# train_sampler = None\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"unlabeled\", download=True, transform=TransformsSimCLR(size=96)\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, download=True, transform=TransformsSimCLR(size=32)\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.batch_size,\n",
    "#     shuffle=(train_sampler is None),\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "#     sampler=train_sampler,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBlXZwvjzPmp"
   },
   "source": [
    "### Load the SimCLR model, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 125,\n",
      " 'dataset': 'casava',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 20,\n",
      " 'epochs': 20,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 20,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'logs',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 125,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.projection_dim = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xERq_yHSzJRX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409a663651974f45a767a16dc875a95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth\" to /root/.cache/torch/checkpoints/se_resnet50-ce0d4300.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821a7a28f43f42a5993bc3cc0cf6942f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112611220), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, scheduler = load_model(args, unlabeled_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=125, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyJ3ulWqzViL"
   },
   "source": [
    "### Setup TensorBoard for logging experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZNieMqfzU7H"
   },
   "outputs": [],
   "source": [
    "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "writer = SummaryWriter(log_dir=tb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xpl6uQiIzbvK"
   },
   "source": [
    "### Create the mask that will remove correlated samples from the negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtNCVEynzjtV"
   },
   "source": [
    "### Initialize the criterion (NT-Xent loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u067AY93zh-k"
   },
   "outputs": [],
   "source": [
    "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NT_Xent(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (similarity_f): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN5KBK-yztGD"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer):\n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "\n",
    "        if x_i.shape[0] != args.batch_size:\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.to(args.device)\n",
    "        x_j = x_j.to(args.device)\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        h_i, z_i = model(x_i)\n",
    "        h_j, z_j = model(x_j)\n",
    "\n",
    "#         ipdb.set_trace()\n",
    "        loss = criterion(z_i, z_j)\n",
    "\n",
    "        if apex and args.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        loss_epoch += loss.item()\n",
    "        args.global_step += 1\n",
    "\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/101]\t Loss: 5.378081321716309\n",
      "Step [50/101]\t Loss: 4.22678279876709\n",
      "Epoch [0/20]\t Loss: 4.284260721489934\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.1650495529174805\n",
      "Step [50/101]\t Loss: 4.117736339569092\n",
      "Epoch [1/20]\t Loss: 4.046436411319393\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.0341410636901855\n",
      "Step [50/101]\t Loss: 4.010402202606201\n",
      "Epoch [2/20]\t Loss: 4.001922099897177\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.050032615661621\n",
      "Step [50/101]\t Loss: 3.9922380447387695\n",
      "Epoch [3/20]\t Loss: 3.9678459379932667\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.946702003479004\n",
      "Step [50/101]\t Loss: 4.040078163146973\n",
      "Epoch [4/20]\t Loss: 3.9486640373078905\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.971569538116455\n",
      "Step [50/101]\t Loss: 3.9605798721313477\n",
      "Epoch [5/20]\t Loss: 3.9370357046032898\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9507763385772705\n",
      "Step [50/101]\t Loss: 3.9254724979400635\n",
      "Epoch [6/20]\t Loss: 3.9252730289308153\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.978753089904785\n",
      "Step [50/101]\t Loss: 3.9122629165649414\n",
      "Epoch [7/20]\t Loss: 3.908475330560514\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.917720079421997\n",
      "Step [50/101]\t Loss: 3.929980516433716\n",
      "Epoch [8/20]\t Loss: 3.910165774940264\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9238624572753906\n",
      "Step [50/101]\t Loss: 3.92535662651062\n",
      "Epoch [9/20]\t Loss: 3.89538837423419\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9313161373138428\n",
      "Step [50/101]\t Loss: 3.875788450241089\n",
      "Epoch [10/20]\t Loss: 3.88971214719338\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.921940326690674\n",
      "Step [50/101]\t Loss: 3.911146402359009\n",
      "Epoch [11/20]\t Loss: 3.883233851725512\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9078164100646973\n",
      "Step [50/101]\t Loss: 3.9259679317474365\n",
      "Epoch [12/20]\t Loss: 3.8839688088634228\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9132957458496094\n",
      "Step [50/101]\t Loss: 3.9217076301574707\n",
      "Epoch [13/20]\t Loss: 3.875321862721207\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9303996562957764\n",
      "Step [50/101]\t Loss: 3.906965494155884\n",
      "Epoch [14/20]\t Loss: 3.87299639635747\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.885793685913086\n",
      "Step [50/101]\t Loss: 3.886220932006836\n",
      "Epoch [15/20]\t Loss: 3.873833982071074\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.908318042755127\n",
      "Step [50/101]\t Loss: 3.9212138652801514\n",
      "Epoch [16/20]\t Loss: 3.869410200874404\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.897831439971924\n",
      "Step [50/101]\t Loss: 3.842320442199707\n",
      "Epoch [17/20]\t Loss: 3.858624231697309\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.9002254009246826\n",
      "Step [50/101]\t Loss: 3.9118635654449463\n",
      "Epoch [18/20]\t Loss: 3.8596723858672792\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 3.8596031665802\n",
      "Step [50/101]\t Loss: 3.8661558628082275\n",
      "Epoch [19/20]\t Loss: 3.852429016981975\t lr: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        \n",
    "        args.global_step = 0\n",
    "        args.current_epoch = 0\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        #     ipdb.set_trace()\n",
    "            loss_epoch = train(args, unlabeled_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                save_model(args, model, optimizer)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(unlabeled_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(unlabeled_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "        ## end training\n",
    "        save_model(args, model, optimizer)\n",
    "    except:\n",
    "        extype, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "TdCrD62hzjDQ",
    "outputId": "259e91ae-1fa9-4ccf-b978-9f4ce14c7f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/101]\t Loss: 5.506179332733154\n",
      "Step [50/101]\t Loss: 5.432827472686768\n",
      "Epoch [0/20]\t Loss: 5.271726820728566\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.969191074371338\n",
      "Step [50/101]\t Loss: 5.021357536315918\n",
      "Epoch [1/20]\t Loss: 5.034497865355841\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.9862518310546875\n",
      "Step [50/101]\t Loss: 4.900743007659912\n",
      "Epoch [2/20]\t Loss: 4.8258984442984705\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.807394504547119\n",
      "Step [50/101]\t Loss: 4.828079700469971\n",
      "Epoch [3/20]\t Loss: 4.66922378067923\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.638996124267578\n",
      "Step [50/101]\t Loss: 4.709902763366699\n",
      "Epoch [4/20]\t Loss: 4.572105369945564\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.540196895599365\n",
      "Step [50/101]\t Loss: 4.555490493774414\n",
      "Epoch [5/20]\t Loss: 4.513140815319401\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.573647975921631\n",
      "Step [50/101]\t Loss: 4.508334636688232\n",
      "Epoch [6/20]\t Loss: 4.490872123453877\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.494942665100098\n",
      "Step [50/101]\t Loss: 4.498405933380127\n",
      "Epoch [7/20]\t Loss: 4.456653476941703\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.44772481918335\n",
      "Step [50/101]\t Loss: 4.474287509918213\n",
      "Epoch [8/20]\t Loss: 4.437755216466318\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.426217555999756\n",
      "Step [50/101]\t Loss: 4.47157096862793\n",
      "Epoch [9/20]\t Loss: 4.415010253981788\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.5384440422058105\n",
      "Step [50/101]\t Loss: 4.441305160522461\n",
      "Epoch [10/20]\t Loss: 4.3988769219653445\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.437762260437012\n",
      "Step [50/101]\t Loss: 4.381251811981201\n",
      "Epoch [11/20]\t Loss: 4.3755244736624235\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.301000595092773\n",
      "Step [50/101]\t Loss: 4.428627967834473\n",
      "Epoch [12/20]\t Loss: 4.351391905605203\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.421194076538086\n",
      "Step [50/101]\t Loss: 4.4758782386779785\n",
      "Epoch [13/20]\t Loss: 4.348623204939436\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.356816291809082\n",
      "Step [50/101]\t Loss: 4.365453243255615\n",
      "Epoch [14/20]\t Loss: 4.321013242891519\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.343160629272461\n",
      "Step [50/101]\t Loss: 4.388178825378418\n",
      "Epoch [15/20]\t Loss: 4.3078921242515635\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.297610759735107\n",
      "Step [50/101]\t Loss: 4.365362644195557\n",
      "Epoch [16/20]\t Loss: 4.296993184797834\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.29519510269165\n",
      "Step [50/101]\t Loss: 4.308860778808594\n",
      "Epoch [17/20]\t Loss: 4.286001073251857\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.374560832977295\n",
      "Step [50/101]\t Loss: 4.34701681137085\n",
      "Epoch [18/20]\t Loss: 4.286937487007368\t lr: 0.0002\n",
      "Step [0/101]\t Loss: 4.2655029296875\n",
      "Step [50/101]\t Loss: 4.230329513549805\n",
      "Epoch [19/20]\t Loss: 4.264556960304184\t lr: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import pdb, traceback, sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        \n",
    "        args.global_step = 0\n",
    "        args.current_epoch = 0\n",
    "        for epoch in range(args.start_epoch, args.epochs):\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        #     ipdb.set_trace()\n",
    "            loss_epoch = train(args, unlabeled_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                save_model(args, model, optimizer)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(unlabeled_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(unlabeled_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "        ## end training\n",
    "        save_model(args, model, optimizer)\n",
    "    except:\n",
    "        extype, value, tb = sys.exc_info()\n",
    "        traceback.print_exc()\n",
    "        pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb, traceback, sys\n",
    "\n",
    "# def bombs():\n",
    "#     a = []\n",
    "#     print (a[0])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     try:\n",
    "#         bombs()\n",
    "#     except:\n",
    "#         extype, value, tb = sys.exc_info()\n",
    "#         traceback.print_exc()\n",
    "#         pdb.post_mortem(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77BXUR9_4hNc"
   },
   "source": [
    "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7eHATk04Sgu"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download('./logs/checkpoint_'+args.epochs.tar) # checkpoint_100.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAQpjiuJy61N"
   },
   "source": [
    "# Part 2:\n",
    "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24wrzMP2vYcV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFyS9RvpuCuC"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZRtPBCLvgqz"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skBYAPb2uKB5"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, z = simclr_model(x)\n",
    "            # h = 512\n",
    "            # z = 64\n",
    "\n",
    "        output = model(h)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "OJk4-nc-vkF0",
    "outputId": "403ed12f-844f-4a05-e0db-cc5ffca627d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'logs/0',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "pprint(config)\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "if use_tpu:\n",
    "    args.device = dev\n",
    "else:\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7cSwhu55KJc"
   },
   "outputs": [],
   "source": [
    "args.batch_size = 125\n",
    "args.resnet = \"resnet18\"\n",
    "args.model_path = \"logs\"\n",
    "args.epoch_num = 20 # 100\n",
    "args.projection_dim =125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWRuVrZZ5Vm1"
   },
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iPGuFjLW5PF9",
    "outputId": "42131d22-129f-4d12-efaf-b01c29d78588"
   },
   "outputs": [],
   "source": [
    "# root = \"./datasets\"\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# if args.dataset == \"STL10\":\n",
    "#     train_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.STL10(\n",
    "#         root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
    "#     )\n",
    "# elif args.dataset == \"CIFAR10\":\n",
    "#     train_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=True, download=True, transform=transform\n",
    "#     )\n",
    "#     test_dataset = torchvision.datasets.CIFAR10(\n",
    "#         root, train=False, download=True, transform=transform\n",
    "#     )\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=args.logistic_batch_size,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True,\n",
    "#     num_workers=args.workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load SimCLR model and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RTVnvx2a5QnX",
    "outputId": "380865bd-d974-45c4-cf81-956366ddf0f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=125, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZoABGRr5Q8_"
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = 5 # stl-10\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T694n_HQ5Tad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/37]\t Loss: 1.9253181219100952\t Accuracy: 0.088\n",
      "Epoch [0/500]\t Loss: 1.362829578889383\t Accuracy: 0.4864864864864865\n",
      "Step [0/37]\t Loss: 1.0069397687911987\t Accuracy: 0.648\n",
      "Epoch [1/500]\t Loss: 1.0447613999650285\t Accuracy: 0.6443243243243244\n",
      "Step [0/37]\t Loss: 0.9092667102813721\t Accuracy: 0.688\n",
      "Epoch [2/500]\t Loss: 0.9503162857648488\t Accuracy: 0.6551351351351351\n",
      "Step [0/37]\t Loss: 0.8735869526863098\t Accuracy: 0.696\n",
      "Epoch [3/500]\t Loss: 0.8998695837484824\t Accuracy: 0.6715675675675676\n",
      "Step [0/37]\t Loss: 0.875934898853302\t Accuracy: 0.696\n",
      "Epoch [4/500]\t Loss: 0.8769352709924852\t Accuracy: 0.6817297297297298\n",
      "Step [0/37]\t Loss: 0.9020223021507263\t Accuracy: 0.672\n",
      "Epoch [5/500]\t Loss: 0.8478986040965931\t Accuracy: 0.6927567567567569\n",
      "Step [0/37]\t Loss: 0.8289649486541748\t Accuracy: 0.696\n",
      "Epoch [6/500]\t Loss: 0.8353655257740537\t Accuracy: 0.6981621621621622\n",
      "Step [0/37]\t Loss: 0.8641154170036316\t Accuracy: 0.664\n",
      "Epoch [7/500]\t Loss: 0.8306513686437864\t Accuracy: 0.6970810810810811\n",
      "Step [0/37]\t Loss: 0.8510821461677551\t Accuracy: 0.656\n",
      "Epoch [8/500]\t Loss: 0.8125449918411873\t Accuracy: 0.7029189189189191\n",
      "Step [0/37]\t Loss: 0.8923091292381287\t Accuracy: 0.648\n",
      "Epoch [9/500]\t Loss: 0.8024693920805648\t Accuracy: 0.7094054054054054\n",
      "Step [0/37]\t Loss: 0.6946459412574768\t Accuracy: 0.744\n",
      "Epoch [10/500]\t Loss: 0.7989476548658835\t Accuracy: 0.7096216216216218\n",
      "Step [0/37]\t Loss: 1.01026451587677\t Accuracy: 0.648\n",
      "Epoch [11/500]\t Loss: 0.793290460431898\t Accuracy: 0.7087567567567566\n",
      "Step [0/37]\t Loss: 0.7757633924484253\t Accuracy: 0.688\n",
      "Epoch [12/500]\t Loss: 0.7824872393865843\t Accuracy: 0.7137297297297297\n",
      "Step [0/37]\t Loss: 0.7926446199417114\t Accuracy: 0.696\n",
      "Epoch [13/500]\t Loss: 0.784865542038067\t Accuracy: 0.7100540540540541\n",
      "Step [0/37]\t Loss: 0.6897744536399841\t Accuracy: 0.784\n",
      "Epoch [14/500]\t Loss: 0.779552614366686\t Accuracy: 0.7139459459459461\n",
      "Step [0/37]\t Loss: 0.7669687271118164\t Accuracy: 0.72\n",
      "Epoch [15/500]\t Loss: 0.7802358591878736\t Accuracy: 0.7161081081081082\n",
      "Step [0/37]\t Loss: 0.7871405482292175\t Accuracy: 0.728\n",
      "Epoch [16/500]\t Loss: 0.7824012685466457\t Accuracy: 0.7091891891891894\n",
      "Step [0/37]\t Loss: 0.6741544008255005\t Accuracy: 0.752\n",
      "Epoch [17/500]\t Loss: 0.7686446051339846\t Accuracy: 0.7169729729729729\n",
      "Step [0/37]\t Loss: 0.6983897089958191\t Accuracy: 0.752\n",
      "Epoch [18/500]\t Loss: 0.7674903112488825\t Accuracy: 0.7167567567567568\n",
      "Step [0/37]\t Loss: 0.7857545614242554\t Accuracy: 0.744\n",
      "Epoch [19/500]\t Loss: 0.7623830099363584\t Accuracy: 0.7223783783783784\n",
      "Step [0/37]\t Loss: 0.8883956670761108\t Accuracy: 0.696\n",
      "Epoch [20/500]\t Loss: 0.7571270385304013\t Accuracy: 0.7210810810810814\n",
      "Step [0/37]\t Loss: 0.8526529669761658\t Accuracy: 0.672\n",
      "Epoch [21/500]\t Loss: 0.7567203028781994\t Accuracy: 0.7206486486486487\n",
      "Step [0/37]\t Loss: 0.7200419902801514\t Accuracy: 0.728\n",
      "Epoch [22/500]\t Loss: 0.7573685468854131\t Accuracy: 0.7193513513513516\n",
      "Step [0/37]\t Loss: 0.7877910733222961\t Accuracy: 0.68\n",
      "Epoch [23/500]\t Loss: 0.7485589691110559\t Accuracy: 0.7241081081081081\n",
      "Step [0/37]\t Loss: 0.6782524585723877\t Accuracy: 0.744\n",
      "Epoch [24/500]\t Loss: 0.7476910932643993\t Accuracy: 0.7217297297297297\n",
      "Step [0/37]\t Loss: 0.7889044880867004\t Accuracy: 0.696\n",
      "Epoch [25/500]\t Loss: 0.7420739918141752\t Accuracy: 0.7260540540540541\n",
      "Step [0/37]\t Loss: 0.6989777088165283\t Accuracy: 0.752\n",
      "Epoch [26/500]\t Loss: 0.7395346825187271\t Accuracy: 0.7273513513513515\n",
      "Step [0/37]\t Loss: 0.7237018942832947\t Accuracy: 0.76\n",
      "Epoch [27/500]\t Loss: 0.7347521379187301\t Accuracy: 0.7292972972972974\n",
      "Step [0/37]\t Loss: 0.7640891671180725\t Accuracy: 0.704\n",
      "Epoch [28/500]\t Loss: 0.7364932943034816\t Accuracy: 0.7273513513513515\n",
      "Step [0/37]\t Loss: 0.6635704636573792\t Accuracy: 0.776\n",
      "Epoch [29/500]\t Loss: 0.7391849305178668\t Accuracy: 0.7282162162162165\n",
      "Step [0/37]\t Loss: 0.6583179235458374\t Accuracy: 0.76\n",
      "Epoch [30/500]\t Loss: 0.7276224638964679\t Accuracy: 0.7312432432432434\n",
      "Step [0/37]\t Loss: 0.595046877861023\t Accuracy: 0.824\n",
      "Epoch [31/500]\t Loss: 0.7297534104940053\t Accuracy: 0.7292972972972973\n",
      "Step [0/37]\t Loss: 0.6871379613876343\t Accuracy: 0.752\n",
      "Epoch [32/500]\t Loss: 0.7310588939769848\t Accuracy: 0.7336216216216218\n",
      "Step [0/37]\t Loss: 0.7147438526153564\t Accuracy: 0.72\n",
      "Epoch [33/500]\t Loss: 0.7191988874126125\t Accuracy: 0.7334054054054056\n",
      "Step [0/37]\t Loss: 0.7679160237312317\t Accuracy: 0.688\n",
      "Epoch [34/500]\t Loss: 0.720394575918043\t Accuracy: 0.7347027027027029\n",
      "Step [0/37]\t Loss: 0.8452272415161133\t Accuracy: 0.728\n",
      "Epoch [35/500]\t Loss: 0.7226265765525199\t Accuracy: 0.7338378378378377\n",
      "Step [0/37]\t Loss: 0.890101969242096\t Accuracy: 0.704\n",
      "Epoch [36/500]\t Loss: 0.7210900235820461\t Accuracy: 0.7334054054054054\n",
      "Step [0/37]\t Loss: 0.7171388864517212\t Accuracy: 0.784\n",
      "Epoch [37/500]\t Loss: 0.7188638368168393\t Accuracy: 0.7375135135135136\n",
      "Step [0/37]\t Loss: 0.6751728653907776\t Accuracy: 0.76\n",
      "Epoch [38/500]\t Loss: 0.7178913451529838\t Accuracy: 0.7368648648648651\n",
      "Step [0/37]\t Loss: 0.6877520084381104\t Accuracy: 0.76\n",
      "Epoch [39/500]\t Loss: 0.7169821745640522\t Accuracy: 0.7362162162162162\n",
      "Step [0/37]\t Loss: 0.649200975894928\t Accuracy: 0.76\n",
      "Epoch [40/500]\t Loss: 0.7137974387890583\t Accuracy: 0.7385945945945946\n",
      "Step [0/37]\t Loss: 0.764817476272583\t Accuracy: 0.728\n",
      "Epoch [41/500]\t Loss: 0.7142673601975312\t Accuracy: 0.7403243243243245\n",
      "Step [0/37]\t Loss: 0.7396726012229919\t Accuracy: 0.744\n",
      "Epoch [42/500]\t Loss: 0.7095796675295443\t Accuracy: 0.7377297297297299\n",
      "Step [0/37]\t Loss: 0.796881914138794\t Accuracy: 0.72\n",
      "Epoch [43/500]\t Loss: 0.7048691414497994\t Accuracy: 0.7446486486486488\n",
      "Step [0/37]\t Loss: 0.780005693435669\t Accuracy: 0.72\n",
      "Epoch [44/500]\t Loss: 0.7112442504715275\t Accuracy: 0.743135135135135\n",
      "Step [0/37]\t Loss: 0.6617770195007324\t Accuracy: 0.736\n",
      "Epoch [45/500]\t Loss: 0.7041030751692282\t Accuracy: 0.7437837837837837\n",
      "Step [0/37]\t Loss: 0.678330659866333\t Accuracy: 0.784\n",
      "Epoch [46/500]\t Loss: 0.7008895616273623\t Accuracy: 0.7433513513513514\n",
      "Step [0/37]\t Loss: 0.8331618309020996\t Accuracy: 0.664\n",
      "Epoch [47/500]\t Loss: 0.7009312913224504\t Accuracy: 0.7418378378378381\n",
      "Step [0/37]\t Loss: 0.6500837802886963\t Accuracy: 0.752\n",
      "Epoch [48/500]\t Loss: 0.7099528699307829\t Accuracy: 0.7429189189189191\n",
      "Step [0/37]\t Loss: 0.6812548637390137\t Accuracy: 0.728\n",
      "Epoch [49/500]\t Loss: 0.695287366171141\t Accuracy: 0.7478918918918919\n",
      "Step [0/37]\t Loss: 0.6992064714431763\t Accuracy: 0.704\n",
      "Epoch [50/500]\t Loss: 0.6939241773373371\t Accuracy: 0.7474594594594596\n",
      "Step [0/37]\t Loss: 0.7758203148841858\t Accuracy: 0.744\n",
      "Epoch [51/500]\t Loss: 0.7009050572240675\t Accuracy: 0.7429189189189191\n",
      "Step [0/37]\t Loss: 0.6700348258018494\t Accuracy: 0.72\n",
      "Epoch [52/500]\t Loss: 0.6945287182524398\t Accuracy: 0.7504864864864866\n",
      "Step [0/37]\t Loss: 0.6591994762420654\t Accuracy: 0.776\n",
      "Epoch [53/500]\t Loss: 0.6999801059026975\t Accuracy: 0.7446486486486489\n",
      "Step [0/37]\t Loss: 0.88393634557724\t Accuracy: 0.632\n",
      "Epoch [54/500]\t Loss: 0.6923471238162067\t Accuracy: 0.7450810810810811\n",
      "Step [0/37]\t Loss: 0.7915607690811157\t Accuracy: 0.72\n",
      "Epoch [55/500]\t Loss: 0.6936700489069965\t Accuracy: 0.7452972972972974\n",
      "Step [0/37]\t Loss: 0.6047007441520691\t Accuracy: 0.768\n",
      "Epoch [56/500]\t Loss: 0.6995458377374185\t Accuracy: 0.7424864864864869\n",
      "Step [0/37]\t Loss: 0.6784470081329346\t Accuracy: 0.784\n",
      "Epoch [57/500]\t Loss: 0.6829310252859786\t Accuracy: 0.7517837837837839\n",
      "Step [0/37]\t Loss: 0.6480441093444824\t Accuracy: 0.792\n",
      "Epoch [58/500]\t Loss: 0.6913282919574428\t Accuracy: 0.745945945945946\n",
      "Step [0/37]\t Loss: 0.6824234127998352\t Accuracy: 0.768\n",
      "Epoch [59/500]\t Loss: 0.6898614264823295\t Accuracy: 0.7468108108108111\n",
      "Step [0/37]\t Loss: 0.8658474683761597\t Accuracy: 0.672\n",
      "Epoch [60/500]\t Loss: 0.6843207897366704\t Accuracy: 0.750054054054054\n",
      "Step [0/37]\t Loss: 0.6575392484664917\t Accuracy: 0.768\n",
      "Epoch [61/500]\t Loss: 0.6926797338434167\t Accuracy: 0.7457297297297298\n",
      "Step [0/37]\t Loss: 0.6148382425308228\t Accuracy: 0.768\n",
      "Epoch [62/500]\t Loss: 0.687358703162219\t Accuracy: 0.7496216216216216\n",
      "Step [0/37]\t Loss: 0.7587761878967285\t Accuracy: 0.696\n",
      "Epoch [63/500]\t Loss: 0.6855008795454696\t Accuracy: 0.7481081081081082\n",
      "Step [0/37]\t Loss: 0.7393488883972168\t Accuracy: 0.696\n",
      "Epoch [64/500]\t Loss: 0.6823731612514805\t Accuracy: 0.7520000000000001\n",
      "Step [0/37]\t Loss: 0.6915479898452759\t Accuracy: 0.736\n",
      "Epoch [65/500]\t Loss: 0.6796997350615424\t Accuracy: 0.7522162162162165\n",
      "Step [0/37]\t Loss: 0.5828198790550232\t Accuracy: 0.768\n",
      "Epoch [66/500]\t Loss: 0.6789408020071082\t Accuracy: 0.7489729729729735\n",
      "Step [0/37]\t Loss: 0.8386338949203491\t Accuracy: 0.712\n",
      "Epoch [67/500]\t Loss: 0.6770064170296127\t Accuracy: 0.7481081081081082\n",
      "Step [0/37]\t Loss: 0.6911738514900208\t Accuracy: 0.704\n",
      "Epoch [68/500]\t Loss: 0.6819286088685732\t Accuracy: 0.7489729729729732\n",
      "Step [0/37]\t Loss: 0.6688130497932434\t Accuracy: 0.776\n",
      "Epoch [69/500]\t Loss: 0.6749675620246578\t Accuracy: 0.7532972972972973\n",
      "Step [0/37]\t Loss: 0.6344995498657227\t Accuracy: 0.784\n",
      "Epoch [70/500]\t Loss: 0.6795412350345302\t Accuracy: 0.7489729729729733\n",
      "Step [0/37]\t Loss: 0.6059792637825012\t Accuracy: 0.8\n",
      "Epoch [71/500]\t Loss: 0.6807483756864393\t Accuracy: 0.751783783783784\n",
      "Step [0/37]\t Loss: 0.7289838790893555\t Accuracy: 0.744\n",
      "Epoch [72/500]\t Loss: 0.6761265235978204\t Accuracy: 0.7541621621621623\n",
      "Step [0/37]\t Loss: 0.6637914180755615\t Accuracy: 0.744\n",
      "Epoch [73/500]\t Loss: 0.6785363490517075\t Accuracy: 0.7532972972972974\n",
      "Step [0/37]\t Loss: 0.6684908866882324\t Accuracy: 0.736\n",
      "Epoch [74/500]\t Loss: 0.6749176753533853\t Accuracy: 0.7520000000000001\n",
      "Step [0/37]\t Loss: 0.5524208545684814\t Accuracy: 0.824\n",
      "Epoch [75/500]\t Loss: 0.662292447444555\t Accuracy: 0.7576216216216217\n",
      "Step [0/37]\t Loss: 0.713623583316803\t Accuracy: 0.704\n",
      "Epoch [76/500]\t Loss: 0.6729736175086047\t Accuracy: 0.7552432432432433\n",
      "Step [0/37]\t Loss: 0.5987589359283447\t Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vLaebM9Qvztx",
    "outputId": "17fd9ef1-5154-41f5-e8f0-0959e0f82f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/37]\t Loss: 1.8033009767532349\t Accuracy: 0.136\n",
      "Epoch [0/500]\t Loss: 1.3058979640135895\t Accuracy: 0.5074594594594597\n",
      "Step [0/37]\t Loss: 1.1310392618179321\t Accuracy: 0.56\n",
      "Epoch [1/500]\t Loss: 1.1025966373649803\t Accuracy: 0.5943783783783785\n",
      "Step [0/37]\t Loss: 1.1083776950836182\t Accuracy: 0.608\n",
      "Epoch [2/500]\t Loss: 1.0608275178316477\t Accuracy: 0.6023783783783784\n",
      "Step [0/37]\t Loss: 0.9856696724891663\t Accuracy: 0.672\n",
      "Epoch [3/500]\t Loss: 1.0526621744439408\t Accuracy: 0.6019459459459459\n",
      "Step [0/37]\t Loss: 1.1596343517303467\t Accuracy: 0.56\n",
      "Epoch [4/500]\t Loss: 1.0424807184451335\t Accuracy: 0.6056216216216217\n",
      "Step [0/37]\t Loss: 1.0736558437347412\t Accuracy: 0.576\n",
      "Epoch [5/500]\t Loss: 1.0309529691129118\t Accuracy: 0.6099459459459459\n",
      "Step [0/37]\t Loss: 1.16108238697052\t Accuracy: 0.544\n",
      "Epoch [6/500]\t Loss: 1.0287092763024408\t Accuracy: 0.6116756756756757\n",
      "Step [0/37]\t Loss: 0.9434301853179932\t Accuracy: 0.688\n",
      "Epoch [7/500]\t Loss: 1.0198058888718888\t Accuracy: 0.6147027027027027\n",
      "Step [0/37]\t Loss: 1.113943099975586\t Accuracy: 0.552\n",
      "Epoch [8/500]\t Loss: 1.0225735532270896\t Accuracy: 0.6101621621621621\n",
      "Step [0/37]\t Loss: 1.0189629793167114\t Accuracy: 0.6\n",
      "Epoch [9/500]\t Loss: 1.0173781030886881\t Accuracy: 0.6142702702702704\n",
      "Step [0/37]\t Loss: 1.0884902477264404\t Accuracy: 0.536\n",
      "Epoch [10/500]\t Loss: 1.0238684464145351\t Accuracy: 0.6114594594594596\n",
      "Step [0/37]\t Loss: 1.0873640775680542\t Accuracy: 0.6\n",
      "Epoch [11/500]\t Loss: 1.0141767488943565\t Accuracy: 0.612972972972973\n",
      "Step [0/37]\t Loss: 1.033854365348816\t Accuracy: 0.64\n",
      "Epoch [12/500]\t Loss: 1.008228297169144\t Accuracy: 0.6229189189189188\n",
      "Step [0/37]\t Loss: 0.9485524296760559\t Accuracy: 0.648\n",
      "Epoch [13/500]\t Loss: 1.012501690838788\t Accuracy: 0.616\n",
      "Step [0/37]\t Loss: 1.1229203939437866\t Accuracy: 0.608\n",
      "Epoch [14/500]\t Loss: 1.011778104949642\t Accuracy: 0.6116756756756757\n",
      "Step [0/37]\t Loss: 0.9500762224197388\t Accuracy: 0.672\n",
      "Epoch [15/500]\t Loss: 1.0029996681857754\t Accuracy: 0.6214054054054055\n",
      "Step [0/37]\t Loss: 0.9587697386741638\t Accuracy: 0.648\n",
      "Epoch [16/500]\t Loss: 1.0014339411580884\t Accuracy: 0.6201081081081081\n",
      "Step [0/37]\t Loss: 0.9559009671211243\t Accuracy: 0.68\n",
      "Epoch [17/500]\t Loss: 1.0083174367208738\t Accuracy: 0.6183783783783784\n",
      "Step [0/37]\t Loss: 1.1889280080795288\t Accuracy: 0.552\n",
      "Epoch [18/500]\t Loss: 1.0010022537128345\t Accuracy: 0.6194594594594595\n",
      "Step [0/37]\t Loss: 1.0365569591522217\t Accuracy: 0.624\n",
      "Epoch [19/500]\t Loss: 0.9979361182934529\t Accuracy: 0.6261621621621621\n",
      "Step [0/37]\t Loss: 1.013893961906433\t Accuracy: 0.648\n",
      "Epoch [20/500]\t Loss: 0.9931009814545915\t Accuracy: 0.6220540540540539\n",
      "Step [0/37]\t Loss: 1.1179018020629883\t Accuracy: 0.616\n",
      "Epoch [21/500]\t Loss: 0.9930059426539654\t Accuracy: 0.6218378378378379\n",
      "Step [0/37]\t Loss: 1.015285849571228\t Accuracy: 0.6\n",
      "Epoch [22/500]\t Loss: 1.0047405507113483\t Accuracy: 0.6224864864864865\n",
      "Step [0/37]\t Loss: 0.9152193069458008\t Accuracy: 0.672\n",
      "Epoch [23/500]\t Loss: 0.9946665779964344\t Accuracy: 0.6252972972972973\n",
      "Step [0/37]\t Loss: 1.115788459777832\t Accuracy: 0.584\n",
      "Epoch [24/500]\t Loss: 0.9997544755806794\t Accuracy: 0.619891891891892\n",
      "Step [0/37]\t Loss: 0.9976512789726257\t Accuracy: 0.608\n",
      "Epoch [25/500]\t Loss: 0.9928673473564354\t Accuracy: 0.6257297297297297\n",
      "Step [0/37]\t Loss: 0.9223300814628601\t Accuracy: 0.68\n",
      "Epoch [26/500]\t Loss: 0.9976288740699356\t Accuracy: 0.6214054054054055\n",
      "Step [0/37]\t Loss: 0.9461998343467712\t Accuracy: 0.656\n",
      "Epoch [27/500]\t Loss: 0.9956010032344509\t Accuracy: 0.6211891891891892\n",
      "Step [0/37]\t Loss: 1.0611393451690674\t Accuracy: 0.576\n",
      "Epoch [28/500]\t Loss: 0.9861307160274403\t Accuracy: 0.6276756756756757\n",
      "Step [0/37]\t Loss: 1.0447298288345337\t Accuracy: 0.584\n",
      "Epoch [29/500]\t Loss: 0.9891293886545542\t Accuracy: 0.628108108108108\n",
      "Step [0/37]\t Loss: 1.0635769367218018\t Accuracy: 0.6\n",
      "Epoch [30/500]\t Loss: 0.9943820109238496\t Accuracy: 0.6235675675675676\n",
      "Step [0/37]\t Loss: 1.1241897344589233\t Accuracy: 0.584\n",
      "Epoch [31/500]\t Loss: 0.9889136891107302\t Accuracy: 0.6255135135135134\n",
      "Step [0/37]\t Loss: 0.8885579705238342\t Accuracy: 0.672\n",
      "Epoch [32/500]\t Loss: 0.9877686903283402\t Accuracy: 0.624864864864865\n",
      "Step [0/37]\t Loss: 0.9491863250732422\t Accuracy: 0.656\n",
      "Epoch [33/500]\t Loss: 0.9808122612334587\t Accuracy: 0.6302702702702703\n",
      "Step [0/37]\t Loss: 0.9717525243759155\t Accuracy: 0.64\n",
      "Epoch [34/500]\t Loss: 0.9800167293161959\t Accuracy: 0.6296216216216217\n",
      "Step [0/37]\t Loss: 0.9412503838539124\t Accuracy: 0.656\n",
      "Epoch [35/500]\t Loss: 0.978393591739036\t Accuracy: 0.6324324324324325\n",
      "Step [0/37]\t Loss: 0.8845765590667725\t Accuracy: 0.648\n",
      "Epoch [36/500]\t Loss: 0.9832291538650925\t Accuracy: 0.6255135135135135\n",
      "Step [0/37]\t Loss: 1.1710538864135742\t Accuracy: 0.48\n",
      "Epoch [37/500]\t Loss: 0.9889631947955569\t Accuracy: 0.6233513513513514\n",
      "Step [0/37]\t Loss: 0.9217975735664368\t Accuracy: 0.656\n",
      "Epoch [38/500]\t Loss: 0.9858019754693315\t Accuracy: 0.6263783783783785\n",
      "Step [0/37]\t Loss: 1.0927571058273315\t Accuracy: 0.608\n",
      "Epoch [39/500]\t Loss: 0.9774902028006476\t Accuracy: 0.6311351351351352\n",
      "Step [0/37]\t Loss: 1.013459324836731\t Accuracy: 0.648\n",
      "Epoch [40/500]\t Loss: 0.9844006364409988\t Accuracy: 0.6259459459459459\n",
      "Step [0/37]\t Loss: 0.96531081199646\t Accuracy: 0.624\n",
      "Epoch [41/500]\t Loss: 0.9799570795652028\t Accuracy: 0.6300540540540539\n",
      "Step [0/37]\t Loss: 0.9787879586219788\t Accuracy: 0.648\n",
      "Epoch [42/500]\t Loss: 0.980630244757678\t Accuracy: 0.6322162162162163\n",
      "Step [0/37]\t Loss: 0.916633665561676\t Accuracy: 0.672\n",
      "Epoch [43/500]\t Loss: 0.9758370550903114\t Accuracy: 0.6281081081081081\n",
      "Step [0/37]\t Loss: 0.9701990485191345\t Accuracy: 0.624\n",
      "Epoch [44/500]\t Loss: 0.9809103157069232\t Accuracy: 0.6291891891891892\n",
      "Step [0/37]\t Loss: 0.95835280418396\t Accuracy: 0.632\n",
      "Epoch [45/500]\t Loss: 0.975676860358264\t Accuracy: 0.6274594594594595\n",
      "Step [0/37]\t Loss: 0.9946370720863342\t Accuracy: 0.632\n",
      "Epoch [46/500]\t Loss: 0.9775510639757723\t Accuracy: 0.6324324324324326\n",
      "Step [0/37]\t Loss: 0.9622368812561035\t Accuracy: 0.656\n",
      "Epoch [47/500]\t Loss: 0.9740126712902172\t Accuracy: 0.6315675675675674\n",
      "Step [0/37]\t Loss: 1.0243192911148071\t Accuracy: 0.616\n",
      "Epoch [48/500]\t Loss: 0.9699419173034461\t Accuracy: 0.6343783783783784\n",
      "Step [0/37]\t Loss: 1.0600663423538208\t Accuracy: 0.624\n",
      "Epoch [49/500]\t Loss: 0.9704662029807632\t Accuracy: 0.6352432432432433\n",
      "Step [0/37]\t Loss: 0.9606145024299622\t Accuracy: 0.624\n",
      "Epoch [50/500]\t Loss: 0.9722542988287436\t Accuracy: 0.6322162162162164\n",
      "Step [0/37]\t Loss: 1.1357265710830688\t Accuracy: 0.592\n",
      "Epoch [51/500]\t Loss: 0.9715521657789076\t Accuracy: 0.6345945945945947\n",
      "Step [0/37]\t Loss: 0.8836181163787842\t Accuracy: 0.656\n",
      "Epoch [52/500]\t Loss: 0.9718232170955555\t Accuracy: 0.6315675675675676\n",
      "Step [0/37]\t Loss: 1.0258432626724243\t Accuracy: 0.608\n",
      "Epoch [53/500]\t Loss: 0.9720781058878512\t Accuracy: 0.6311351351351352\n",
      "Step [0/37]\t Loss: 0.9228202700614929\t Accuracy: 0.648\n",
      "Epoch [54/500]\t Loss: 0.973266289040849\t Accuracy: 0.6343783783783784\n",
      "Step [0/37]\t Loss: 1.1420886516571045\t Accuracy: 0.536\n",
      "Epoch [55/500]\t Loss: 0.974487757360613\t Accuracy: 0.6296216216216216\n",
      "Step [0/37]\t Loss: 1.024275302886963\t Accuracy: 0.608\n",
      "Epoch [56/500]\t Loss: 0.970441773131087\t Accuracy: 0.6313513513513516\n",
      "Step [0/37]\t Loss: 0.9729394912719727\t Accuracy: 0.64\n",
      "Epoch [57/500]\t Loss: 0.9699945030985652\t Accuracy: 0.6345945945945948\n",
      "Step [0/37]\t Loss: 0.929798424243927\t Accuracy: 0.68\n",
      "Epoch [58/500]\t Loss: 0.9590459627074164\t Accuracy: 0.6404324324324325\n",
      "Step [0/37]\t Loss: 1.0574895143508911\t Accuracy: 0.576\n",
      "Epoch [59/500]\t Loss: 0.9644181760581764\t Accuracy: 0.6365405405405405\n",
      "Step [0/37]\t Loss: 1.0646651983261108\t Accuracy: 0.56\n",
      "Epoch [60/500]\t Loss: 0.9665242949047604\t Accuracy: 0.6341621621621624\n",
      "Step [0/37]\t Loss: 0.8326179385185242\t Accuracy: 0.688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aab1da4690d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# final testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-4f1c640c4e7f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
    "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SimCLR Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f62ac17ac704e108fa3ea5f52a9ea8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554f93f21a4344ada4a1e7c74fe386b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62ac17ac704e108fa3ea5f52a9ea8d",
      "placeholder": "​",
      "style": "IPY_MODEL_56b658779c7745a885cde6850fae178f",
      "value": " 170500096/? [00:19&lt;00:00, 93331221.18it/s]"
     }
    },
    "56b658779c7745a885cde6850fae178f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb79baa5d7b4c81896e083f9543b33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f1d2aed682f44f98524873f26408de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8ecfd2a00a874c6cacacbe39ab3f87cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e100213220094b8cbf3e9578bc3a1554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3834039bcc6436489e4b5fc04fb4664",
       "IPY_MODEL_554f93f21a4344ada4a1e7c74fe386b7"
      ],
      "layout": "IPY_MODEL_8ecfd2a00a874c6cacacbe39ab3f87cc"
     }
    },
    "e3834039bcc6436489e4b5fc04fb4664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb79baa5d7b4c81896e083f9543b33c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f1d2aed682f44f98524873f26408de6",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
