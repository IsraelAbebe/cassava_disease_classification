{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMpVoOgFsZoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMe1Ue0lsZtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip drive/My\\ Drive/ammi-2020-convnets.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "UJJxiKFrsOEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install timm -q\n",
        "!pip install pretrainedmodels  -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7OaDQgE0EbT",
        "colab_type": "text"
      },
      "source": [
        "# Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "HUX-27YDsOEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "\n",
        "import pretrainedmodels\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqamKy9YsOEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM3jWZnosOE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"train/train\"\n",
        "test_path = \"test/test\"\n",
        "extraimage_path = \"extraimages/extraimages\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxuEdqZhsOE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train set:')\n",
        "class_distrbution = {}\n",
        "for cls in os.listdir(data_path):\n",
        "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
        "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
        "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
        "print(im.size)\n",
        "class_distrbution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n0OJ2JrsOE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformations for both the training and testing data\n",
        "mean=[0.4543, 0.5137, 0.3240]\n",
        "std=[0.1949, 0.1977, 0.1661]\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(320), #448, 299, 224, 331\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])\n",
        "test_transforms = transforms.Compose([ transforms.Resize(320),\n",
        "                                       transforms.CenterCrop(320),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuU-Wa6ysOFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "\n",
        "        files = []\n",
        "        class_names = {}\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "\n",
        "                name = str(i)+'-'+className\n",
        "                if name not in class_names:\n",
        "                    class_names[name] = 1\n",
        "                else:\n",
        "                    class_names[name] += 1\n",
        "        self.file_list = files\n",
        "        print(class_names)\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = self.file_list[idx][0]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "        \n",
        "# #         return im.view(3, 448, 448), classCategory\n",
        "#         return im.view(3, 224, 224), classCategory\n",
        "# #         return im.view(3, 299, 299), classCategory\n",
        "        return im.view(3, 320, 320), classCategory   # NASNetLarge 331x331"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKgTaq4lsOFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
        "\n",
        "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
        "\n",
        "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXvez_GJsOFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgeZkwuZuuDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
        "                                             sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
        "                                             sampler=valid_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj8faxARsOFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "#     img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSIfWH9sOFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(labels)\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "matplotlib_imshow(img_grid, one_channel=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn1u1_iO1CAx",
        "colab_type": "text"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVzoUlp-sOFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Additional(nn.Module):\n",
        "    def __init__(self, modelA,in_features,nb_classes=5):\n",
        "        super(Additional, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        # Remove last linear layer\n",
        "        self.modelA.classifier = nn.Identity()\n",
        "        \n",
        "        for p in self.modelA.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        # Create new classifier\n",
        "        self.fc_1 = nn.Linear(in_features,256)\n",
        "        self.fc_2 = nn.Linear(256,  512)\n",
        "        self.fc_out = nn.Linear( 512, nb_classes)\n",
        "        \n",
        "        #Dropout\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #model\n",
        "        x = self.modelA(x.clone())  \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        #FC\n",
        "        x  = self.dropout(F.relu(self.fc_1(x)))\n",
        "        x = self.dropout(F.relu(self.fc_2(x)))\n",
        "        x = self.fc_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dbORs6m1FpE",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K8IXv3esOFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function is used during training process, to calculation the loss and accuracy\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7EbNOuYsOFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_loss_train, total_acc_train = [],[]\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss = AverageMeter()\n",
        "    train_acc = AverageMeter()\n",
        "    curr_iter = (epoch - 1) * len(train_loader)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data\n",
        "        N = images.size(0)\n",
        "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
        "        images = Variable(images).to(device)\n",
        "        labels = Variable(labels).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        prediction = outputs.max(1, keepdim=True)[1]\n",
        "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
        "        train_loss.update(loss.item())\n",
        "        curr_iter += 1\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
        "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
        "            total_loss_train.append(train_loss.avg)\n",
        "            total_acc_train.append(train_acc.avg)\n",
        "    return train_loss.avg, train_acc.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKVRT2KsOFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion, optimizer, epoch):\n",
        "    model.eval()\n",
        "    val_loss = AverageMeter()\n",
        "    val_acc = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            images, labels = data\n",
        "            N = images.size(0)\n",
        "            images = Variable(images).to(device)\n",
        "            labels = Variable(labels).to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            prediction = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
        "\n",
        "            val_loss.update(criterion(outputs, labels).item())\n",
        "\n",
        "    print('------------------------------------------------------------')\n",
        "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
        "    print('------------------------------------------------------------')\n",
        "    return val_loss.avg, val_acc.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1e2FxdEsOF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(test_loader,train_loader, model):\n",
        "    model.eval()\n",
        "    pred = []\n",
        "    _class_labels = np.array(train_loader.dataset.classes)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            images, _ = data\n",
        "            images = Variable(images).to(device)\n",
        "    \n",
        "            outputs = model(images)\n",
        "    \n",
        "            prediction = outputs.data.cpu().numpy().argmax()\n",
        "            \n",
        "            _predicted_class_labels = _class_labels[prediction]\n",
        "            \n",
        "            pred.append(_predicted_class_labels)\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRnK6CaZ1JO-",
        "colab_type": "text"
      },
      "source": [
        "# Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RfqavBqsOF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_name = 'se_resnet101'\n",
        "\n",
        "# model = timm.create_model('efficientnet_b3a', pretrained=True)\n",
        "model = pretrainedmodels.se_resnet101(num_classes=1000, pretrained='imagenet')\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUkWhVmLsOF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_fits = model.classifier.in_features\n",
        "num_fits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmYYOxJksOGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Additional(model,num_fits)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYjDjh32sOGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lr = 2e-4 # 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "epoch_num = 15\n",
        "best_val_acc = 0.88\n",
        "total_loss_val, total_acc_val = [],[]\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
        "    loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)\n",
        "    total_loss_val.append(loss_val)\n",
        "    total_acc_val.append(acc_val)\n",
        "    if acc_val > best_val_acc:\n",
        "        best_val_acc = acc_val\n",
        "        torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
        "        print('*****************************************************')\n",
        "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
        "        print('*****************************************************')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UBFbamesOGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # load better model\n",
        "# model.load_state_dict(torch.load('se_resnext101_32x4dfreeze_0.86.ckpt'))\n",
        "# model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAXB2uQ7sOHN",
        "colab_type": "text"
      },
      "source": [
        "## Sumission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soh5HjFesOHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = train_loader.dataset.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkIh16L5sOHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(image_dir):\n",
        "    # Process a PIL image for use in a PyTorch model\n",
        "    # tensor.numpy().transpose(1, 2, 0)\n",
        "    image = Image.open(image_dir)\n",
        "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])\n",
        "    image = preprocess(image)\n",
        "    # Convert 2D image to 1D vector\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = torch.from_numpy(image)\n",
        "    inputs = image.to(device)\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXdzLhIZsOHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq1W5ge_sOHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using our model to predict the label\n",
        "def predict(image, model):\n",
        "    # Pass the image through our model\n",
        "    output = model(image)\n",
        "    # Reverse the log function in our output\n",
        "    output = torch.exp(output)\n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJPVFz_rsOHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_directory = \"./data/test/test/0\"\n",
        "predictions, test_image_fileName = [], []\n",
        "try:\n",
        "    test_images = listdir(test_directory)\n",
        "    for images in test_images:\n",
        "        test_image_fileName.append(images)\n",
        "        image = process_image(f'{test_directory}/{images}')\n",
        "        top_prob, top_class = predict(image, model)\n",
        "        predictions.append(class_names[top_class])\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSqV9PXwsOHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-raIb-VsOH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] Creating pandas dataframe\")\n",
        "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
        "submission_data_frame = pd.DataFrame(submission_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3q3nDi8sOH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u1WoocAsOH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data_frame.to_csv('submission'+model_name+'_freeze_86_flip.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}