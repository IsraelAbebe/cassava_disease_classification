{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\n\nimport torch.nn.functional as F\nimport time\nimport os\nimport copy\nimport pretrainedmodels\nimport os\nfrom torch.utils.data import Dataset\nimport glob\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport time\nimport numpy as np\nimport pandas as pd\nimport os\nimport datetime as dt\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nimport torch\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms, datasets, models\n\n\n\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train set:')\nfor cls in os.listdir('../input/ammi-2020-convnets/train/train'):\n    print('{}:{}'.format(cls, len(os.listdir(os.path.join('../input/ammi-2020-convnets/train/train', cls)))))\nim = Image.open('../input/ammi-2020-convnets/train/train/cgm/train-cgm-738.jpg')\nprint(im.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_path = \"../input/ammi-2020-convnets/train/train\"\ntest_path = \"../input/ammi-2020-convnets/test\"\nextraimage_path = \"../input/ammi-2020-convnets/extraimages/extraimages\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformations for both the training and testing data\nmean=[0.4543, 0.5137, 0.3240]\nstd=[0.1949, 0.1977, 0.1661]\n\n\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224), #448, 299, 224\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize(mean=mean,std=std)])\n\ntest_transforms = transforms.Compose([ transforms.Resize(224),\n                                       transforms.CenterCrop(224),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize(mean=mean,std=std)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nclass CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        class_names = {}\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n                \n                name = str(i)+'-'+className\n                if name not in class_names:\n                    class_names[name] = 1\n                else:\n                    class_names[name] += 1\n        self.file_list = files\n        print(class_names)\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        className = self.file_list[idx][1]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n        \n        return im.view(3, 224, 224), classCategory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data = CassavaDataset(data_path, transform=train_transforms)\n\ntest_data = CassavaDataset(test_path, transform=test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\n\nvalidation_split = .2\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n                                             sampler=train_sampler)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n                                             sampler=valid_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=1) # make batch = 1 here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_loader.class_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n#     img = img / 2 + 0.5     # unnormalize\n    npimg = img.cpu().numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nimg_grid = torchvision.utils.make_grid(images)\n\nmatplotlib_imshow(img_grid, one_channel=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Additional(nn.Module):\n    def __init__(self,modelA,modelB,in_features_a,in_features_b,nb_classes=5,freeze = True,drop=0.3):\n        super(Additional, self).__init__()\n        \n        self.modelA = modelA\n        self.modelB = modelB\n        \n#         # Remove last linear layer\n#         self.modelA.fc = nn.Identity() # for resnet\n#         self.modelB.fc = nn.Identity() # for resnet\n\n        self.modelA.last_linear = nn.Identity() #for re_renext\n        self.modelB.last_linear = nn.Identity() #for re_renext\n        \n#         self.modelA.classifier = nn.Identity()    # densenet201\n#         self.modelB.classifier = nn.Identity()    # densenet201\n\n\n\n        for p in self.modelA.parameters():\n            if freeze:\n                p.requires_grad = False\n            else :\n                p.requires_grad = True\n                \n        for p in self.modelB.parameters():\n            if freeze:\n                p.requires_grad = False\n            else :\n                p.requires_grad = True\n                \n                \n        \n        # Create new classifier\n        self.last_linear = nn.Linear((in_features_a+in_features_b),(in_features_a+in_features_b)//2)\n        self.fc_2 = nn.Linear((in_features_a+in_features_b)//2,  512)\n        self.fc_out = nn.Linear( 512, nb_classes)\n        \n        #Dropout\n        self.dropout = nn.Dropout(p=drop)\n        \n    def forward(self, x):\n        #model A\n        x1 = self.modelA(x.clone())  \n        x1 = x1.view(x1.size(0), -1)\n        \n        #model B\n        x2 = self.modelB(x.clone())  \n        x2 = x2.view(x2.size(0), -1)\n        \n        #concat\n        x = torch.cat((x1, x2), dim=1)\n        \n        x  = self.dropout(self.last_linear(F.relu(x)))\n        x = self.dropout(self.fc_2(F.relu(x)))\n        x = self.fc_out(F.relu(x))\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function is used during training process, to calculation the loss and accuracy\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_loss_train, total_acc_train = [],[]\ndef train(train_loader, model, criterion, optimizer, epoch):\n    model.train()\n    train_loss = AverageMeter()\n    train_acc = AverageMeter()\n    curr_iter = (epoch - 1) * len(train_loader)\n    for i, data in enumerate(train_loader):\n        images, labels = data\n        N = images.size(0)\n        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n        images = Variable(images).to(device)\n        labels = Variable(labels).to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        prediction = outputs.max(1, keepdim=True)[1]\n        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n        train_loss.update(loss.item())\n        curr_iter += 1\n        if (i + 1) % 100 == 0:\n            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n            total_loss_train.append(train_loss.avg)\n            total_acc_train.append(train_acc.avg)\n    return train_loss.avg, train_acc.avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(val_loader, model, criterion, optimizer, epoch):\n    model.eval()\n    val_loss = AverageMeter()\n    val_acc = AverageMeter()\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            images, labels = data\n            N = images.size(0)\n            images = Variable(images).to(device)\n            labels = Variable(labels).to(device)\n\n            outputs = model(images)\n            prediction = outputs.max(1, keepdim=True)[1]\n\n            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n\n            val_loss.update(criterion(outputs, labels).item())\n\n    print('------------------------------------------------------------')\n    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n    print('------------------------------------------------------------')\n    return val_loss.avg, val_acc.avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(test_loader, model):\n    model.eval()\n    pred = []\n    _class_labels = np.array(['cbb','cbsd','cgm','cmd','healthy'])\n    with torch.no_grad():\n        for i, data in enumerate(test_loader):\n            images, _ = data\n            images = Variable(images).to(device)\n    \n            outputs = model(images)\n    \n            prediction = outputs.data.cpu().numpy().argmax()\n            \n            _predicted_class_labels = _class_labels[prediction]\n            \n            pred.append(_predicted_class_labels)\n\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodelA = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")\nmodelB = pretrainedmodels.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_fitsa = modelA.last_linear.in_features\nnum_fitsb = modelB.last_linear.in_features\nprint(num_fitsa,num_fitsb)\n\n\nmodel = Additional(modelA,modelB,num_fitsa,num_fitsb, freeze = True)\nmodel = model.to(device)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 2e-4 # 0.001\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n\nepoch_num = 20\nbest_val_acc = 0\ntotal_loss_val, total_acc_val = [],[]\nfor epoch in range(1, epoch_num+1):\n    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n    loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch)\n    total_loss_val.append(loss_val)\n    total_acc_val.append(acc_val)\n    if acc_val > best_val_acc:\n        best_val_acc = acc_val\n        torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n        print('*****************************************************')\n        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n        print('*****************************************************')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = {0:'cbsd', 1: 'cgm', 2: 'cbb', 3: 'healthy', 4: 'cmd'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_image(image_dir):\n    # Process a PIL image for use in a PyTorch model\n    # tensor.numpy().transpose(1, 2, 0)\n    image = Image.open(image_dir)\n    preprocess = transforms.Compose([ transforms.Resize(224),\n                                       transforms.CenterCrop(224),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize(mean=mean,std=std)])\n    image = preprocess(image)\n    # Convert 2D image to 1D vector\n    image = np.expand_dims(image, 0)\n    image = torch.from_numpy(image)\n    inputs = image.to(device)\n    return inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using our model to predict the label\ndef predict(image, model):\n    # Pass the image through our model\n    output = model(image)\n    # Reverse the log function in our output\n    output = torch.exp(output)\n    # Get the top predicted class, and the output percentage for\n    # that class\n    probs, classes = output.topk(1, dim=1)\n    return probs.item(), classes.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_directory = \"./data/test/test/0\"\npredictions, test_image_fileName = [], []\ntry:\n    test_images = listdir(test_directory)\n    for images in test_images:\n        test_image_fileName.append(images)\n        image = process_image(f'{test_directory}/{images}')\n        top_prob, top_class = predict(image, model)\n        predictions.append(class_names[top_class])\nexcept Exception as e:\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] Creating pandas dataframe\")\nsubmission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\nsubmission_data_frame = pd.DataFrame(submission_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data_frame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data_frame.to_csv('submission'+model_name+'_freeze_86_flip.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}