{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of Hyperparameter search.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc_uz2oO2pXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVEbpjAt1m7V",
        "colab_type": "text"
      },
      "source": [
        "# Goole drive push data and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbLP11Z72pa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip drive/My\\ Drive/ammi-2020-convnets.zip \\\n",
        "\n",
        "# !mkdir models\n",
        "# !cp -r drive/My\\ Drive/data/models/* models/.\n",
        "\n",
        "\n",
        "# !cp -r models/* drive/My\\ Drive/data/models/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "qqpdX2q92luH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install timm  -q\n",
        "!pip install pretrainedmodels -q\n",
        "!pip install optuna -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "YmkoGkTG2luO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import glob\n",
        "\n",
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "\n",
        "import pretrainedmodels\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNcK3_fJ13lj",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zdZDVnyB2luX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"train/train/\"\n",
        "test_path = \"test/test/0\"\n",
        "extraimage_path = \"extraimages/extraimages\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QLdzIITF2lua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train set:')\n",
        "class_distrbution = {}\n",
        "for cls in os.listdir(data_path):\n",
        "    print('{}:{}'.format(cls, len(os.listdir(os.path.join(data_path, cls)))))\n",
        "    class_distrbution[cls] =  len(os.listdir(os.path.join(data_path, cls)))\n",
        "im = Image.open(data_path+'/cgm/train-cgm-738.jpg')\n",
        "print(im.size)\n",
        "class_distrbution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oav-wv9l2luf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformations for both the training and testing data\n",
        "mean=[0.4543, 0.5137, 0.3240]\n",
        "std=[0.1949, 0.1977, 0.1661]\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomResizedCrop(320),\n",
        "                                       transforms.RandomRotation(30),#448, 299, 224, 331\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])\n",
        "\n",
        "test_transforms = transforms.Compose([ transforms.Resize(320),\n",
        "                                       transforms.CenterCrop(320),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])\n",
        "\n",
        "# normalize = transforms.Normalize(mean=mean, std=std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ugb5UPSi2luj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "\n",
        "        files = []\n",
        "        class_names = {}\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "\n",
        "                name = str(i)+'-'+className\n",
        "                if name not in class_names:\n",
        "                    class_names[name] = 1\n",
        "                else:\n",
        "                    class_names[name] += 1\n",
        "        self.file_list = files\n",
        "        print(class_names)\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = self.file_list[idx][0]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "        \n",
        "# #         return im.view(3, 448, 448), classCategory\n",
        "#         return im.view(3, 224, 224), classCategory\n",
        "# #         return im.view(3, 299, 299), classCategory\n",
        "        return im.view(3, 320, 320), classCategory   # NASNetLarge 331x331"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "04vmfRUF2luo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
        "\n",
        "test_data = CassavaDataset(test_path, transform=test_transforms)\n",
        "\n",
        "extraimage_data = CassavaDataset(extraimage_path, transform=train_transforms) #maybe need an other trasforms, I had to change the dataset structure :)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR9imK9V6AA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
        "                                             sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
        "                                             sampler=valid_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z5UYtczq2lu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8lPSuAKS2lu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(labels)\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "matplotlib_imshow(img_grid, one_channel=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9sRl661-eH",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nreSeSPi2lu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Additional(nn.Module):\n",
        "    def __init__(self, modelA,in_features,nb_classes=5,drop=0.2):\n",
        "        super(Additional, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        # Remove last linear layer\n",
        "        self.modelA.classifier = nn.Identity()\n",
        "        \n",
        "        for p in self.modelA.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        # Create new classifier\n",
        "        self.fc_1 = nn.Linear(in_features,256)\n",
        "        self.fc_2 = nn.Linear(256,  512)\n",
        "        self.fc_out = nn.Linear( 512, nb_classes)\n",
        "        \n",
        "        #Dropout\n",
        "        self.dropout = nn.Dropout(p=drop)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #model\n",
        "        x = self.modelA(x.clone())  \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        #FC\n",
        "        x  = self.dropout(F.relu(self.fc_1(x)))\n",
        "        x = self.dropout(F.relu(self.fc_2(x)))\n",
        "        x = self.fc_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b6q1vhNp2lu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function is used during training process, to calculation the loss and accuracy\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B1kzFdYS2lvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_loss_train, total_acc_train = [],[]\n",
        "def train(train_loader, model, criterion, optimizer, epoch,device):\n",
        "    model.train()\n",
        "    train_loss = AverageMeter()\n",
        "    train_acc = AverageMeter()\n",
        "    curr_iter = (epoch - 1) * len(train_loader)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data\n",
        "        N = images.size(0)\n",
        "#         print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
        "        images = Variable(images).to(device)\n",
        "        labels = Variable(labels).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        prediction = outputs.max(1, keepdim=True)[1]\n",
        "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
        "        train_loss.update(loss.item())\n",
        "        curr_iter += 1\n",
        "    return train_loss.avg, train_acc.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "85ucNX4u2lvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion, optimizer, epoch,device):\n",
        "    model.eval()\n",
        "    val_loss = AverageMeter()\n",
        "    val_acc = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            images, labels = data\n",
        "            N = images.size(0)\n",
        "            images = Variable(images).to(device)\n",
        "            labels = Variable(labels).to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            prediction = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
        "\n",
        "            val_loss.update(criterion(outputs, labels).item())\n",
        "            \n",
        "    return val_loss.avg, val_acc.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xBd_CDek2lvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(test_loader,train_loader, model):\n",
        "    model.eval()\n",
        "    pred = []\n",
        "    _class_labels = np.array(train_loader.dataset.classes)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            images, _ = data\n",
        "            images = Variable(images).to(device)\n",
        "    \n",
        "            outputs = model(images)\n",
        "    \n",
        "            prediction = outputs.data.cpu().numpy().argmax()\n",
        "            \n",
        "            _predicted_class_labels = _class_labels[prediction]\n",
        "            \n",
        "            pred.append(_predicted_class_labels)\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mweR7ZnM2PlO",
        "colab_type": "text"
      },
      "source": [
        "# Find the right Hyper parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DLFWXa-f2lvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    drop  = trial.suggest_loguniform('drop', 0.1, 0.5)\n",
        "\n",
        "    model = timm.create_model('efficientnet_b3a', pretrained=True)\n",
        "    model = model.to(device)\n",
        "    model_name = 'efficientnet_b3a'\n",
        "\n",
        "    model = Additional(model,model.classifier.in_features,drop=drop)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
        "    # class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
        "\n",
        "    # class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
        "\n",
        "    # weights = torch.Tensor(class_weights_normalized)\n",
        "    # weights = weights.to(device)\n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    lr  = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    optim_ = trial.suggest_categorical('optim_',[optim.Adam])\n",
        "    momentum = trial.suggest_uniform('momentum', 0.4, 0.99)\n",
        "    optimizer = optim_(model.parameters(), lr=lr)\n",
        "    \n",
        "    epoch_num = 10\n",
        "    best_val_acc = 0.85\n",
        "    total_loss_val, total_acc_val = [],[]\n",
        "    for epoch in range(1, epoch_num+1):\n",
        "        loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch,device)\n",
        "        loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch,device)\n",
        "        total_loss_val.append(loss_val)\n",
        "        total_acc_val.append(acc_val)\n",
        "        if acc_val > best_val_acc:\n",
        "            best_val_acc = acc_val\n",
        "            torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
        "        print('*****************************************************')\n",
        "        print('best record: [epoch %d], [Train loss %.5f], [Train acc %.5f], [val loss %.5f], [val acc %.5f]' % (epoch,loss_train,acc_train, loss_val, acc_val))\n",
        "        print('*****************************************************')\n",
        "            \n",
        "     # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "            \n",
        "            \n",
        "    return acc_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CIem_NWz2lvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import optuna\n",
        "\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
        "study.optimize(func=objective, n_trials=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li0VDGbFrxIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "netfANdB2UT7",
        "colab_type": "text"
      },
      "source": [
        "# Train on the best ayperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6gDPRqEBICw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "drop  = 0.307\n",
        "\n",
        "model = timm.create_model('efficientnet_b3a', pretrained=True)\n",
        "model = model.to(device)\n",
        "model_name = 'efficientnet_b3a'\n",
        "\n",
        "model = Additional(model,model.classifier.in_features,drop=drop)\n",
        "model = model.to(device)\n",
        "\n",
        "# class_weights = [class_distrbution[i] for i in train_loader.dataset.classes]\n",
        "# class_weights_normalized = [max(class_weights)/i for i in class_weights]\n",
        "\n",
        "# class_weights_normalized,torch.Tensor(class_weights_normalized)\n",
        "\n",
        "# weights = torch.Tensor(class_weights_normalized)\n",
        "# weights = weights.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss(weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "lr  = 0.00031\n",
        "# optim_ = trial.suggest_categorical('optim_',[optim.Adam])\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "epoch_num = 25\n",
        "best_val_acc = 0.85\n",
        "total_loss_val, total_acc_val = [],[]\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch,device)\n",
        "    loss_val, acc_val = validate(valid_loader, model, criterion, optimizer, epoch,device)\n",
        "    total_loss_val.append(loss_val)\n",
        "    total_acc_val.append(acc_val)\n",
        "    if acc_val > best_val_acc:\n",
        "        best_val_acc = acc_val\n",
        "        torch.save(model.state_dict(), model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt')\n",
        "        print('Model saved :{}'.format(model_name+'freeze_'+str(best_val_acc)[:4]+'.ckpt'))\n",
        "    print('*****************************************************')\n",
        "    print('[epoch %d], [Train loss %.5f], [Train acc %.5f], [val loss %.5f], [val acc %.5f]' % (epoch,loss_train,acc_train, loss_val, acc_val))\n",
        "    print('*****************************************************')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnLZLSVD2lvW",
        "colab_type": "text"
      },
      "source": [
        "## Sumission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "FPVTcaqS2lvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = train_loader.dataset.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "-vEf1EwF2lvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(image_dir):\n",
        "    # Process a PIL image for use in a PyTorch model\n",
        "    # tensor.numpy().transpose(1, 2, 0)\n",
        "    image = Image.open(image_dir)\n",
        "    preprocess = transforms.Compose([ transforms.Resize(224),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=mean,std=std)])\n",
        "    image = preprocess(image)\n",
        "    # Convert 2D image to 1D vector\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = torch.from_numpy(image)\n",
        "    inputs = image.to(device)\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "fIU_hFFj2lvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using our model to predict the label\n",
        "def predict(image, model):\n",
        "    # Pass the image through our model\n",
        "    output = model(image)\n",
        "    # Reverse the log function in our output\n",
        "    output = torch.exp(output)\n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "B9iP5gF92lvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_directory = \"./data/test/test/0\"\n",
        "predictions, test_image_fileName = [], []\n",
        "try:\n",
        "    test_images = listdir(test_directory)\n",
        "    for images in test_images:\n",
        "        test_image_fileName.append(images)\n",
        "        image = process_image(f'{test_directory}/{images}')\n",
        "        top_prob, top_class = predict(image, model)\n",
        "        predictions.append(class_names[top_class])\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "ULVlmzOa2lvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "AjZRSY1o2lvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] Creating pandas dataframe\")\n",
        "submission_data = {\"Category\":predictions,\"Id\":test_image_fileName,}\n",
        "submission_data_frame = pd.DataFrame(submission_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "b0zCCf9x2lvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "vYHtxJ7x2lvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_data_frame.to_csv('submission'+model_name+'_freeze_86_flip.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "y7BYF8Fd2lvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}